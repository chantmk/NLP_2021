{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HW_KeyValueAttention_TH2EN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chantmk/NLP_2021/blob/main/HW8/HW_KeyValueAttention_TH2EN_finished.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1cDcKRZwXCL"
      },
      "source": [
        "# Key-Value Attention Mechanism Homework on Keras: Character-level Machine Translation (Many-to-Many, encoder-decoder)\n",
        "\n",
        "In this homework, you will create an MT model with key-value attention mechnism that coverts names of constituency MP candidates in the 2019 Thai general election from Thai script to Roman(Latin) script. E.g. นิยม-->niyom "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy6QYsP4wa-k",
        "outputId": "414c1fd7-06b2-41e7-d3dd-3b014da6ba98"
      },
      "source": [
        "!wget https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import matplotlib as mpl\n",
        "mpl.font_manager.fontManager.addfont('thsarabunnew-webfont.ttf') # 3.2+\n",
        "mpl.rc('font', family='TH Sarabun New')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-22 09:47:30--  https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Phonbopit/sarabun-webfont/master/fonts/thsarabunnew-webfont.ttf [following]\n",
            "--2021-03-22 09:47:30--  https://raw.githubusercontent.com/Phonbopit/sarabun-webfont/master/fonts/thsarabunnew-webfont.ttf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 98308 (96K) [application/octet-stream]\n",
            "Saving to: ‘thsarabunnew-webfont.ttf’\n",
            "\n",
            "thsarabunnew-webfon 100%[===================>]  96.00K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2021-03-22 09:47:31 (10.6 MB/s) - ‘thsarabunnew-webfont.ttf’ saved [98308/98308]\n",
            "\n",
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRdbTrQJwXCR"
      },
      "source": [
        "%matplotlib inline\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
        "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq20keO6wXCh"
      },
      "source": [
        "## Load Dataset\n",
        "We have generated a toy dataset using names of constituency MP candidates in 2019 Thai General Election from elect.in.th's github(https://github.com/codeforthailand/dataset-election-62-candidates) and tltk (https://pypi.org/project/tltk/) library to convert them into Roman script.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/images/dataset_diagram.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8lWBh40wjgz",
        "outputId": "b50e40ef-43d2-4104-9e28-ec724d18589a"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/mp_name_th_en.csv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-22 09:47:32--  https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/mp_name_th_en.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 324399 (317K) [text/plain]\n",
            "Saving to: ‘mp_name_th_en.csv’\n",
            "\n",
            "mp_name_th_en.csv   100%[===================>] 316.80K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-03-22 09:47:32 (12.6 MB/s) - ‘mp_name_th_en.csv’ saved [324399/324399]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTQk8W4OwXCk"
      },
      "source": [
        "import csv\n",
        "with open('mp_name_th_en.csv') as csvfile:\n",
        "    readCSV = csv.reader(csvfile, delimiter=',')\n",
        "    name_th = []\n",
        "    name_en = []\n",
        "    for row in readCSV:\n",
        "        name_th.append(row[0].strip())\n",
        "        name_en.append(row[1].strip())"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVNHVM_FwXCs",
        "outputId": "1fbbcccb-048f-4789-9520-3438e7c9d5f4"
      },
      "source": [
        "for th, en in zip(name_th[:10],name_en[:10]):\n",
        "    print(th,en)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ไกรสีห์ kraisi\n",
            "พัชรี phatri\n",
            "ธีระ thira\n",
            "วุฒิกร wutthikon\n",
            "ไสว sawai\n",
            "สัมภาษณ์ samphat\n",
            "วศิน wasin\n",
            "ทินวัฒน์ thinwat\n",
            "ศักดินัย sakdinai\n",
            "สุรศักดิ์ surasak\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heMTiM7qwXC2"
      },
      "source": [
        "## Task1: Preprocess dataset for Keras (1 point)\n",
        "* 2 dictionaries for indexing (1 for input and another for output)\n",
        "* DON'T FORGET TO INCLUDE special token for padding\n",
        "* DON'T FORGET TO INCLUDE special token for the end of word symbol (output)\n",
        "* Be mindful of your pad_sequences \"padding\" hyperparameter. Choose wisely (post-padding vs pre-padding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O5YhjntwXC4",
        "outputId": "e6783e58-ffe8-475c-b54a-ce21bb56ab9a"
      },
      "source": [
        "input_char_th = sorted(list(set(''.join(name_th))))\n",
        "output_char_en = sorted(list(set(''.join(name_en))))\n",
        "input_char_th.insert(0, \"<PAD>\")\n",
        "output_char_en = [\"<PAD>\", \"</s>\"] + output_char_en\n",
        "print(input_char_th)\n",
        "print(output_char_en)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<PAD>', 'ก', 'ข', 'ค', 'ฆ', 'ง', 'จ', 'ฉ', 'ช', 'ซ', 'ฌ', 'ญ', 'ฎ', 'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท', 'ธ', 'น', 'บ', 'ป', 'ผ', 'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ล', 'ว', 'ศ', 'ษ', 'ส', 'ห', 'ฬ', 'อ', 'ฮ', 'ะ', 'ั', 'า', 'ำ', 'ิ', 'ี', 'ึ', 'ื', 'ุ', 'ู', 'เ', 'แ', 'โ', 'ใ', 'ไ', '็', '่', '้', '๊', '๋', '์']\n",
            "['<PAD>', '</s>', '-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'w', 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaaGc5WssEnA",
        "outputId": "51cd99e5-108b-4de8-f1d4-7ab11c2ee982"
      },
      "source": [
        "input_char_idx = { char:index for index, char in enumerate(input_char_th)}\n",
        "input_idx_char = { index:char for index, char in enumerate(input_char_th)}\n",
        "\n",
        "output_char_idx = { char:index for index, char in enumerate(output_char_en)}\n",
        "output_idx_char = { index:char for index, char in enumerate(output_char_en)}\n",
        "\n",
        "print(\"Input map-----\")\n",
        "print(input_char_idx)\n",
        "print(input_idx_char)\n",
        "print(len(input_char_idx), len(input_idx_char))\n",
        "print(\"Output map----\")\n",
        "print(output_char_idx)\n",
        "print(output_idx_char)\n",
        "print(len(output_char_idx), len(output_idx_char))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input map-----\n",
            "{'<PAD>': 0, 'ก': 1, 'ข': 2, 'ค': 3, 'ฆ': 4, 'ง': 5, 'จ': 6, 'ฉ': 7, 'ช': 8, 'ซ': 9, 'ฌ': 10, 'ญ': 11, 'ฎ': 12, 'ฏ': 13, 'ฐ': 14, 'ฑ': 15, 'ฒ': 16, 'ณ': 17, 'ด': 18, 'ต': 19, 'ถ': 20, 'ท': 21, 'ธ': 22, 'น': 23, 'บ': 24, 'ป': 25, 'ผ': 26, 'ฝ': 27, 'พ': 28, 'ฟ': 29, 'ภ': 30, 'ม': 31, 'ย': 32, 'ร': 33, 'ล': 34, 'ว': 35, 'ศ': 36, 'ษ': 37, 'ส': 38, 'ห': 39, 'ฬ': 40, 'อ': 41, 'ฮ': 42, 'ะ': 43, 'ั': 44, 'า': 45, 'ำ': 46, 'ิ': 47, 'ี': 48, 'ึ': 49, 'ื': 50, 'ุ': 51, 'ู': 52, 'เ': 53, 'แ': 54, 'โ': 55, 'ใ': 56, 'ไ': 57, '็': 58, '่': 59, '้': 60, '๊': 61, '๋': 62, '์': 63}\n",
            "{0: '<PAD>', 1: 'ก', 2: 'ข', 3: 'ค', 4: 'ฆ', 5: 'ง', 6: 'จ', 7: 'ฉ', 8: 'ช', 9: 'ซ', 10: 'ฌ', 11: 'ญ', 12: 'ฎ', 13: 'ฏ', 14: 'ฐ', 15: 'ฑ', 16: 'ฒ', 17: 'ณ', 18: 'ด', 19: 'ต', 20: 'ถ', 21: 'ท', 22: 'ธ', 23: 'น', 24: 'บ', 25: 'ป', 26: 'ผ', 27: 'ฝ', 28: 'พ', 29: 'ฟ', 30: 'ภ', 31: 'ม', 32: 'ย', 33: 'ร', 34: 'ล', 35: 'ว', 36: 'ศ', 37: 'ษ', 38: 'ส', 39: 'ห', 40: 'ฬ', 41: 'อ', 42: 'ฮ', 43: 'ะ', 44: 'ั', 45: 'า', 46: 'ำ', 47: 'ิ', 48: 'ี', 49: 'ึ', 50: 'ื', 51: 'ุ', 52: 'ู', 53: 'เ', 54: 'แ', 55: 'โ', 56: 'ใ', 57: 'ไ', 58: '็', 59: '่', 60: '้', 61: '๊', 62: '๋', 63: '์'}\n",
            "64 64\n",
            "Output map----\n",
            "{'<PAD>': 0, '</s>': 1, '-': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'k': 12, 'l': 13, 'm': 14, 'n': 15, 'o': 16, 'p': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'w': 22, 'y': 23}\n",
            "{0: '<PAD>', 1: '</s>', 2: '-', 3: 'a', 4: 'b', 5: 'c', 6: 'd', 7: 'e', 8: 'f', 9: 'g', 10: 'h', 11: 'i', 12: 'k', 13: 'l', 14: 'm', 15: 'n', 16: 'o', 17: 'p', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'w', 23: 'y'}\n",
            "24 24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1jh649Qsxrj",
        "outputId": "918687b3-981c-43c7-be71-57ce4e9d3b6b"
      },
      "source": [
        "max_input = len(max(name_th, key=len))\n",
        "max_output = len(max(name_en, key=len))+1\n",
        "\n",
        "x = [[input_char_idx[char] for char in name] for name in name_th]\n",
        "y = [[output_char_idx[char] for char in name] for name in name_en]\n",
        "print(x[:3], \"\\n-----\")\n",
        "\n",
        "x = pad_sequences(x, maxlen=max_input)\n",
        "y = pad_sequences(y, maxlen=max_output)\n",
        "print(x.shape)\n",
        "print(x[:3], \"\\n-----\")\n",
        "\n",
        "input_vocab_size = len(input_char_idx)\n",
        "output_vocab_size = len(output_char_idx)\n",
        "print(input_vocab_size)\n",
        "print(output_vocab_size)\n",
        "x = to_categorical(x, input_vocab_size)\n",
        "y = to_categorical(y, output_vocab_size)\n",
        "print(x.shape)\n",
        "print(x[:3], \"\\n-----\")\n",
        "\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[57, 1, 33, 38, 48, 39, 63], [28, 44, 8, 33, 48], [22, 48, 33, 43]] \n",
            "-----\n",
            "(10887, 20)\n",
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0 57  1 33 38 48 39 63]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 28 44  8 33 48]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 22 48 33 43]] \n",
            "-----\n",
            "64\n",
            "24\n",
            "(10887, 20, 64)\n",
            "[[[1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 1.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]] \n",
            "-----\n",
            "(10887, 20, 64) (10887, 20, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNqqnkVSwXC-"
      },
      "source": [
        "# Attention Mechanism\n",
        "## Task 2: Code your own (key-value) attention mechnism (1 point)\n",
        "* PLEASE READ: you DO NOT have to follow all the details in (Daniluk, et al. 2017). You just need to create a key-value attention mechanism where the \"key\" part of the mechanism is used for attention score calculation, and the \"value\" part of the mechanism is used to encode information to create a context vector.  \n",
        "* Define global variables\n",
        "* fill code for one_step_attention function\n",
        "* Hint: use keras.layers.Lambda \n",
        "* HINT: you will probably need more hidden dimmensions than what you've seen in the demo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSdFcuGuwXDB"
      },
      "source": [
        "from tensorflow.keras.activations import softmax\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow import split\n",
        "def softMaxAxis1(x):\n",
        "    return softmax(x,axis=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNraiNpMB5XY"
      },
      "source": [
        "#These are global variables (shared layers)\n",
        "repeator = RepeatVector(max_input)\n",
        "concatenator = Concatenate(axis=-1)\n",
        "splitter = Lambda(lambda tensor: split(tensor, num_or_size_splits=2, axis=-1) )\n",
        "#Attention function###\n",
        "fattn_1 = Dense(10, activation = \"tanh\")\n",
        "fattn_2 = Dense(1, activation = \"relu\")\n",
        "###\n",
        "activator = Activation(softMaxAxis1, name='attention_scores') \n",
        "dotor = Dot(axes = 1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsF2OldsB9RL"
      },
      "source": [
        "def one_step_attention(a, s_prev):\n",
        "\n",
        "    a_k, a_v = splitter(a)\n",
        "    s_prev = repeator(s_prev)\n",
        "    # s_prev_k, s_prev_v = splitter(s_prev)\n",
        "    # concat = concatenator([a_k, s_prev_k])\n",
        "    concat = concatenator([a_k, s_prev])\n",
        "    e = fattn_1(concat)\n",
        "    energies = fattn_2(e)\n",
        "    attention_scores = activator(energies)\n",
        "    # r = concatenator([a_v, s_prev_v])\n",
        "    r = concatenator([a_v, s_prev])\n",
        "    re = fattn_1(r)\n",
        "    context =  dotor([attention_scores, re])\n",
        "    return context"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bgSCY3NwXDU"
      },
      "source": [
        "## Task3: Create and train your encoder/decoder model here (1 point)\n",
        "* HINT: you will probably need more hidden dimmensions than what you've seen in the demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pmo6LO2N4H8"
      },
      "source": [
        "n_h = 64 #hidden dimensions for encoder \n",
        "n_s = 64 #hidden dimensions for decoder\n",
        "m = 10887\n",
        "encoder_LSTM =  Bidirectional(LSTM(n_h, return_sequences=True),input_shape=(-1, max_input, n_h*2))\n",
        "decoder_LSTM_cell = LSTM(n_s, return_state = True) #decoder_LSTM_cell\n",
        "output_layer = Dense(output_vocab_size, activation=\"softmax\") #softmax output layer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSTTONrUOJSI"
      },
      "source": [
        "s0 = np.zeros((m, n_s))\n",
        "c0 = np.zeros((m, n_s))\n",
        "outputs = list(y.swapaxes(0,1))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_JYHl6YN631"
      },
      "source": [
        "def model(Tx, Ty, n_h, n_s, input_vocab_size, output_vocab_size):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    Tx -- length of the input sequence\n",
        "    Ty -- length of the output sequence\n",
        "    n_h -- hidden state size of the Bi-LSTM\n",
        "    n_s -- hidden state size of the post-attention LSTM\n",
        "    input_vocab_size -- size of the input vocab\n",
        "    output_vocab_size -- size of the output vocab\n",
        "\n",
        "    Returns:\n",
        "    model -- Keras model instance\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input of your model\n",
        "    X = Input(shape=(Tx, input_vocab_size))\n",
        "    # Define hidden state and cell state for decoder_LSTM_Cell\n",
        "    s0 = Input(shape=(n_s,), name='s0')\n",
        "    c0 = Input(shape=(n_s,), name='c0')\n",
        "    s = s0\n",
        "    c = c0\n",
        "    \n",
        "    # Initialize empty list of outputs\n",
        "    outputs = list()\n",
        "    #Encoder Bi-LSTM\n",
        "    # h = Bidirectional(LSTM(n_h, return_sequences=True),input_shape=(-1, Tx, n_h*2))(X)\n",
        "    h = encoder_LSTM(X)\n",
        "    #Iterate for Ty steps (Decoding)\n",
        "    for t in range(Ty):\n",
        "    \n",
        "        #Perform one step of the attention mechanism to calculate the context vector at timestep t\n",
        "        context = one_step_attention(h, s)\n",
        "       \n",
        "        # Feed the context vector to the decoder LSTM cell\n",
        "        s, _, c = decoder_LSTM_cell(context,initial_state=[s,c])\n",
        "           \n",
        "        # Pass the decoder hidden output to the output layer (softmax)\n",
        "        out = output_layer(s)\n",
        "        \n",
        "        # Append an output list with the current output\n",
        "        outputs.append(out)\n",
        "    \n",
        "    #Create model instance\n",
        "    model = Model(inputs=[X,s0,c0],outputs=outputs)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at2QBuIMN_uf"
      },
      "source": [
        "model = model(max_input, max_output, n_h, n_s, input_vocab_size, output_vocab_size)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKSnoc2XOD6F",
        "outputId": "2cb235c7-740a-4daa-dc30-258c6f825adb"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 20, 64)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 20, 128)      66048       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "s0 (InputLayer)                 [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 [(None, 20, 64), (No 0           bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector (RepeatVector)    (None, 20, 64)       0           s0[0][0]                         \n",
            "                                                                 lstm_1[0][0]                     \n",
            "                                                                 lstm_1[1][0]                     \n",
            "                                                                 lstm_1[2][0]                     \n",
            "                                                                 lstm_1[3][0]                     \n",
            "                                                                 lstm_1[4][0]                     \n",
            "                                                                 lstm_1[5][0]                     \n",
            "                                                                 lstm_1[6][0]                     \n",
            "                                                                 lstm_1[7][0]                     \n",
            "                                                                 lstm_1[8][0]                     \n",
            "                                                                 lstm_1[9][0]                     \n",
            "                                                                 lstm_1[10][0]                    \n",
            "                                                                 lstm_1[11][0]                    \n",
            "                                                                 lstm_1[12][0]                    \n",
            "                                                                 lstm_1[13][0]                    \n",
            "                                                                 lstm_1[14][0]                    \n",
            "                                                                 lstm_1[15][0]                    \n",
            "                                                                 lstm_1[16][0]                    \n",
            "                                                                 lstm_1[17][0]                    \n",
            "                                                                 lstm_1[18][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 20, 128)      0           lambda[0][0]                     \n",
            "                                                                 repeat_vector[0][0]              \n",
            "                                                                 lambda[0][1]                     \n",
            "                                                                 repeat_vector[0][0]              \n",
            "                                                                 lambda[1][0]                     \n",
            "                                                                 repeat_vector[1][0]              \n",
            "                                                                 lambda[1][1]                     \n",
            "                                                                 repeat_vector[1][0]              \n",
            "                                                                 lambda[2][0]                     \n",
            "                                                                 repeat_vector[2][0]              \n",
            "                                                                 lambda[2][1]                     \n",
            "                                                                 repeat_vector[2][0]              \n",
            "                                                                 lambda[3][0]                     \n",
            "                                                                 repeat_vector[3][0]              \n",
            "                                                                 lambda[3][1]                     \n",
            "                                                                 repeat_vector[3][0]              \n",
            "                                                                 lambda[4][0]                     \n",
            "                                                                 repeat_vector[4][0]              \n",
            "                                                                 lambda[4][1]                     \n",
            "                                                                 repeat_vector[4][0]              \n",
            "                                                                 lambda[5][0]                     \n",
            "                                                                 repeat_vector[5][0]              \n",
            "                                                                 lambda[5][1]                     \n",
            "                                                                 repeat_vector[5][0]              \n",
            "                                                                 lambda[6][0]                     \n",
            "                                                                 repeat_vector[6][0]              \n",
            "                                                                 lambda[6][1]                     \n",
            "                                                                 repeat_vector[6][0]              \n",
            "                                                                 lambda[7][0]                     \n",
            "                                                                 repeat_vector[7][0]              \n",
            "                                                                 lambda[7][1]                     \n",
            "                                                                 repeat_vector[7][0]              \n",
            "                                                                 lambda[8][0]                     \n",
            "                                                                 repeat_vector[8][0]              \n",
            "                                                                 lambda[8][1]                     \n",
            "                                                                 repeat_vector[8][0]              \n",
            "                                                                 lambda[9][0]                     \n",
            "                                                                 repeat_vector[9][0]              \n",
            "                                                                 lambda[9][1]                     \n",
            "                                                                 repeat_vector[9][0]              \n",
            "                                                                 lambda[10][0]                    \n",
            "                                                                 repeat_vector[10][0]             \n",
            "                                                                 lambda[10][1]                    \n",
            "                                                                 repeat_vector[10][0]             \n",
            "                                                                 lambda[11][0]                    \n",
            "                                                                 repeat_vector[11][0]             \n",
            "                                                                 lambda[11][1]                    \n",
            "                                                                 repeat_vector[11][0]             \n",
            "                                                                 lambda[12][0]                    \n",
            "                                                                 repeat_vector[12][0]             \n",
            "                                                                 lambda[12][1]                    \n",
            "                                                                 repeat_vector[12][0]             \n",
            "                                                                 lambda[13][0]                    \n",
            "                                                                 repeat_vector[13][0]             \n",
            "                                                                 lambda[13][1]                    \n",
            "                                                                 repeat_vector[13][0]             \n",
            "                                                                 lambda[14][0]                    \n",
            "                                                                 repeat_vector[14][0]             \n",
            "                                                                 lambda[14][1]                    \n",
            "                                                                 repeat_vector[14][0]             \n",
            "                                                                 lambda[15][0]                    \n",
            "                                                                 repeat_vector[15][0]             \n",
            "                                                                 lambda[15][1]                    \n",
            "                                                                 repeat_vector[15][0]             \n",
            "                                                                 lambda[16][0]                    \n",
            "                                                                 repeat_vector[16][0]             \n",
            "                                                                 lambda[16][1]                    \n",
            "                                                                 repeat_vector[16][0]             \n",
            "                                                                 lambda[17][0]                    \n",
            "                                                                 repeat_vector[17][0]             \n",
            "                                                                 lambda[17][1]                    \n",
            "                                                                 repeat_vector[17][0]             \n",
            "                                                                 lambda[18][0]                    \n",
            "                                                                 repeat_vector[18][0]             \n",
            "                                                                 lambda[18][1]                    \n",
            "                                                                 repeat_vector[18][0]             \n",
            "                                                                 lambda[19][0]                    \n",
            "                                                                 repeat_vector[19][0]             \n",
            "                                                                 lambda[19][1]                    \n",
            "                                                                 repeat_vector[19][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20, 10)       1290        concatenate[0][0]                \n",
            "                                                                 concatenate[1][0]                \n",
            "                                                                 concatenate[2][0]                \n",
            "                                                                 concatenate[3][0]                \n",
            "                                                                 concatenate[4][0]                \n",
            "                                                                 concatenate[5][0]                \n",
            "                                                                 concatenate[6][0]                \n",
            "                                                                 concatenate[7][0]                \n",
            "                                                                 concatenate[8][0]                \n",
            "                                                                 concatenate[9][0]                \n",
            "                                                                 concatenate[10][0]               \n",
            "                                                                 concatenate[11][0]               \n",
            "                                                                 concatenate[12][0]               \n",
            "                                                                 concatenate[13][0]               \n",
            "                                                                 concatenate[14][0]               \n",
            "                                                                 concatenate[15][0]               \n",
            "                                                                 concatenate[16][0]               \n",
            "                                                                 concatenate[17][0]               \n",
            "                                                                 concatenate[18][0]               \n",
            "                                                                 concatenate[19][0]               \n",
            "                                                                 concatenate[20][0]               \n",
            "                                                                 concatenate[21][0]               \n",
            "                                                                 concatenate[22][0]               \n",
            "                                                                 concatenate[23][0]               \n",
            "                                                                 concatenate[24][0]               \n",
            "                                                                 concatenate[25][0]               \n",
            "                                                                 concatenate[26][0]               \n",
            "                                                                 concatenate[27][0]               \n",
            "                                                                 concatenate[28][0]               \n",
            "                                                                 concatenate[29][0]               \n",
            "                                                                 concatenate[30][0]               \n",
            "                                                                 concatenate[31][0]               \n",
            "                                                                 concatenate[32][0]               \n",
            "                                                                 concatenate[33][0]               \n",
            "                                                                 concatenate[34][0]               \n",
            "                                                                 concatenate[35][0]               \n",
            "                                                                 concatenate[36][0]               \n",
            "                                                                 concatenate[37][0]               \n",
            "                                                                 concatenate[38][0]               \n",
            "                                                                 concatenate[39][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20, 1)        11          dense[0][0]                      \n",
            "                                                                 dense[2][0]                      \n",
            "                                                                 dense[4][0]                      \n",
            "                                                                 dense[6][0]                      \n",
            "                                                                 dense[8][0]                      \n",
            "                                                                 dense[10][0]                     \n",
            "                                                                 dense[12][0]                     \n",
            "                                                                 dense[14][0]                     \n",
            "                                                                 dense[16][0]                     \n",
            "                                                                 dense[18][0]                     \n",
            "                                                                 dense[20][0]                     \n",
            "                                                                 dense[22][0]                     \n",
            "                                                                 dense[24][0]                     \n",
            "                                                                 dense[26][0]                     \n",
            "                                                                 dense[28][0]                     \n",
            "                                                                 dense[30][0]                     \n",
            "                                                                 dense[32][0]                     \n",
            "                                                                 dense[34][0]                     \n",
            "                                                                 dense[36][0]                     \n",
            "                                                                 dense[38][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_scores (Activation)   (None, 20, 1)        0           dense_1[0][0]                    \n",
            "                                                                 dense_1[1][0]                    \n",
            "                                                                 dense_1[2][0]                    \n",
            "                                                                 dense_1[3][0]                    \n",
            "                                                                 dense_1[4][0]                    \n",
            "                                                                 dense_1[5][0]                    \n",
            "                                                                 dense_1[6][0]                    \n",
            "                                                                 dense_1[7][0]                    \n",
            "                                                                 dense_1[8][0]                    \n",
            "                                                                 dense_1[9][0]                    \n",
            "                                                                 dense_1[10][0]                   \n",
            "                                                                 dense_1[11][0]                   \n",
            "                                                                 dense_1[12][0]                   \n",
            "                                                                 dense_1[13][0]                   \n",
            "                                                                 dense_1[14][0]                   \n",
            "                                                                 dense_1[15][0]                   \n",
            "                                                                 dense_1[16][0]                   \n",
            "                                                                 dense_1[17][0]                   \n",
            "                                                                 dense_1[18][0]                   \n",
            "                                                                 dense_1[19][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 1, 10)        0           attention_scores[0][0]           \n",
            "                                                                 dense[1][0]                      \n",
            "                                                                 attention_scores[1][0]           \n",
            "                                                                 dense[3][0]                      \n",
            "                                                                 attention_scores[2][0]           \n",
            "                                                                 dense[5][0]                      \n",
            "                                                                 attention_scores[3][0]           \n",
            "                                                                 dense[7][0]                      \n",
            "                                                                 attention_scores[4][0]           \n",
            "                                                                 dense[9][0]                      \n",
            "                                                                 attention_scores[5][0]           \n",
            "                                                                 dense[11][0]                     \n",
            "                                                                 attention_scores[6][0]           \n",
            "                                                                 dense[13][0]                     \n",
            "                                                                 attention_scores[7][0]           \n",
            "                                                                 dense[15][0]                     \n",
            "                                                                 attention_scores[8][0]           \n",
            "                                                                 dense[17][0]                     \n",
            "                                                                 attention_scores[9][0]           \n",
            "                                                                 dense[19][0]                     \n",
            "                                                                 attention_scores[10][0]          \n",
            "                                                                 dense[21][0]                     \n",
            "                                                                 attention_scores[11][0]          \n",
            "                                                                 dense[23][0]                     \n",
            "                                                                 attention_scores[12][0]          \n",
            "                                                                 dense[25][0]                     \n",
            "                                                                 attention_scores[13][0]          \n",
            "                                                                 dense[27][0]                     \n",
            "                                                                 attention_scores[14][0]          \n",
            "                                                                 dense[29][0]                     \n",
            "                                                                 attention_scores[15][0]          \n",
            "                                                                 dense[31][0]                     \n",
            "                                                                 attention_scores[16][0]          \n",
            "                                                                 dense[33][0]                     \n",
            "                                                                 attention_scores[17][0]          \n",
            "                                                                 dense[35][0]                     \n",
            "                                                                 attention_scores[18][0]          \n",
            "                                                                 dense[37][0]                     \n",
            "                                                                 attention_scores[19][0]          \n",
            "                                                                 dense[39][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "c0 (InputLayer)                 [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 64), (None,  19200       dot[0][0]                        \n",
            "                                                                 s0[0][0]                         \n",
            "                                                                 c0[0][0]                         \n",
            "                                                                 dot[1][0]                        \n",
            "                                                                 lstm_1[0][0]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "                                                                 dot[2][0]                        \n",
            "                                                                 lstm_1[1][0]                     \n",
            "                                                                 lstm_1[1][2]                     \n",
            "                                                                 dot[3][0]                        \n",
            "                                                                 lstm_1[2][0]                     \n",
            "                                                                 lstm_1[2][2]                     \n",
            "                                                                 dot[4][0]                        \n",
            "                                                                 lstm_1[3][0]                     \n",
            "                                                                 lstm_1[3][2]                     \n",
            "                                                                 dot[5][0]                        \n",
            "                                                                 lstm_1[4][0]                     \n",
            "                                                                 lstm_1[4][2]                     \n",
            "                                                                 dot[6][0]                        \n",
            "                                                                 lstm_1[5][0]                     \n",
            "                                                                 lstm_1[5][2]                     \n",
            "                                                                 dot[7][0]                        \n",
            "                                                                 lstm_1[6][0]                     \n",
            "                                                                 lstm_1[6][2]                     \n",
            "                                                                 dot[8][0]                        \n",
            "                                                                 lstm_1[7][0]                     \n",
            "                                                                 lstm_1[7][2]                     \n",
            "                                                                 dot[9][0]                        \n",
            "                                                                 lstm_1[8][0]                     \n",
            "                                                                 lstm_1[8][2]                     \n",
            "                                                                 dot[10][0]                       \n",
            "                                                                 lstm_1[9][0]                     \n",
            "                                                                 lstm_1[9][2]                     \n",
            "                                                                 dot[11][0]                       \n",
            "                                                                 lstm_1[10][0]                    \n",
            "                                                                 lstm_1[10][2]                    \n",
            "                                                                 dot[12][0]                       \n",
            "                                                                 lstm_1[11][0]                    \n",
            "                                                                 lstm_1[11][2]                    \n",
            "                                                                 dot[13][0]                       \n",
            "                                                                 lstm_1[12][0]                    \n",
            "                                                                 lstm_1[12][2]                    \n",
            "                                                                 dot[14][0]                       \n",
            "                                                                 lstm_1[13][0]                    \n",
            "                                                                 lstm_1[13][2]                    \n",
            "                                                                 dot[15][0]                       \n",
            "                                                                 lstm_1[14][0]                    \n",
            "                                                                 lstm_1[14][2]                    \n",
            "                                                                 dot[16][0]                       \n",
            "                                                                 lstm_1[15][0]                    \n",
            "                                                                 lstm_1[15][2]                    \n",
            "                                                                 dot[17][0]                       \n",
            "                                                                 lstm_1[16][0]                    \n",
            "                                                                 lstm_1[16][2]                    \n",
            "                                                                 dot[18][0]                       \n",
            "                                                                 lstm_1[17][0]                    \n",
            "                                                                 lstm_1[17][2]                    \n",
            "                                                                 dot[19][0]                       \n",
            "                                                                 lstm_1[18][0]                    \n",
            "                                                                 lstm_1[18][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 24)           1560        lstm_1[0][0]                     \n",
            "                                                                 lstm_1[1][0]                     \n",
            "                                                                 lstm_1[2][0]                     \n",
            "                                                                 lstm_1[3][0]                     \n",
            "                                                                 lstm_1[4][0]                     \n",
            "                                                                 lstm_1[5][0]                     \n",
            "                                                                 lstm_1[6][0]                     \n",
            "                                                                 lstm_1[7][0]                     \n",
            "                                                                 lstm_1[8][0]                     \n",
            "                                                                 lstm_1[9][0]                     \n",
            "                                                                 lstm_1[10][0]                    \n",
            "                                                                 lstm_1[11][0]                    \n",
            "                                                                 lstm_1[12][0]                    \n",
            "                                                                 lstm_1[13][0]                    \n",
            "                                                                 lstm_1[14][0]                    \n",
            "                                                                 lstm_1[15][0]                    \n",
            "                                                                 lstm_1[16][0]                    \n",
            "                                                                 lstm_1[17][0]                    \n",
            "                                                                 lstm_1[18][0]                    \n",
            "                                                                 lstm_1[19][0]                    \n",
            "==================================================================================================\n",
            "Total params: 88,109\n",
            "Trainable params: 88,109\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpTFxnXQOID_"
      },
      "source": [
        "opt = Adam(lr= 0.01, clipvalue=0.5)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VR6J7K6OKgH",
        "outputId": "b8101607-1c63-4679-ad8b-46cde031bbba"
      },
      "source": [
        "model.fit([x, s0, c0], outputs, epochs=40, batch_size=64)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "171/171 [==============================] - 76s 74ms/step - loss: 30.5015 - dense_2_loss: 0.6549 - dense_2_1_loss: 0.4259 - dense_2_2_loss: 0.3745 - dense_2_3_loss: 0.3622 - dense_2_4_loss: 0.3685 - dense_2_5_loss: 0.3882 - dense_2_6_loss: 0.4241 - dense_2_7_loss: 0.4843 - dense_2_8_loss: 0.5900 - dense_2_9_loss: 0.7524 - dense_2_10_loss: 1.0374 - dense_2_11_loss: 1.4206 - dense_2_12_loss: 1.9461 - dense_2_13_loss: 2.5411 - dense_2_14_loss: 2.9827 - dense_2_15_loss: 3.2131 - dense_2_16_loss: 3.1750 - dense_2_17_loss: 3.3792 - dense_2_18_loss: 3.0154 - dense_2_19_loss: 2.9659 - dense_2_accuracy: 0.9672 - dense_2_1_accuracy: 0.9670 - dense_2_2_accuracy: 0.9670 - dense_2_3_accuracy: 0.9665 - dense_2_4_accuracy: 0.9661 - dense_2_5_accuracy: 0.9650 - dense_2_6_accuracy: 0.9611 - dense_2_7_accuracy: 0.9532 - dense_2_8_accuracy: 0.9364 - dense_2_9_accuracy: 0.9055 - dense_2_10_accuracy: 0.8370 - dense_2_11_accuracy: 0.7204 - dense_2_12_accuracy: 0.5622 - dense_2_13_accuracy: 0.3534 - dense_2_14_accuracy: 0.1900 - dense_2_15_accuracy: 0.0957 - dense_2_16_accuracy: 0.0949 - dense_2_17_accuracy: 0.0316 - dense_2_18_accuracy: 0.1545 - dense_2_19_accuracy: 0.0675\n",
            "Epoch 2/40\n",
            "171/171 [==============================] - 13s 74ms/step - loss: 21.0398 - dense_2_loss: 0.0111 - dense_2_1_loss: 0.0056 - dense_2_2_loss: 0.0062 - dense_2_3_loss: 0.0092 - dense_2_4_loss: 0.0123 - dense_2_5_loss: 0.0217 - dense_2_6_loss: 0.0456 - dense_2_7_loss: 0.1011 - dense_2_8_loss: 0.1733 - dense_2_9_loss: 0.2864 - dense_2_10_loss: 0.5358 - dense_2_11_loss: 0.9218 - dense_2_12_loss: 1.4244 - dense_2_13_loss: 1.9901 - dense_2_14_loss: 2.4249 - dense_2_15_loss: 2.6607 - dense_2_16_loss: 2.6878 - dense_2_17_loss: 2.9257 - dense_2_18_loss: 2.4810 - dense_2_19_loss: 2.3152 - dense_2_accuracy: 0.9998 - dense_2_1_accuracy: 0.9994 - dense_2_2_accuracy: 0.9993 - dense_2_3_accuracy: 0.9988 - dense_2_4_accuracy: 0.9981 - dense_2_5_accuracy: 0.9966 - dense_2_6_accuracy: 0.9922 - dense_2_7_accuracy: 0.9823 - dense_2_8_accuracy: 0.9649 - dense_2_9_accuracy: 0.9384 - dense_2_10_accuracy: 0.8745 - dense_2_11_accuracy: 0.7650 - dense_2_12_accuracy: 0.6268 - dense_2_13_accuracy: 0.4298 - dense_2_14_accuracy: 0.2770 - dense_2_15_accuracy: 0.1938 - dense_2_16_accuracy: 0.2122 - dense_2_17_accuracy: 0.0753 - dense_2_18_accuracy: 0.3341 - dense_2_19_accuracy: 0.1483\n",
            "Epoch 3/40\n",
            "171/171 [==============================] - 13s 75ms/step - loss: 20.2621 - dense_2_loss: 0.0071 - dense_2_1_loss: 0.0020 - dense_2_2_loss: 0.0024 - dense_2_3_loss: 0.0045 - dense_2_4_loss: 0.0095 - dense_2_5_loss: 0.0166 - dense_2_6_loss: 0.0399 - dense_2_7_loss: 0.0811 - dense_2_8_loss: 0.1577 - dense_2_9_loss: 0.2731 - dense_2_10_loss: 0.5121 - dense_2_11_loss: 0.8809 - dense_2_12_loss: 1.3749 - dense_2_13_loss: 1.9035 - dense_2_14_loss: 2.3757 - dense_2_15_loss: 2.6202 - dense_2_16_loss: 2.5815 - dense_2_17_loss: 2.8253 - dense_2_18_loss: 2.4220 - dense_2_19_loss: 2.1720 - dense_2_accuracy: 0.9998 - dense_2_1_accuracy: 0.9995 - dense_2_2_accuracy: 0.9995 - dense_2_3_accuracy: 0.9991 - dense_2_4_accuracy: 0.9984 - dense_2_5_accuracy: 0.9971 - dense_2_6_accuracy: 0.9926 - dense_2_7_accuracy: 0.9840 - dense_2_8_accuracy: 0.9665 - dense_2_9_accuracy: 0.9384 - dense_2_10_accuracy: 0.8723 - dense_2_11_accuracy: 0.7659 - dense_2_12_accuracy: 0.6251 - dense_2_13_accuracy: 0.4435 - dense_2_14_accuracy: 0.2799 - dense_2_15_accuracy: 0.1932 - dense_2_16_accuracy: 0.2087 - dense_2_17_accuracy: 0.1367 - dense_2_18_accuracy: 0.2987 - dense_2_19_accuracy: 0.2026\n",
            "Epoch 4/40\n",
            "171/171 [==============================] - 13s 75ms/step - loss: 19.9439 - dense_2_loss: 0.0074 - dense_2_1_loss: 0.0016 - dense_2_2_loss: 0.0020 - dense_2_3_loss: 0.0060 - dense_2_4_loss: 0.0078 - dense_2_5_loss: 0.0121 - dense_2_6_loss: 0.0301 - dense_2_7_loss: 0.0676 - dense_2_8_loss: 0.1342 - dense_2_9_loss: 0.2638 - dense_2_10_loss: 0.4769 - dense_2_11_loss: 0.8383 - dense_2_12_loss: 1.3182 - dense_2_13_loss: 1.8523 - dense_2_14_loss: 2.3203 - dense_2_15_loss: 2.5538 - dense_2_16_loss: 2.5448 - dense_2_17_loss: 2.8037 - dense_2_18_loss: 2.4677 - dense_2_19_loss: 2.2352 - dense_2_accuracy: 0.9998 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9995 - dense_2_3_accuracy: 0.9989 - dense_2_4_accuracy: 0.9986 - dense_2_5_accuracy: 0.9973 - dense_2_6_accuracy: 0.9933 - dense_2_7_accuracy: 0.9842 - dense_2_8_accuracy: 0.9676 - dense_2_9_accuracy: 0.9368 - dense_2_10_accuracy: 0.8753 - dense_2_11_accuracy: 0.7736 - dense_2_12_accuracy: 0.6263 - dense_2_13_accuracy: 0.4568 - dense_2_14_accuracy: 0.2871 - dense_2_15_accuracy: 0.1873 - dense_2_16_accuracy: 0.2124 - dense_2_17_accuracy: 0.1352 - dense_2_18_accuracy: 0.2928 - dense_2_19_accuracy: 0.1908\n",
            "Epoch 5/40\n",
            "171/171 [==============================] - 13s 75ms/step - loss: 18.4441 - dense_2_loss: 0.0040 - dense_2_1_loss: 0.0022 - dense_2_2_loss: 0.0024 - dense_2_3_loss: 0.0029 - dense_2_4_loss: 0.0073 - dense_2_5_loss: 0.0115 - dense_2_6_loss: 0.0268 - dense_2_7_loss: 0.0619 - dense_2_8_loss: 0.1278 - dense_2_9_loss: 0.2648 - dense_2_10_loss: 0.4529 - dense_2_11_loss: 0.7677 - dense_2_12_loss: 1.2354 - dense_2_13_loss: 1.8003 - dense_2_14_loss: 2.2387 - dense_2_15_loss: 2.4792 - dense_2_16_loss: 2.4133 - dense_2_17_loss: 2.4853 - dense_2_18_loss: 2.1839 - dense_2_19_loss: 1.8759 - dense_2_accuracy: 0.9998 - dense_2_1_accuracy: 0.9995 - dense_2_2_accuracy: 0.9995 - dense_2_3_accuracy: 0.9993 - dense_2_4_accuracy: 0.9982 - dense_2_5_accuracy: 0.9977 - dense_2_6_accuracy: 0.9940 - dense_2_7_accuracy: 0.9868 - dense_2_8_accuracy: 0.9693 - dense_2_9_accuracy: 0.9342 - dense_2_10_accuracy: 0.8766 - dense_2_11_accuracy: 0.7893 - dense_2_12_accuracy: 0.6513 - dense_2_13_accuracy: 0.4648 - dense_2_14_accuracy: 0.3053 - dense_2_15_accuracy: 0.2028 - dense_2_16_accuracy: 0.2337 - dense_2_17_accuracy: 0.2341 - dense_2_18_accuracy: 0.3489 - dense_2_19_accuracy: 0.3095\n",
            "Epoch 6/40\n",
            "171/171 [==============================] - 13s 75ms/step - loss: 17.1771 - dense_2_loss: 0.0069 - dense_2_1_loss: 9.6642e-04 - dense_2_2_loss: 9.6119e-04 - dense_2_3_loss: 0.0061 - dense_2_4_loss: 0.0077 - dense_2_5_loss: 0.0134 - dense_2_6_loss: 0.0313 - dense_2_7_loss: 0.0706 - dense_2_8_loss: 0.1227 - dense_2_9_loss: 0.2319 - dense_2_10_loss: 0.4064 - dense_2_11_loss: 0.7138 - dense_2_12_loss: 1.1468 - dense_2_13_loss: 1.6599 - dense_2_14_loss: 2.1584 - dense_2_15_loss: 2.4107 - dense_2_16_loss: 2.2575 - dense_2_17_loss: 2.2874 - dense_2_18_loss: 2.0127 - dense_2_19_loss: 1.6311 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9989 - dense_2_4_accuracy: 0.9982 - dense_2_5_accuracy: 0.9972 - dense_2_6_accuracy: 0.9922 - dense_2_7_accuracy: 0.9826 - dense_2_8_accuracy: 0.9680 - dense_2_9_accuracy: 0.9418 - dense_2_10_accuracy: 0.8852 - dense_2_11_accuracy: 0.7977 - dense_2_12_accuracy: 0.6602 - dense_2_13_accuracy: 0.4982 - dense_2_14_accuracy: 0.3293 - dense_2_15_accuracy: 0.2142 - dense_2_16_accuracy: 0.2750 - dense_2_17_accuracy: 0.2941 - dense_2_18_accuracy: 0.4050 - dense_2_19_accuracy: 0.4160\n",
            "Epoch 7/40\n",
            "171/171 [==============================] - 13s 74ms/step - loss: 15.7480 - dense_2_loss: 0.0056 - dense_2_1_loss: 2.3604e-04 - dense_2_2_loss: 2.6158e-04 - dense_2_3_loss: 0.0022 - dense_2_4_loss: 0.0073 - dense_2_5_loss: 0.0122 - dense_2_6_loss: 0.0320 - dense_2_7_loss: 0.0580 - dense_2_8_loss: 0.1213 - dense_2_9_loss: 0.2255 - dense_2_10_loss: 0.4062 - dense_2_11_loss: 0.6939 - dense_2_12_loss: 1.1114 - dense_2_13_loss: 1.5900 - dense_2_14_loss: 2.0611 - dense_2_15_loss: 2.2962 - dense_2_16_loss: 2.0646 - dense_2_17_loss: 2.0692 - dense_2_18_loss: 1.6939 - dense_2_19_loss: 1.2970 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9995 - dense_2_4_accuracy: 0.9984 - dense_2_5_accuracy: 0.9971 - dense_2_6_accuracy: 0.9929 - dense_2_7_accuracy: 0.9864 - dense_2_8_accuracy: 0.9685 - dense_2_9_accuracy: 0.9393 - dense_2_10_accuracy: 0.8843 - dense_2_11_accuracy: 0.7958 - dense_2_12_accuracy: 0.6683 - dense_2_13_accuracy: 0.5137 - dense_2_14_accuracy: 0.3596 - dense_2_15_accuracy: 0.2551 - dense_2_16_accuracy: 0.3553 - dense_2_17_accuracy: 0.3715 - dense_2_18_accuracy: 0.4774 - dense_2_19_accuracy: 0.5621\n",
            "Epoch 8/40\n",
            "171/171 [==============================] - 13s 75ms/step - loss: 14.9241 - dense_2_loss: 0.0074 - dense_2_1_loss: 0.0014 - dense_2_2_loss: 0.0021 - dense_2_3_loss: 0.0049 - dense_2_4_loss: 0.0090 - dense_2_5_loss: 0.0208 - dense_2_6_loss: 0.0420 - dense_2_7_loss: 0.0663 - dense_2_8_loss: 0.1238 - dense_2_9_loss: 0.2294 - dense_2_10_loss: 0.3974 - dense_2_11_loss: 0.6586 - dense_2_12_loss: 1.0766 - dense_2_13_loss: 1.5195 - dense_2_14_loss: 1.9676 - dense_2_15_loss: 2.1930 - dense_2_16_loss: 1.9883 - dense_2_17_loss: 1.9376 - dense_2_18_loss: 1.5679 - dense_2_19_loss: 1.1104 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9997 - dense_2_2_accuracy: 0.9994 - dense_2_3_accuracy: 0.9990 - dense_2_4_accuracy: 0.9980 - dense_2_5_accuracy: 0.9954 - dense_2_6_accuracy: 0.9902 - dense_2_7_accuracy: 0.9838 - dense_2_8_accuracy: 0.9669 - dense_2_9_accuracy: 0.9408 - dense_2_10_accuracy: 0.8843 - dense_2_11_accuracy: 0.8006 - dense_2_12_accuracy: 0.6765 - dense_2_13_accuracy: 0.5363 - dense_2_14_accuracy: 0.3848 - dense_2_15_accuracy: 0.2844 - dense_2_16_accuracy: 0.3711 - dense_2_17_accuracy: 0.4166 - dense_2_18_accuracy: 0.5010 - dense_2_19_accuracy: 0.6387\n",
            "Epoch 9/40\n",
            "171/171 [==============================] - 13s 75ms/step - loss: 14.0203 - dense_2_loss: 0.0036 - dense_2_1_loss: 4.5040e-04 - dense_2_2_loss: 7.2638e-04 - dense_2_3_loss: 0.0056 - dense_2_4_loss: 0.0102 - dense_2_5_loss: 0.0155 - dense_2_6_loss: 0.0320 - dense_2_7_loss: 0.0496 - dense_2_8_loss: 0.1090 - dense_2_9_loss: 0.2122 - dense_2_10_loss: 0.3778 - dense_2_11_loss: 0.6368 - dense_2_12_loss: 1.0288 - dense_2_13_loss: 1.4273 - dense_2_14_loss: 1.8866 - dense_2_15_loss: 2.0794 - dense_2_16_loss: 1.8742 - dense_2_17_loss: 1.8099 - dense_2_18_loss: 1.4721 - dense_2_19_loss: 0.9887 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9990 - dense_2_4_accuracy: 0.9980 - dense_2_5_accuracy: 0.9967 - dense_2_6_accuracy: 0.9927 - dense_2_7_accuracy: 0.9867 - dense_2_8_accuracy: 0.9700 - dense_2_9_accuracy: 0.9439 - dense_2_10_accuracy: 0.8892 - dense_2_11_accuracy: 0.8140 - dense_2_12_accuracy: 0.6873 - dense_2_13_accuracy: 0.5602 - dense_2_14_accuracy: 0.4196 - dense_2_15_accuracy: 0.3330 - dense_2_16_accuracy: 0.4070 - dense_2_17_accuracy: 0.4439 - dense_2_18_accuracy: 0.5333 - dense_2_19_accuracy: 0.6916\n",
            "Epoch 10/40\n",
            "171/171 [==============================] - 13s 75ms/step - loss: 13.7795 - dense_2_loss: 0.0033 - dense_2_1_loss: 7.7575e-04 - dense_2_2_loss: 0.0013 - dense_2_3_loss: 0.0040 - dense_2_4_loss: 0.0108 - dense_2_5_loss: 0.0136 - dense_2_6_loss: 0.0296 - dense_2_7_loss: 0.0506 - dense_2_8_loss: 0.1091 - dense_2_9_loss: 0.2010 - dense_2_10_loss: 0.3594 - dense_2_11_loss: 0.6194 - dense_2_12_loss: 0.9979 - dense_2_13_loss: 1.4051 - dense_2_14_loss: 1.8393 - dense_2_15_loss: 1.9952 - dense_2_16_loss: 1.8078 - dense_2_17_loss: 1.8247 - dense_2_18_loss: 1.5163 - dense_2_19_loss: 0.9905 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9993 - dense_2_4_accuracy: 0.9979 - dense_2_5_accuracy: 0.9967 - dense_2_6_accuracy: 0.9926 - dense_2_7_accuracy: 0.9870 - dense_2_8_accuracy: 0.9713 - dense_2_9_accuracy: 0.9458 - dense_2_10_accuracy: 0.8929 - dense_2_11_accuracy: 0.8139 - dense_2_12_accuracy: 0.6989 - dense_2_13_accuracy: 0.5668 - dense_2_14_accuracy: 0.4311 - dense_2_15_accuracy: 0.3689 - dense_2_16_accuracy: 0.4123 - dense_2_17_accuracy: 0.4484 - dense_2_18_accuracy: 0.5192 - dense_2_19_accuracy: 0.6969\n",
            "Epoch 11/40\n",
            "171/171 [==============================] - 13s 74ms/step - loss: 11.8783 - dense_2_loss: 0.0037 - dense_2_1_loss: 0.0011 - dense_2_2_loss: 0.0016 - dense_2_3_loss: 0.0051 - dense_2_4_loss: 0.0122 - dense_2_5_loss: 0.0132 - dense_2_6_loss: 0.0315 - dense_2_7_loss: 0.0480 - dense_2_8_loss: 0.1021 - dense_2_9_loss: 0.1800 - dense_2_10_loss: 0.3226 - dense_2_11_loss: 0.5502 - dense_2_12_loss: 0.9039 - dense_2_13_loss: 1.2616 - dense_2_14_loss: 1.6784 - dense_2_15_loss: 1.8169 - dense_2_16_loss: 1.6188 - dense_2_17_loss: 1.4795 - dense_2_18_loss: 1.1421 - dense_2_19_loss: 0.7059 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9995 - dense_2_3_accuracy: 0.9992 - dense_2_4_accuracy: 0.9977 - dense_2_5_accuracy: 0.9965 - dense_2_6_accuracy: 0.9925 - dense_2_7_accuracy: 0.9866 - dense_2_8_accuracy: 0.9733 - dense_2_9_accuracy: 0.9490 - dense_2_10_accuracy: 0.9067 - dense_2_11_accuracy: 0.8362 - dense_2_12_accuracy: 0.7273 - dense_2_13_accuracy: 0.6125 - dense_2_14_accuracy: 0.4867 - dense_2_15_accuracy: 0.4313 - dense_2_16_accuracy: 0.4834 - dense_2_17_accuracy: 0.5569 - dense_2_18_accuracy: 0.6380 - dense_2_19_accuracy: 0.7947\n",
            "Epoch 12/40\n",
            "171/171 [==============================] - 13s 74ms/step - loss: 10.9435 - dense_2_loss: 0.0028 - dense_2_1_loss: 0.0012 - dense_2_2_loss: 0.0019 - dense_2_3_loss: 0.0070 - dense_2_4_loss: 0.0100 - dense_2_5_loss: 0.0142 - dense_2_6_loss: 0.0285 - dense_2_7_loss: 0.0459 - dense_2_8_loss: 0.1013 - dense_2_9_loss: 0.1746 - dense_2_10_loss: 0.3050 - dense_2_11_loss: 0.5199 - dense_2_12_loss: 0.8435 - dense_2_13_loss: 1.1731 - dense_2_14_loss: 1.5709 - dense_2_15_loss: 1.6872 - dense_2_16_loss: 1.5089 - dense_2_17_loss: 1.3191 - dense_2_18_loss: 1.0234 - dense_2_19_loss: 0.6051 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9995 - dense_2_3_accuracy: 0.9987 - dense_2_4_accuracy: 0.9980 - dense_2_5_accuracy: 0.9963 - dense_2_6_accuracy: 0.9929 - dense_2_7_accuracy: 0.9879 - dense_2_8_accuracy: 0.9734 - dense_2_9_accuracy: 0.9527 - dense_2_10_accuracy: 0.9121 - dense_2_11_accuracy: 0.8460 - dense_2_12_accuracy: 0.7469 - dense_2_13_accuracy: 0.6450 - dense_2_14_accuracy: 0.5265 - dense_2_15_accuracy: 0.4882 - dense_2_16_accuracy: 0.5207 - dense_2_17_accuracy: 0.5997 - dense_2_18_accuracy: 0.6810 - dense_2_19_accuracy: 0.8225\n",
            "Epoch 13/40\n",
            "171/171 [==============================] - 13s 74ms/step - loss: 9.9396 - dense_2_loss: 0.0026 - dense_2_1_loss: 6.4778e-04 - dense_2_2_loss: 0.0015 - dense_2_3_loss: 0.0064 - dense_2_4_loss: 0.0085 - dense_2_5_loss: 0.0114 - dense_2_6_loss: 0.0254 - dense_2_7_loss: 0.0468 - dense_2_8_loss: 0.0899 - dense_2_9_loss: 0.1667 - dense_2_10_loss: 0.2687 - dense_2_11_loss: 0.4621 - dense_2_12_loss: 0.7684 - dense_2_13_loss: 1.0650 - dense_2_14_loss: 1.4567 - dense_2_15_loss: 1.5877 - dense_2_16_loss: 1.3711 - dense_2_17_loss: 1.2091 - dense_2_18_loss: 0.8836 - dense_2_19_loss: 0.5076 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9996 - dense_2_3_accuracy: 0.9987 - dense_2_4_accuracy: 0.9981 - dense_2_5_accuracy: 0.9971 - dense_2_6_accuracy: 0.9931 - dense_2_7_accuracy: 0.9886 - dense_2_8_accuracy: 0.9759 - dense_2_9_accuracy: 0.9521 - dense_2_10_accuracy: 0.9218 - dense_2_11_accuracy: 0.8621 - dense_2_12_accuracy: 0.7769 - dense_2_13_accuracy: 0.6748 - dense_2_14_accuracy: 0.5603 - dense_2_15_accuracy: 0.5190 - dense_2_16_accuracy: 0.5686 - dense_2_17_accuracy: 0.6366 - dense_2_18_accuracy: 0.7192 - dense_2_19_accuracy: 0.8558\n",
            "Epoch 14/40\n",
            "171/171 [==============================] - 13s 75ms/step - loss: 9.6299 - dense_2_loss: 0.0022 - dense_2_1_loss: 6.1549e-04 - dense_2_2_loss: 7.7609e-04 - dense_2_3_loss: 0.0042 - dense_2_4_loss: 0.0085 - dense_2_5_loss: 0.0110 - dense_2_6_loss: 0.0239 - dense_2_7_loss: 0.0423 - dense_2_8_loss: 0.0967 - dense_2_9_loss: 0.1613 - dense_2_10_loss: 0.2688 - dense_2_11_loss: 0.4669 - dense_2_12_loss: 0.7473 - dense_2_13_loss: 1.0399 - dense_2_14_loss: 1.3812 - dense_2_15_loss: 1.5066 - dense_2_16_loss: 1.3158 - dense_2_17_loss: 1.1926 - dense_2_18_loss: 0.8625 - dense_2_19_loss: 0.4969 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9993 - dense_2_4_accuracy: 0.9984 - dense_2_5_accuracy: 0.9976 - dense_2_6_accuracy: 0.9934 - dense_2_7_accuracy: 0.9890 - dense_2_8_accuracy: 0.9729 - dense_2_9_accuracy: 0.9540 - dense_2_10_accuracy: 0.9203 - dense_2_11_accuracy: 0.8613 - dense_2_12_accuracy: 0.7774 - dense_2_13_accuracy: 0.6876 - dense_2_14_accuracy: 0.5856 - dense_2_15_accuracy: 0.5507 - dense_2_16_accuracy: 0.5911 - dense_2_17_accuracy: 0.6382 - dense_2_18_accuracy: 0.7334 - dense_2_19_accuracy: 0.8584\n",
            "Epoch 15/40\n",
            "171/171 [==============================] - 13s 75ms/step - loss: 8.7884 - dense_2_loss: 0.0021 - dense_2_1_loss: 7.8057e-04 - dense_2_2_loss: 0.0011 - dense_2_3_loss: 0.0018 - dense_2_4_loss: 0.0060 - dense_2_5_loss: 0.0094 - dense_2_6_loss: 0.0288 - dense_2_7_loss: 0.0462 - dense_2_8_loss: 0.0888 - dense_2_9_loss: 0.1425 - dense_2_10_loss: 0.2475 - dense_2_11_loss: 0.4276 - dense_2_12_loss: 0.6998 - dense_2_13_loss: 0.9390 - dense_2_14_loss: 1.2856 - dense_2_15_loss: 1.3990 - dense_2_16_loss: 1.2165 - dense_2_17_loss: 1.0770 - dense_2_18_loss: 0.7412 - dense_2_19_loss: 0.4276 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9996 - dense_2_3_accuracy: 0.9995 - dense_2_4_accuracy: 0.9982 - dense_2_5_accuracy: 0.9973 - dense_2_6_accuracy: 0.9931 - dense_2_7_accuracy: 0.9879 - dense_2_8_accuracy: 0.9776 - dense_2_9_accuracy: 0.9605 - dense_2_10_accuracy: 0.9286 - dense_2_11_accuracy: 0.8729 - dense_2_12_accuracy: 0.7992 - dense_2_13_accuracy: 0.7217 - dense_2_14_accuracy: 0.6164 - dense_2_15_accuracy: 0.5864 - dense_2_16_accuracy: 0.6219 - dense_2_17_accuracy: 0.6755 - dense_2_18_accuracy: 0.7691 - dense_2_19_accuracy: 0.8793\n",
            "Epoch 16/40\n",
            "171/171 [==============================] - 13s 75ms/step - loss: 9.4528 - dense_2_loss: 0.0032 - dense_2_1_loss: 0.0012 - dense_2_2_loss: 0.0018 - dense_2_3_loss: 0.0065 - dense_2_4_loss: 0.0084 - dense_2_5_loss: 0.0143 - dense_2_6_loss: 0.0311 - dense_2_7_loss: 0.0442 - dense_2_8_loss: 0.0848 - dense_2_9_loss: 0.1473 - dense_2_10_loss: 0.2688 - dense_2_11_loss: 0.4587 - dense_2_12_loss: 0.7375 - dense_2_13_loss: 1.0056 - dense_2_14_loss: 1.3743 - dense_2_15_loss: 1.4947 - dense_2_16_loss: 1.3002 - dense_2_17_loss: 1.1227 - dense_2_18_loss: 0.8357 - dense_2_19_loss: 0.5115 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9995 - dense_2_3_accuracy: 0.9986 - dense_2_4_accuracy: 0.9982 - dense_2_5_accuracy: 0.9959 - dense_2_6_accuracy: 0.9915 - dense_2_7_accuracy: 0.9869 - dense_2_8_accuracy: 0.9771 - dense_2_9_accuracy: 0.9574 - dense_2_10_accuracy: 0.9256 - dense_2_11_accuracy: 0.8637 - dense_2_12_accuracy: 0.7782 - dense_2_13_accuracy: 0.6916 - dense_2_14_accuracy: 0.5756 - dense_2_15_accuracy: 0.5489 - dense_2_16_accuracy: 0.5829 - dense_2_17_accuracy: 0.6588 - dense_2_18_accuracy: 0.7415 - dense_2_19_accuracy: 0.8543\n",
            "Epoch 17/40\n",
            "171/171 [==============================] - 13s 75ms/step - loss: 8.4995 - dense_2_loss: 0.0025 - dense_2_1_loss: 0.0013 - dense_2_2_loss: 0.0019 - dense_2_3_loss: 0.0064 - dense_2_4_loss: 0.0088 - dense_2_5_loss: 0.0106 - dense_2_6_loss: 0.0291 - dense_2_7_loss: 0.0472 - dense_2_8_loss: 0.0825 - dense_2_9_loss: 0.1374 - dense_2_10_loss: 0.2454 - dense_2_11_loss: 0.4177 - dense_2_12_loss: 0.6767 - dense_2_13_loss: 0.9082 - dense_2_14_loss: 1.2377 - dense_2_15_loss: 1.3059 - dense_2_16_loss: 1.1779 - dense_2_17_loss: 0.9993 - dense_2_18_loss: 0.7293 - dense_2_19_loss: 0.4740 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9996 - dense_2_3_accuracy: 0.9985 - dense_2_4_accuracy: 0.9976 - dense_2_5_accuracy: 0.9970 - dense_2_6_accuracy: 0.9923 - dense_2_7_accuracy: 0.9874 - dense_2_8_accuracy: 0.9776 - dense_2_9_accuracy: 0.9598 - dense_2_10_accuracy: 0.9281 - dense_2_11_accuracy: 0.8793 - dense_2_12_accuracy: 0.7964 - dense_2_13_accuracy: 0.7199 - dense_2_14_accuracy: 0.6269 - dense_2_15_accuracy: 0.6111 - dense_2_16_accuracy: 0.6333 - dense_2_17_accuracy: 0.7030 - dense_2_18_accuracy: 0.7813 - dense_2_19_accuracy: 0.8732\n",
            "Epoch 18/40\n",
            "171/171 [==============================] - 13s 77ms/step - loss: 8.5824 - dense_2_loss: 0.0021 - dense_2_1_loss: 0.0018 - dense_2_2_loss: 0.0024 - dense_2_3_loss: 0.0038 - dense_2_4_loss: 0.0072 - dense_2_5_loss: 0.0102 - dense_2_6_loss: 0.0316 - dense_2_7_loss: 0.0528 - dense_2_8_loss: 0.0985 - dense_2_9_loss: 0.1650 - dense_2_10_loss: 0.2773 - dense_2_11_loss: 0.4461 - dense_2_12_loss: 0.6932 - dense_2_13_loss: 0.9294 - dense_2_14_loss: 1.2413 - dense_2_15_loss: 1.3354 - dense_2_16_loss: 1.1708 - dense_2_17_loss: 0.9874 - dense_2_18_loss: 0.7136 - dense_2_19_loss: 0.4124 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9997 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9993 - dense_2_4_accuracy: 0.9986 - dense_2_5_accuracy: 0.9975 - dense_2_6_accuracy: 0.9924 - dense_2_7_accuracy: 0.9859 - dense_2_8_accuracy: 0.9733 - dense_2_9_accuracy: 0.9536 - dense_2_10_accuracy: 0.9185 - dense_2_11_accuracy: 0.8678 - dense_2_12_accuracy: 0.7924 - dense_2_13_accuracy: 0.7156 - dense_2_14_accuracy: 0.6256 - dense_2_15_accuracy: 0.5940 - dense_2_16_accuracy: 0.6363 - dense_2_17_accuracy: 0.7019 - dense_2_18_accuracy: 0.7839 - dense_2_19_accuracy: 0.8797\n",
            "Epoch 19/40\n",
            "171/171 [==============================] - 13s 76ms/step - loss: 6.7041 - dense_2_loss: 0.0018 - dense_2_1_loss: 7.6282e-04 - dense_2_2_loss: 0.0010 - dense_2_3_loss: 0.0046 - dense_2_4_loss: 0.0057 - dense_2_5_loss: 0.0106 - dense_2_6_loss: 0.0241 - dense_2_7_loss: 0.0352 - dense_2_8_loss: 0.0724 - dense_2_9_loss: 0.1176 - dense_2_10_loss: 0.2055 - dense_2_11_loss: 0.3467 - dense_2_12_loss: 0.5529 - dense_2_13_loss: 0.7467 - dense_2_14_loss: 1.0472 - dense_2_15_loss: 1.1106 - dense_2_16_loss: 0.9625 - dense_2_17_loss: 0.7124 - dense_2_18_loss: 0.4703 - dense_2_19_loss: 0.2757 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9989 - dense_2_4_accuracy: 0.9985 - dense_2_5_accuracy: 0.9969 - dense_2_6_accuracy: 0.9930 - dense_2_7_accuracy: 0.9906 - dense_2_8_accuracy: 0.9797 - dense_2_9_accuracy: 0.9688 - dense_2_10_accuracy: 0.9417 - dense_2_11_accuracy: 0.8966 - dense_2_12_accuracy: 0.8456 - dense_2_13_accuracy: 0.7803 - dense_2_14_accuracy: 0.6875 - dense_2_15_accuracy: 0.6772 - dense_2_16_accuracy: 0.7051 - dense_2_17_accuracy: 0.7857 - dense_2_18_accuracy: 0.8613 - dense_2_19_accuracy: 0.9288\n",
            "Epoch 20/40\n",
            "171/171 [==============================] - 13s 76ms/step - loss: 7.0754 - dense_2_loss: 0.0017 - dense_2_1_loss: 0.0020 - dense_2_2_loss: 0.0027 - dense_2_3_loss: 0.0065 - dense_2_4_loss: 0.0087 - dense_2_5_loss: 0.0140 - dense_2_6_loss: 0.0247 - dense_2_7_loss: 0.0457 - dense_2_8_loss: 0.0702 - dense_2_9_loss: 0.1299 - dense_2_10_loss: 0.2317 - dense_2_11_loss: 0.3839 - dense_2_12_loss: 0.5915 - dense_2_13_loss: 0.7813 - dense_2_14_loss: 1.0667 - dense_2_15_loss: 1.1150 - dense_2_16_loss: 0.9787 - dense_2_17_loss: 0.7681 - dense_2_18_loss: 0.5390 - dense_2_19_loss: 0.3133 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9996 - dense_2_2_accuracy: 0.9995 - dense_2_3_accuracy: 0.9988 - dense_2_4_accuracy: 0.9978 - dense_2_5_accuracy: 0.9966 - dense_2_6_accuracy: 0.9936 - dense_2_7_accuracy: 0.9877 - dense_2_8_accuracy: 0.9789 - dense_2_9_accuracy: 0.9629 - dense_2_10_accuracy: 0.9305 - dense_2_11_accuracy: 0.8792 - dense_2_12_accuracy: 0.8285 - dense_2_13_accuracy: 0.7629 - dense_2_14_accuracy: 0.6728 - dense_2_15_accuracy: 0.6642 - dense_2_16_accuracy: 0.6951 - dense_2_17_accuracy: 0.7705 - dense_2_18_accuracy: 0.8414 - dense_2_19_accuracy: 0.9106\n",
            "Epoch 21/40\n",
            "171/171 [==============================] - 13s 76ms/step - loss: 6.2754 - dense_2_loss: 0.0013 - dense_2_1_loss: 5.1349e-04 - dense_2_2_loss: 0.0010 - dense_2_3_loss: 0.0061 - dense_2_4_loss: 0.0065 - dense_2_5_loss: 0.0094 - dense_2_6_loss: 0.0227 - dense_2_7_loss: 0.0358 - dense_2_8_loss: 0.0662 - dense_2_9_loss: 0.1220 - dense_2_10_loss: 0.2093 - dense_2_11_loss: 0.3415 - dense_2_12_loss: 0.5244 - dense_2_13_loss: 0.6999 - dense_2_14_loss: 0.9440 - dense_2_15_loss: 1.0218 - dense_2_16_loss: 0.8883 - dense_2_17_loss: 0.6458 - dense_2_18_loss: 0.4441 - dense_2_19_loss: 0.2847 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9989 - dense_2_4_accuracy: 0.9981 - dense_2_5_accuracy: 0.9975 - dense_2_6_accuracy: 0.9937 - dense_2_7_accuracy: 0.9900 - dense_2_8_accuracy: 0.9814 - dense_2_9_accuracy: 0.9662 - dense_2_10_accuracy: 0.9374 - dense_2_11_accuracy: 0.9018 - dense_2_12_accuracy: 0.8477 - dense_2_13_accuracy: 0.7997 - dense_2_14_accuracy: 0.7169 - dense_2_15_accuracy: 0.6958 - dense_2_16_accuracy: 0.7345 - dense_2_17_accuracy: 0.8131 - dense_2_18_accuracy: 0.8693 - dense_2_19_accuracy: 0.9257\n",
            "Epoch 22/40\n",
            "171/171 [==============================] - 13s 77ms/step - loss: 5.9441 - dense_2_loss: 0.0014 - dense_2_1_loss: 7.5109e-04 - dense_2_2_loss: 0.0011 - dense_2_3_loss: 0.0065 - dense_2_4_loss: 0.0084 - dense_2_5_loss: 0.0120 - dense_2_6_loss: 0.0209 - dense_2_7_loss: 0.0347 - dense_2_8_loss: 0.0577 - dense_2_9_loss: 0.1039 - dense_2_10_loss: 0.1781 - dense_2_11_loss: 0.3058 - dense_2_12_loss: 0.5067 - dense_2_13_loss: 0.6684 - dense_2_14_loss: 0.9084 - dense_2_15_loss: 0.9611 - dense_2_16_loss: 0.8270 - dense_2_17_loss: 0.6283 - dense_2_18_loss: 0.4367 - dense_2_19_loss: 0.2762 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9986 - dense_2_4_accuracy: 0.9973 - dense_2_5_accuracy: 0.9966 - dense_2_6_accuracy: 0.9936 - dense_2_7_accuracy: 0.9899 - dense_2_8_accuracy: 0.9832 - dense_2_9_accuracy: 0.9697 - dense_2_10_accuracy: 0.9489 - dense_2_11_accuracy: 0.9109 - dense_2_12_accuracy: 0.8542 - dense_2_13_accuracy: 0.8058 - dense_2_14_accuracy: 0.7243 - dense_2_15_accuracy: 0.7148 - dense_2_16_accuracy: 0.7538 - dense_2_17_accuracy: 0.8177 - dense_2_18_accuracy: 0.8731 - dense_2_19_accuracy: 0.9243\n",
            "Epoch 23/40\n",
            "171/171 [==============================] - 13s 77ms/step - loss: 6.3246 - dense_2_loss: 0.0012 - dense_2_1_loss: 7.4114e-04 - dense_2_2_loss: 9.5108e-04 - dense_2_3_loss: 0.0034 - dense_2_4_loss: 0.0050 - dense_2_5_loss: 0.0092 - dense_2_6_loss: 0.0222 - dense_2_7_loss: 0.0356 - dense_2_8_loss: 0.0681 - dense_2_9_loss: 0.1172 - dense_2_10_loss: 0.2071 - dense_2_11_loss: 0.3297 - dense_2_12_loss: 0.5343 - dense_2_13_loss: 0.7078 - dense_2_14_loss: 0.9496 - dense_2_15_loss: 1.0207 - dense_2_16_loss: 0.8799 - dense_2_17_loss: 0.6697 - dense_2_18_loss: 0.4498 - dense_2_19_loss: 0.3122 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9992 - dense_2_4_accuracy: 0.9989 - dense_2_5_accuracy: 0.9970 - dense_2_6_accuracy: 0.9938 - dense_2_7_accuracy: 0.9910 - dense_2_8_accuracy: 0.9800 - dense_2_9_accuracy: 0.9667 - dense_2_10_accuracy: 0.9358 - dense_2_11_accuracy: 0.9000 - dense_2_12_accuracy: 0.8452 - dense_2_13_accuracy: 0.7838 - dense_2_14_accuracy: 0.7113 - dense_2_15_accuracy: 0.6878 - dense_2_16_accuracy: 0.7379 - dense_2_17_accuracy: 0.8114 - dense_2_18_accuracy: 0.8753 - dense_2_19_accuracy: 0.9122\n",
            "Epoch 24/40\n",
            "171/171 [==============================] - 13s 76ms/step - loss: 5.6000 - dense_2_loss: 0.0013 - dense_2_1_loss: 0.0012 - dense_2_2_loss: 7.8628e-04 - dense_2_3_loss: 0.0032 - dense_2_4_loss: 0.0048 - dense_2_5_loss: 0.0123 - dense_2_6_loss: 0.0217 - dense_2_7_loss: 0.0360 - dense_2_8_loss: 0.0623 - dense_2_9_loss: 0.1084 - dense_2_10_loss: 0.1818 - dense_2_11_loss: 0.3066 - dense_2_12_loss: 0.4832 - dense_2_13_loss: 0.6171 - dense_2_14_loss: 0.8621 - dense_2_15_loss: 0.8903 - dense_2_16_loss: 0.7643 - dense_2_17_loss: 0.5840 - dense_2_18_loss: 0.4074 - dense_2_19_loss: 0.2513 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9997 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9992 - dense_2_4_accuracy: 0.9986 - dense_2_5_accuracy: 0.9969 - dense_2_6_accuracy: 0.9941 - dense_2_7_accuracy: 0.9889 - dense_2_8_accuracy: 0.9823 - dense_2_9_accuracy: 0.9689 - dense_2_10_accuracy: 0.9457 - dense_2_11_accuracy: 0.9061 - dense_2_12_accuracy: 0.8622 - dense_2_13_accuracy: 0.8176 - dense_2_14_accuracy: 0.7424 - dense_2_15_accuracy: 0.7328 - dense_2_16_accuracy: 0.7768 - dense_2_17_accuracy: 0.8372 - dense_2_18_accuracy: 0.8843 - dense_2_19_accuracy: 0.9332\n",
            "Epoch 25/40\n",
            "171/171 [==============================] - 13s 76ms/step - loss: 5.2889 - dense_2_loss: 8.6207e-04 - dense_2_1_loss: 3.7447e-04 - dense_2_2_loss: 7.1780e-04 - dense_2_3_loss: 0.0047 - dense_2_4_loss: 0.0054 - dense_2_5_loss: 0.0064 - dense_2_6_loss: 0.0224 - dense_2_7_loss: 0.0348 - dense_2_8_loss: 0.0655 - dense_2_9_loss: 0.1042 - dense_2_10_loss: 0.1735 - dense_2_11_loss: 0.2812 - dense_2_12_loss: 0.4449 - dense_2_13_loss: 0.6087 - dense_2_14_loss: 0.8186 - dense_2_15_loss: 0.8429 - dense_2_16_loss: 0.7229 - dense_2_17_loss: 0.5509 - dense_2_18_loss: 0.3677 - dense_2_19_loss: 0.2321 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9991 - dense_2_4_accuracy: 0.9988 - dense_2_5_accuracy: 0.9981 - dense_2_6_accuracy: 0.9940 - dense_2_7_accuracy: 0.9900 - dense_2_8_accuracy: 0.9811 - dense_2_9_accuracy: 0.9681 - dense_2_10_accuracy: 0.9497 - dense_2_11_accuracy: 0.9167 - dense_2_12_accuracy: 0.8739 - dense_2_13_accuracy: 0.8178 - dense_2_14_accuracy: 0.7559 - dense_2_15_accuracy: 0.7507 - dense_2_16_accuracy: 0.7909 - dense_2_17_accuracy: 0.8470 - dense_2_18_accuracy: 0.8992 - dense_2_19_accuracy: 0.9350\n",
            "Epoch 26/40\n",
            "171/171 [==============================] - 13s 76ms/step - loss: 4.9783 - dense_2_loss: 0.0011 - dense_2_1_loss: 0.0014 - dense_2_2_loss: 0.0017 - dense_2_3_loss: 0.0047 - dense_2_4_loss: 0.0063 - dense_2_5_loss: 0.0105 - dense_2_6_loss: 0.0192 - dense_2_7_loss: 0.0344 - dense_2_8_loss: 0.0570 - dense_2_9_loss: 0.0955 - dense_2_10_loss: 0.1648 - dense_2_11_loss: 0.2899 - dense_2_12_loss: 0.4594 - dense_2_13_loss: 0.5871 - dense_2_14_loss: 0.7590 - dense_2_15_loss: 0.7648 - dense_2_16_loss: 0.6530 - dense_2_17_loss: 0.4914 - dense_2_18_loss: 0.3503 - dense_2_19_loss: 0.2267 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9997 - dense_2_2_accuracy: 0.9996 - dense_2_3_accuracy: 0.9986 - dense_2_4_accuracy: 0.9977 - dense_2_5_accuracy: 0.9973 - dense_2_6_accuracy: 0.9943 - dense_2_7_accuracy: 0.9902 - dense_2_8_accuracy: 0.9842 - dense_2_9_accuracy: 0.9739 - dense_2_10_accuracy: 0.9492 - dense_2_11_accuracy: 0.9143 - dense_2_12_accuracy: 0.8682 - dense_2_13_accuracy: 0.8240 - dense_2_14_accuracy: 0.7766 - dense_2_15_accuracy: 0.7753 - dense_2_16_accuracy: 0.8123 - dense_2_17_accuracy: 0.8634 - dense_2_18_accuracy: 0.8998 - dense_2_19_accuracy: 0.9384\n",
            "Epoch 27/40\n",
            "171/171 [==============================] - 13s 77ms/step - loss: 6.1563 - dense_2_loss: 0.0010 - dense_2_1_loss: 8.2393e-04 - dense_2_2_loss: 0.0015 - dense_2_3_loss: 0.0048 - dense_2_4_loss: 0.0060 - dense_2_5_loss: 0.0127 - dense_2_6_loss: 0.0291 - dense_2_7_loss: 0.0429 - dense_2_8_loss: 0.0657 - dense_2_9_loss: 0.1212 - dense_2_10_loss: 0.2058 - dense_2_11_loss: 0.3267 - dense_2_12_loss: 0.5174 - dense_2_13_loss: 0.6784 - dense_2_14_loss: 0.8952 - dense_2_15_loss: 0.9627 - dense_2_16_loss: 0.8170 - dense_2_17_loss: 0.6716 - dense_2_18_loss: 0.4855 - dense_2_19_loss: 0.3105 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9988 - dense_2_4_accuracy: 0.9980 - dense_2_5_accuracy: 0.9972 - dense_2_6_accuracy: 0.9924 - dense_2_7_accuracy: 0.9886 - dense_2_8_accuracy: 0.9811 - dense_2_9_accuracy: 0.9636 - dense_2_10_accuracy: 0.9370 - dense_2_11_accuracy: 0.9026 - dense_2_12_accuracy: 0.8498 - dense_2_13_accuracy: 0.7951 - dense_2_14_accuracy: 0.7356 - dense_2_15_accuracy: 0.7085 - dense_2_16_accuracy: 0.7649 - dense_2_17_accuracy: 0.8078 - dense_2_18_accuracy: 0.8591 - dense_2_19_accuracy: 0.9108\n",
            "Epoch 28/40\n",
            "171/171 [==============================] - 13s 77ms/step - loss: 5.5051 - dense_2_loss: 0.0014 - dense_2_1_loss: 6.0215e-04 - dense_2_2_loss: 6.0420e-04 - dense_2_3_loss: 0.0039 - dense_2_4_loss: 0.0079 - dense_2_5_loss: 0.0159 - dense_2_6_loss: 0.0314 - dense_2_7_loss: 0.0453 - dense_2_8_loss: 0.0761 - dense_2_9_loss: 0.1022 - dense_2_10_loss: 0.1731 - dense_2_11_loss: 0.2823 - dense_2_12_loss: 0.4670 - dense_2_13_loss: 0.6122 - dense_2_14_loss: 0.8200 - dense_2_15_loss: 0.8561 - dense_2_16_loss: 0.7340 - dense_2_17_loss: 0.5778 - dense_2_18_loss: 0.4234 - dense_2_19_loss: 0.2740 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9992 - dense_2_4_accuracy: 0.9976 - dense_2_5_accuracy: 0.9962 - dense_2_6_accuracy: 0.9922 - dense_2_7_accuracy: 0.9878 - dense_2_8_accuracy: 0.9796 - dense_2_9_accuracy: 0.9716 - dense_2_10_accuracy: 0.9505 - dense_2_11_accuracy: 0.9122 - dense_2_12_accuracy: 0.8635 - dense_2_13_accuracy: 0.8154 - dense_2_14_accuracy: 0.7530 - dense_2_15_accuracy: 0.7538 - dense_2_16_accuracy: 0.7870 - dense_2_17_accuracy: 0.8395 - dense_2_18_accuracy: 0.8806 - dense_2_19_accuracy: 0.9254\n",
            "Epoch 29/40\n",
            "171/171 [==============================] - 13s 78ms/step - loss: 4.7901 - dense_2_loss: 8.3695e-04 - dense_2_1_loss: 8.2394e-04 - dense_2_2_loss: 0.0010 - dense_2_3_loss: 0.0046 - dense_2_4_loss: 0.0046 - dense_2_5_loss: 0.0098 - dense_2_6_loss: 0.0172 - dense_2_7_loss: 0.0306 - dense_2_8_loss: 0.0589 - dense_2_9_loss: 0.0955 - dense_2_10_loss: 0.1607 - dense_2_11_loss: 0.2585 - dense_2_12_loss: 0.3958 - dense_2_13_loss: 0.5589 - dense_2_14_loss: 0.7613 - dense_2_15_loss: 0.7545 - dense_2_16_loss: 0.6369 - dense_2_17_loss: 0.4896 - dense_2_18_loss: 0.3393 - dense_2_19_loss: 0.2109 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9991 - dense_2_4_accuracy: 0.9985 - dense_2_5_accuracy: 0.9977 - dense_2_6_accuracy: 0.9946 - dense_2_7_accuracy: 0.9919 - dense_2_8_accuracy: 0.9848 - dense_2_9_accuracy: 0.9753 - dense_2_10_accuracy: 0.9535 - dense_2_11_accuracy: 0.9249 - dense_2_12_accuracy: 0.8905 - dense_2_13_accuracy: 0.8334 - dense_2_14_accuracy: 0.7725 - dense_2_15_accuracy: 0.7819 - dense_2_16_accuracy: 0.8148 - dense_2_17_accuracy: 0.8639 - dense_2_18_accuracy: 0.9073 - dense_2_19_accuracy: 0.9439\n",
            "Epoch 30/40\n",
            "171/171 [==============================] - 13s 77ms/step - loss: 4.4867 - dense_2_loss: 8.1142e-04 - dense_2_1_loss: 5.9592e-04 - dense_2_2_loss: 0.0012 - dense_2_3_loss: 0.0043 - dense_2_4_loss: 0.0052 - dense_2_5_loss: 0.0130 - dense_2_6_loss: 0.0223 - dense_2_7_loss: 0.0408 - dense_2_8_loss: 0.0647 - dense_2_9_loss: 0.1034 - dense_2_10_loss: 0.1668 - dense_2_11_loss: 0.2560 - dense_2_12_loss: 0.4145 - dense_2_13_loss: 0.5411 - dense_2_14_loss: 0.7007 - dense_2_15_loss: 0.6981 - dense_2_16_loss: 0.5662 - dense_2_17_loss: 0.4134 - dense_2_18_loss: 0.2829 - dense_2_19_loss: 0.1906 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9989 - dense_2_4_accuracy: 0.9981 - dense_2_5_accuracy: 0.9966 - dense_2_6_accuracy: 0.9942 - dense_2_7_accuracy: 0.9882 - dense_2_8_accuracy: 0.9831 - dense_2_9_accuracy: 0.9685 - dense_2_10_accuracy: 0.9515 - dense_2_11_accuracy: 0.9251 - dense_2_12_accuracy: 0.8813 - dense_2_13_accuracy: 0.8436 - dense_2_14_accuracy: 0.7927 - dense_2_15_accuracy: 0.8025 - dense_2_16_accuracy: 0.8330 - dense_2_17_accuracy: 0.8871 - dense_2_18_accuracy: 0.9208 - dense_2_19_accuracy: 0.9492\n",
            "Epoch 31/40\n",
            "171/171 [==============================] - 13s 78ms/step - loss: 4.3938 - dense_2_loss: 0.0011 - dense_2_1_loss: 0.0011 - dense_2_2_loss: 0.0015 - dense_2_3_loss: 0.0047 - dense_2_4_loss: 0.0078 - dense_2_5_loss: 0.0111 - dense_2_6_loss: 0.0258 - dense_2_7_loss: 0.0406 - dense_2_8_loss: 0.0647 - dense_2_9_loss: 0.1063 - dense_2_10_loss: 0.1689 - dense_2_11_loss: 0.2423 - dense_2_12_loss: 0.4095 - dense_2_13_loss: 0.5139 - dense_2_14_loss: 0.6905 - dense_2_15_loss: 0.6709 - dense_2_16_loss: 0.5531 - dense_2_17_loss: 0.3986 - dense_2_18_loss: 0.2954 - dense_2_19_loss: 0.1862 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9988 - dense_2_4_accuracy: 0.9979 - dense_2_5_accuracy: 0.9969 - dense_2_6_accuracy: 0.9927 - dense_2_7_accuracy: 0.9898 - dense_2_8_accuracy: 0.9825 - dense_2_9_accuracy: 0.9707 - dense_2_10_accuracy: 0.9533 - dense_2_11_accuracy: 0.9275 - dense_2_12_accuracy: 0.8851 - dense_2_13_accuracy: 0.8548 - dense_2_14_accuracy: 0.7974 - dense_2_15_accuracy: 0.8077 - dense_2_16_accuracy: 0.8389 - dense_2_17_accuracy: 0.8880 - dense_2_18_accuracy: 0.9127 - dense_2_19_accuracy: 0.9498\n",
            "Epoch 32/40\n",
            "171/171 [==============================] - 13s 78ms/step - loss: 4.9480 - dense_2_loss: 8.5928e-04 - dense_2_1_loss: 9.6451e-04 - dense_2_2_loss: 0.0011 - dense_2_3_loss: 0.0060 - dense_2_4_loss: 0.0059 - dense_2_5_loss: 0.0103 - dense_2_6_loss: 0.0250 - dense_2_7_loss: 0.0410 - dense_2_8_loss: 0.0664 - dense_2_9_loss: 0.1086 - dense_2_10_loss: 0.1783 - dense_2_11_loss: 0.2766 - dense_2_12_loss: 0.4248 - dense_2_13_loss: 0.5530 - dense_2_14_loss: 0.7438 - dense_2_15_loss: 0.7632 - dense_2_16_loss: 0.6355 - dense_2_17_loss: 0.4999 - dense_2_18_loss: 0.3659 - dense_2_19_loss: 0.2408 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9996 - dense_2_3_accuracy: 0.9983 - dense_2_4_accuracy: 0.9987 - dense_2_5_accuracy: 0.9967 - dense_2_6_accuracy: 0.9928 - dense_2_7_accuracy: 0.9887 - dense_2_8_accuracy: 0.9798 - dense_2_9_accuracy: 0.9700 - dense_2_10_accuracy: 0.9464 - dense_2_11_accuracy: 0.9190 - dense_2_12_accuracy: 0.8770 - dense_2_13_accuracy: 0.8377 - dense_2_14_accuracy: 0.7848 - dense_2_15_accuracy: 0.7796 - dense_2_16_accuracy: 0.8131 - dense_2_17_accuracy: 0.8640 - dense_2_18_accuracy: 0.8939 - dense_2_19_accuracy: 0.9333\n",
            "Epoch 33/40\n",
            "171/171 [==============================] - 13s 78ms/step - loss: 3.8088 - dense_2_loss: 7.5808e-04 - dense_2_1_loss: 1.8256e-04 - dense_2_2_loss: 5.7731e-04 - dense_2_3_loss: 0.0043 - dense_2_4_loss: 0.0075 - dense_2_5_loss: 0.0128 - dense_2_6_loss: 0.0233 - dense_2_7_loss: 0.0374 - dense_2_8_loss: 0.0569 - dense_2_9_loss: 0.0910 - dense_2_10_loss: 0.1381 - dense_2_11_loss: 0.2316 - dense_2_12_loss: 0.3319 - dense_2_13_loss: 0.4529 - dense_2_14_loss: 0.5904 - dense_2_15_loss: 0.5890 - dense_2_16_loss: 0.4799 - dense_2_17_loss: 0.3608 - dense_2_18_loss: 0.2437 - dense_2_19_loss: 0.1557 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9991 - dense_2_4_accuracy: 0.9983 - dense_2_5_accuracy: 0.9964 - dense_2_6_accuracy: 0.9942 - dense_2_7_accuracy: 0.9895 - dense_2_8_accuracy: 0.9831 - dense_2_9_accuracy: 0.9761 - dense_2_10_accuracy: 0.9614 - dense_2_11_accuracy: 0.9336 - dense_2_12_accuracy: 0.9087 - dense_2_13_accuracy: 0.8699 - dense_2_14_accuracy: 0.8281 - dense_2_15_accuracy: 0.8321 - dense_2_16_accuracy: 0.8617 - dense_2_17_accuracy: 0.8980 - dense_2_18_accuracy: 0.9337 - dense_2_19_accuracy: 0.9605\n",
            "Epoch 34/40\n",
            "171/171 [==============================] - 13s 78ms/step - loss: 3.7459 - dense_2_loss: 6.0232e-04 - dense_2_1_loss: 4.2678e-04 - dense_2_2_loss: 7.2624e-04 - dense_2_3_loss: 0.0036 - dense_2_4_loss: 0.0035 - dense_2_5_loss: 0.0096 - dense_2_6_loss: 0.0183 - dense_2_7_loss: 0.0291 - dense_2_8_loss: 0.0492 - dense_2_9_loss: 0.0876 - dense_2_10_loss: 0.1374 - dense_2_11_loss: 0.2210 - dense_2_12_loss: 0.3325 - dense_2_13_loss: 0.4348 - dense_2_14_loss: 0.5804 - dense_2_15_loss: 0.5834 - dense_2_16_loss: 0.4701 - dense_2_17_loss: 0.3645 - dense_2_18_loss: 0.2534 - dense_2_19_loss: 0.1657 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9995 - dense_2_4_accuracy: 0.9991 - dense_2_5_accuracy: 0.9981 - dense_2_6_accuracy: 0.9953 - dense_2_7_accuracy: 0.9913 - dense_2_8_accuracy: 0.9872 - dense_2_9_accuracy: 0.9771 - dense_2_10_accuracy: 0.9607 - dense_2_11_accuracy: 0.9361 - dense_2_12_accuracy: 0.9073 - dense_2_13_accuracy: 0.8814 - dense_2_14_accuracy: 0.8350 - dense_2_15_accuracy: 0.8318 - dense_2_16_accuracy: 0.8699 - dense_2_17_accuracy: 0.8989 - dense_2_18_accuracy: 0.9275 - dense_2_19_accuracy: 0.9559\n",
            "Epoch 35/40\n",
            "171/171 [==============================] - 13s 78ms/step - loss: 3.9016 - dense_2_loss: 9.0730e-04 - dense_2_1_loss: 8.1086e-04 - dense_2_2_loss: 0.0019 - dense_2_3_loss: 0.0043 - dense_2_4_loss: 0.0072 - dense_2_5_loss: 0.0139 - dense_2_6_loss: 0.0239 - dense_2_7_loss: 0.0363 - dense_2_8_loss: 0.0620 - dense_2_9_loss: 0.0951 - dense_2_10_loss: 0.1456 - dense_2_11_loss: 0.2240 - dense_2_12_loss: 0.3400 - dense_2_13_loss: 0.4585 - dense_2_14_loss: 0.5960 - dense_2_15_loss: 0.5937 - dense_2_16_loss: 0.4978 - dense_2_17_loss: 0.3606 - dense_2_18_loss: 0.2662 - dense_2_19_loss: 0.1729 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9996 - dense_2_3_accuracy: 0.9990 - dense_2_4_accuracy: 0.9975 - dense_2_5_accuracy: 0.9967 - dense_2_6_accuracy: 0.9946 - dense_2_7_accuracy: 0.9899 - dense_2_8_accuracy: 0.9839 - dense_2_9_accuracy: 0.9748 - dense_2_10_accuracy: 0.9586 - dense_2_11_accuracy: 0.9383 - dense_2_12_accuracy: 0.9037 - dense_2_13_accuracy: 0.8725 - dense_2_14_accuracy: 0.8252 - dense_2_15_accuracy: 0.8336 - dense_2_16_accuracy: 0.8559 - dense_2_17_accuracy: 0.8991 - dense_2_18_accuracy: 0.9247 - dense_2_19_accuracy: 0.9523\n",
            "Epoch 36/40\n",
            "171/171 [==============================] - 13s 78ms/step - loss: 3.7723 - dense_2_loss: 5.2384e-04 - dense_2_1_loss: 0.0012 - dense_2_2_loss: 0.0019 - dense_2_3_loss: 0.0028 - dense_2_4_loss: 0.0053 - dense_2_5_loss: 0.0082 - dense_2_6_loss: 0.0203 - dense_2_7_loss: 0.0305 - dense_2_8_loss: 0.0461 - dense_2_9_loss: 0.0887 - dense_2_10_loss: 0.1419 - dense_2_11_loss: 0.2237 - dense_2_12_loss: 0.3530 - dense_2_13_loss: 0.4597 - dense_2_14_loss: 0.6113 - dense_2_15_loss: 0.5799 - dense_2_16_loss: 0.4877 - dense_2_17_loss: 0.3400 - dense_2_18_loss: 0.2282 - dense_2_19_loss: 0.1415 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9997 - dense_2_2_accuracy: 0.9995 - dense_2_3_accuracy: 0.9992 - dense_2_4_accuracy: 0.9983 - dense_2_5_accuracy: 0.9975 - dense_2_6_accuracy: 0.9945 - dense_2_7_accuracy: 0.9928 - dense_2_8_accuracy: 0.9882 - dense_2_9_accuracy: 0.9778 - dense_2_10_accuracy: 0.9618 - dense_2_11_accuracy: 0.9369 - dense_2_12_accuracy: 0.9010 - dense_2_13_accuracy: 0.8713 - dense_2_14_accuracy: 0.8306 - dense_2_15_accuracy: 0.8327 - dense_2_16_accuracy: 0.8695 - dense_2_17_accuracy: 0.9057 - dense_2_18_accuracy: 0.9386 - dense_2_19_accuracy: 0.9622\n",
            "Epoch 37/40\n",
            "171/171 [==============================] - 13s 78ms/step - loss: 3.6489 - dense_2_loss: 7.6831e-04 - dense_2_1_loss: 0.0014 - dense_2_2_loss: 0.0026 - dense_2_3_loss: 0.0037 - dense_2_4_loss: 0.0064 - dense_2_5_loss: 0.0123 - dense_2_6_loss: 0.0203 - dense_2_7_loss: 0.0299 - dense_2_8_loss: 0.0508 - dense_2_9_loss: 0.0788 - dense_2_10_loss: 0.1260 - dense_2_11_loss: 0.2061 - dense_2_12_loss: 0.3062 - dense_2_13_loss: 0.4075 - dense_2_14_loss: 0.5524 - dense_2_15_loss: 0.5600 - dense_2_16_loss: 0.4645 - dense_2_17_loss: 0.3670 - dense_2_18_loss: 0.2789 - dense_2_19_loss: 0.1732 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9997 - dense_2_2_accuracy: 0.9995 - dense_2_3_accuracy: 0.9988 - dense_2_4_accuracy: 0.9984 - dense_2_5_accuracy: 0.9969 - dense_2_6_accuracy: 0.9937 - dense_2_7_accuracy: 0.9913 - dense_2_8_accuracy: 0.9872 - dense_2_9_accuracy: 0.9782 - dense_2_10_accuracy: 0.9634 - dense_2_11_accuracy: 0.9429 - dense_2_12_accuracy: 0.9137 - dense_2_13_accuracy: 0.8864 - dense_2_14_accuracy: 0.8426 - dense_2_15_accuracy: 0.8395 - dense_2_16_accuracy: 0.8715 - dense_2_17_accuracy: 0.9029 - dense_2_18_accuracy: 0.9239 - dense_2_19_accuracy: 0.9546\n",
            "Epoch 38/40\n",
            "171/171 [==============================] - 13s 78ms/step - loss: 3.3288 - dense_2_loss: 8.5205e-04 - dense_2_1_loss: 5.8582e-04 - dense_2_2_loss: 5.7452e-04 - dense_2_3_loss: 0.0042 - dense_2_4_loss: 0.0065 - dense_2_5_loss: 0.0110 - dense_2_6_loss: 0.0191 - dense_2_7_loss: 0.0302 - dense_2_8_loss: 0.0453 - dense_2_9_loss: 0.0810 - dense_2_10_loss: 0.1271 - dense_2_11_loss: 0.2097 - dense_2_12_loss: 0.3032 - dense_2_13_loss: 0.3891 - dense_2_14_loss: 0.5060 - dense_2_15_loss: 0.5159 - dense_2_16_loss: 0.4118 - dense_2_17_loss: 0.3074 - dense_2_18_loss: 0.2239 - dense_2_19_loss: 0.1351 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9989 - dense_2_4_accuracy: 0.9980 - dense_2_5_accuracy: 0.9964 - dense_2_6_accuracy: 0.9942 - dense_2_7_accuracy: 0.9911 - dense_2_8_accuracy: 0.9879 - dense_2_9_accuracy: 0.9777 - dense_2_10_accuracy: 0.9641 - dense_2_11_accuracy: 0.9431 - dense_2_12_accuracy: 0.9177 - dense_2_13_accuracy: 0.8937 - dense_2_14_accuracy: 0.8599 - dense_2_15_accuracy: 0.8542 - dense_2_16_accuracy: 0.8804 - dense_2_17_accuracy: 0.9177 - dense_2_18_accuracy: 0.9401 - dense_2_19_accuracy: 0.9603\n",
            "Epoch 39/40\n",
            "171/171 [==============================] - 13s 77ms/step - loss: 3.5951 - dense_2_loss: 7.6937e-04 - dense_2_1_loss: 9.8178e-04 - dense_2_2_loss: 0.0014 - dense_2_3_loss: 0.0056 - dense_2_4_loss: 0.0072 - dense_2_5_loss: 0.0140 - dense_2_6_loss: 0.0181 - dense_2_7_loss: 0.0322 - dense_2_8_loss: 0.0521 - dense_2_9_loss: 0.0877 - dense_2_10_loss: 0.1388 - dense_2_11_loss: 0.2253 - dense_2_12_loss: 0.3300 - dense_2_13_loss: 0.4311 - dense_2_14_loss: 0.5710 - dense_2_15_loss: 0.5377 - dense_2_16_loss: 0.4565 - dense_2_17_loss: 0.3115 - dense_2_18_loss: 0.2354 - dense_2_19_loss: 0.1379 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9987 - dense_2_4_accuracy: 0.9984 - dense_2_5_accuracy: 0.9964 - dense_2_6_accuracy: 0.9939 - dense_2_7_accuracy: 0.9912 - dense_2_8_accuracy: 0.9856 - dense_2_9_accuracy: 0.9767 - dense_2_10_accuracy: 0.9623 - dense_2_11_accuracy: 0.9372 - dense_2_12_accuracy: 0.9085 - dense_2_13_accuracy: 0.8816 - dense_2_14_accuracy: 0.8349 - dense_2_15_accuracy: 0.8491 - dense_2_16_accuracy: 0.8682 - dense_2_17_accuracy: 0.9142 - dense_2_18_accuracy: 0.9316 - dense_2_19_accuracy: 0.9640\n",
            "Epoch 40/40\n",
            "171/171 [==============================] - 13s 79ms/step - loss: 3.6947 - dense_2_loss: 8.0168e-04 - dense_2_1_loss: 0.0011 - dense_2_2_loss: 7.6216e-04 - dense_2_3_loss: 0.0050 - dense_2_4_loss: 0.0058 - dense_2_5_loss: 0.0085 - dense_2_6_loss: 0.0216 - dense_2_7_loss: 0.0314 - dense_2_8_loss: 0.0499 - dense_2_9_loss: 0.0799 - dense_2_10_loss: 0.1327 - dense_2_11_loss: 0.2138 - dense_2_12_loss: 0.3192 - dense_2_13_loss: 0.4493 - dense_2_14_loss: 0.5674 - dense_2_15_loss: 0.5703 - dense_2_16_loss: 0.4610 - dense_2_17_loss: 0.3561 - dense_2_18_loss: 0.2649 - dense_2_19_loss: 0.1552 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9984 - dense_2_4_accuracy: 0.9983 - dense_2_5_accuracy: 0.9977 - dense_2_6_accuracy: 0.9941 - dense_2_7_accuracy: 0.9913 - dense_2_8_accuracy: 0.9852 - dense_2_9_accuracy: 0.9781 - dense_2_10_accuracy: 0.9661 - dense_2_11_accuracy: 0.9398 - dense_2_12_accuracy: 0.9128 - dense_2_13_accuracy: 0.8792 - dense_2_14_accuracy: 0.8442 - dense_2_15_accuracy: 0.8351 - dense_2_16_accuracy: 0.8715 - dense_2_17_accuracy: 0.9049 - dense_2_18_accuracy: 0.9269 - dense_2_19_accuracy: 0.9588\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fba90101610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C2RET9GwXDh"
      },
      "source": [
        "# Thai-Script to Roman-Script Translation\n",
        "* Task 4: Test your model on 5 examples of your choice including your name! (1 point)\n",
        "* Task 5: Show your visualization of attention scores on one of your example (1 point)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dvr8zVctSUr7",
        "outputId": "b83cb5ef-bbbe-49d1-9a87-4dc669a53a43"
      },
      "source": [
        "def prep_input(input_list):\n",
        "    prep = []\n",
        "    for line in input_list:\n",
        "        temp = []\n",
        "        for char in line:\n",
        "            temp.append(input_char_idx[char])\n",
        "        prep.append(temp)\n",
        "    prep = pad_sequences(prep, maxlen=max_input)\n",
        "    prep = to_categorical(prep, input_vocab_size)\n",
        "    return prep\n",
        "\n",
        "\n",
        "ex = [\"ธีระ\", \"ธีรา\", \"ธีรธรรม\", \"ธรรมธร\", \"ธรรมกร\"]\n",
        "isin = [ name in name_th for name in ex]\n",
        "\n",
        "s0 = np.zeros((len(ex), n_s))\n",
        "c0 = np.zeros((len(ex), n_s))\n",
        "prep = prep_input(ex)\n",
        "\n",
        "prediction_a = model.predict([prep, s0, c0])\n",
        "prediction_b = np.swapaxes(prediction_a, 0, 1)\n",
        "prediction = np.argmax(prediction_b, axis=-1)\n",
        "for j in range(len(prediction)):\n",
        "    output = (\"\".join([output_idx_char[int(i)] for i in prediction[j]])).strip(\"<PAD>\")\n",
        "    print(isin[j], ex[j], output)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True ธีระ thhirak\n",
            "False ธีรา thirak\n",
            "False ธีรธรรม thirathamm\n",
            "False ธรรมธร thamthonn\n",
            "False ธรรมกร thamkonn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9-mxbsKwXDp"
      },
      "source": [
        "### Plot the attention map\n",
        "* If you need to install thai font: sudo apt install xfonts-thai\n",
        "* this is what your visualization might look like:\n",
        "<img src=\"https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/images/attn_viz_sample.png\"  style=\"width: 350px;\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRL8hHaLwXDq"
      },
      "source": [
        "#task 5\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['font.family']='TH Sarabun New'  #you can change to other font that works for you\n",
        "#fill your code here"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOq8vFSkR2BU"
      },
      "source": [
        "model_att = Model(inputs=model.inputs, outputs=[model.outputs, [model.get_layer('attention_scores').get_output_at(e) for e in range(max_output)]])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymnlnlHPRgpX"
      },
      "source": [
        "ex_name = \"ธรรมกร\"\n",
        "ex_name_pad = [\"<PAD>\" for i in range(max_input-len(ex_name))]+list(ex_name)\n",
        "prep_name = prep_input([ex_name])\n",
        "s0 = np.zeros((len(prep_name), n_s))\n",
        "c0 = np.zeros((len(prep_name), n_s))\n",
        "\n",
        "pred_name = model_att.predict([prep_name, s0, c0])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_jWtbv9SW3o",
        "outputId": "67a131d8-0d33-433b-aff3-2df524ab1ef1"
      },
      "source": [
        "pred_name_out = np.swapaxes(pred_name[0], 0, 1)\n",
        "pred_name_out = np.argmax(pred_name_out, axis=-1)\n",
        "\n",
        "output = [output_idx_char[int(i)] for i in pred_name_out[0]]\n",
        "print(\"\".join(ex_name_pad))\n",
        "print(\"\".join(output))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>ธรรมกร\n",
            "<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>thamkonn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XreV4yRFdUoJ"
      },
      "source": [
        "attention_score = np.array(pred_name[1])\n",
        "attention_score = attention_score.reshape(20, 20)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "RjAN_6MshQ2T",
        "outputId": "dc2bf668-6a84-46b3-de28-d89b2b110769"
      },
      "source": [
        "sns.heatmap(attention_score, xticklabels=ex_name_pad, yticklabels=output ,linewidths=0.01)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb9b0b91d10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}