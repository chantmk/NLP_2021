{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HW_KeyValueAttention_TH2EN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chantmk/NLP_2021/blob/main/HW8/HW_KeyValueAttention_TH2EN_finished.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1cDcKRZwXCL"
      },
      "source": [
        "# Key-Value Attention Mechanism Homework on Keras: Character-level Machine Translation (Many-to-Many, encoder-decoder)\n",
        "\n",
        "In this homework, you will create an MT model with key-value attention mechnism that coverts names of constituency MP candidates in the 2019 Thai general election from Thai script to Roman(Latin) script. E.g. นิยม-->niyom "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy6QYsP4wa-k",
        "outputId": "2525f01d-772c-4195-ef32-33a4f11a0e88"
      },
      "source": [
        "!wget https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import matplotlib as mpl\n",
        "mpl.font_manager.fontManager.addfont('thsarabunnew-webfont.ttf') # 3.2+\n",
        "mpl.rc('font', family='TH Sarabun New')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-21 02:16:31--  https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Phonbopit/sarabun-webfont/master/fonts/thsarabunnew-webfont.ttf [following]\n",
            "--2021-03-21 02:16:31--  https://raw.githubusercontent.com/Phonbopit/sarabun-webfont/master/fonts/thsarabunnew-webfont.ttf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 98308 (96K) [application/octet-stream]\n",
            "Saving to: ‘thsarabunnew-webfont.ttf’\n",
            "\n",
            "\rthsarabunnew-webfon   0%[                    ]       0  --.-KB/s               \rthsarabunnew-webfon 100%[===================>]  96.00K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2021-03-21 02:16:32 (33.3 MB/s) - ‘thsarabunnew-webfont.ttf’ saved [98308/98308]\n",
            "\n",
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRdbTrQJwXCR"
      },
      "source": [
        "%matplotlib inline\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
        "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq20keO6wXCh"
      },
      "source": [
        "## Load Dataset\n",
        "We have generated a toy dataset using names of constituency MP candidates in 2019 Thai General Election from elect.in.th's github(https://github.com/codeforthailand/dataset-election-62-candidates) and tltk (https://pypi.org/project/tltk/) library to convert them into Roman script.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/images/dataset_diagram.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8lWBh40wjgz",
        "outputId": "6c470e8f-4618-4aa4-a3d1-d36a62af68ff"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/mp_name_th_en.csv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-21 02:16:33--  https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/mp_name_th_en.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 324399 (317K) [text/plain]\n",
            "Saving to: ‘mp_name_th_en.csv’\n",
            "\n",
            "\rmp_name_th_en.csv     0%[                    ]       0  --.-KB/s               \rmp_name_th_en.csv   100%[===================>] 316.80K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2021-03-21 02:16:33 (48.5 MB/s) - ‘mp_name_th_en.csv’ saved [324399/324399]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTQk8W4OwXCk"
      },
      "source": [
        "import csv\n",
        "with open('mp_name_th_en.csv') as csvfile:\n",
        "    readCSV = csv.reader(csvfile, delimiter=',')\n",
        "    name_th = []\n",
        "    name_en = []\n",
        "    for row in readCSV:\n",
        "        name_th.append(row[0].strip())\n",
        "        name_en.append(row[1].strip())"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVNHVM_FwXCs",
        "outputId": "def36e8a-bc41-47ec-9e51-57e94a2511bb"
      },
      "source": [
        "for th, en in zip(name_th[:10],name_en[:10]):\n",
        "    print(th,en)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ไกรสีห์ kraisi\n",
            "พัชรี phatri\n",
            "ธีระ thira\n",
            "วุฒิกร wutthikon\n",
            "ไสว sawai\n",
            "สัมภาษณ์ samphat\n",
            "วศิน wasin\n",
            "ทินวัฒน์ thinwat\n",
            "ศักดินัย sakdinai\n",
            "สุรศักดิ์ surasak\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heMTiM7qwXC2"
      },
      "source": [
        "## Task1: Preprocess dataset for Keras (1 point)\n",
        "* 2 dictionaries for indexing (1 for input and another for output)\n",
        "* DON'T FORGET TO INCLUDE special token for padding\n",
        "* DON'T FORGET TO INCLUDE special token for the end of word symbol (output)\n",
        "* Be mindful of your pad_sequences \"padding\" hyperparameter. Choose wisely (post-padding vs pre-padding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O5YhjntwXC4",
        "outputId": "7e3ff976-9c16-43a0-fcb7-d513d116f5df"
      },
      "source": [
        "input_char_th = sorted(list(set(''.join(name_th))))\n",
        "output_char_en = sorted(list(set(''.join(name_en))))\n",
        "input_char_th.insert(0, \"<PAD>\")\n",
        "output_char_en = [\"<PAD>\", \"</s>\"] + output_char_en\n",
        "print(input_char_th)\n",
        "print(output_char_en)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<PAD>', 'ก', 'ข', 'ค', 'ฆ', 'ง', 'จ', 'ฉ', 'ช', 'ซ', 'ฌ', 'ญ', 'ฎ', 'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท', 'ธ', 'น', 'บ', 'ป', 'ผ', 'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ล', 'ว', 'ศ', 'ษ', 'ส', 'ห', 'ฬ', 'อ', 'ฮ', 'ะ', 'ั', 'า', 'ำ', 'ิ', 'ี', 'ึ', 'ื', 'ุ', 'ู', 'เ', 'แ', 'โ', 'ใ', 'ไ', '็', '่', '้', '๊', '๋', '์']\n",
            "['<PAD>', '</s>', '-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'w', 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaaGc5WssEnA",
        "outputId": "5d7035d1-3762-4e45-b583-d7df6f909a49"
      },
      "source": [
        "input_char_idx = { char:index for index, char in enumerate(input_char_th)}\n",
        "input_idx_char = { index:char for index, char in enumerate(input_char_th)}\n",
        "\n",
        "output_char_idx = { char:index for index, char in enumerate(output_char_en)}\n",
        "output_idx_char = { index:char for index, char in enumerate(output_char_en)}\n",
        "\n",
        "print(\"Input map-----\")\n",
        "print(input_char_idx)\n",
        "print(input_idx_char)\n",
        "print(len(input_char_idx), len(input_idx_char))\n",
        "print(\"Output map----\")\n",
        "print(output_char_idx)\n",
        "print(output_idx_char)\n",
        "print(len(output_char_idx), len(output_idx_char))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input map-----\n",
            "{'<PAD>': 0, 'ก': 1, 'ข': 2, 'ค': 3, 'ฆ': 4, 'ง': 5, 'จ': 6, 'ฉ': 7, 'ช': 8, 'ซ': 9, 'ฌ': 10, 'ญ': 11, 'ฎ': 12, 'ฏ': 13, 'ฐ': 14, 'ฑ': 15, 'ฒ': 16, 'ณ': 17, 'ด': 18, 'ต': 19, 'ถ': 20, 'ท': 21, 'ธ': 22, 'น': 23, 'บ': 24, 'ป': 25, 'ผ': 26, 'ฝ': 27, 'พ': 28, 'ฟ': 29, 'ภ': 30, 'ม': 31, 'ย': 32, 'ร': 33, 'ล': 34, 'ว': 35, 'ศ': 36, 'ษ': 37, 'ส': 38, 'ห': 39, 'ฬ': 40, 'อ': 41, 'ฮ': 42, 'ะ': 43, 'ั': 44, 'า': 45, 'ำ': 46, 'ิ': 47, 'ี': 48, 'ึ': 49, 'ื': 50, 'ุ': 51, 'ู': 52, 'เ': 53, 'แ': 54, 'โ': 55, 'ใ': 56, 'ไ': 57, '็': 58, '่': 59, '้': 60, '๊': 61, '๋': 62, '์': 63}\n",
            "{0: '<PAD>', 1: 'ก', 2: 'ข', 3: 'ค', 4: 'ฆ', 5: 'ง', 6: 'จ', 7: 'ฉ', 8: 'ช', 9: 'ซ', 10: 'ฌ', 11: 'ญ', 12: 'ฎ', 13: 'ฏ', 14: 'ฐ', 15: 'ฑ', 16: 'ฒ', 17: 'ณ', 18: 'ด', 19: 'ต', 20: 'ถ', 21: 'ท', 22: 'ธ', 23: 'น', 24: 'บ', 25: 'ป', 26: 'ผ', 27: 'ฝ', 28: 'พ', 29: 'ฟ', 30: 'ภ', 31: 'ม', 32: 'ย', 33: 'ร', 34: 'ล', 35: 'ว', 36: 'ศ', 37: 'ษ', 38: 'ส', 39: 'ห', 40: 'ฬ', 41: 'อ', 42: 'ฮ', 43: 'ะ', 44: 'ั', 45: 'า', 46: 'ำ', 47: 'ิ', 48: 'ี', 49: 'ึ', 50: 'ื', 51: 'ุ', 52: 'ู', 53: 'เ', 54: 'แ', 55: 'โ', 56: 'ใ', 57: 'ไ', 58: '็', 59: '่', 60: '้', 61: '๊', 62: '๋', 63: '์'}\n",
            "64 64\n",
            "Output map----\n",
            "{'<PAD>': 0, '</s>': 1, '-': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'k': 12, 'l': 13, 'm': 14, 'n': 15, 'o': 16, 'p': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'w': 22, 'y': 23}\n",
            "{0: '<PAD>', 1: '</s>', 2: '-', 3: 'a', 4: 'b', 5: 'c', 6: 'd', 7: 'e', 8: 'f', 9: 'g', 10: 'h', 11: 'i', 12: 'k', 13: 'l', 14: 'm', 15: 'n', 16: 'o', 17: 'p', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'w', 23: 'y'}\n",
            "24 24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1jh649Qsxrj",
        "outputId": "5559b304-ca3d-4fb1-9505-bdeb9cb46dc9"
      },
      "source": [
        "max_input = len(max(name_th, key=len))\n",
        "max_output = len(max(name_en, key=len))+1\n",
        "\n",
        "x = [[input_char_idx[char] for char in name] for name in name_th]\n",
        "y = [[output_char_idx[char] for char in name] for name in name_en]\n",
        "print(x[:3], \"\\n-----\")\n",
        "\n",
        "x = pad_sequences(x, maxlen=max_input)\n",
        "y = pad_sequences(y, maxlen=max_output)\n",
        "print(x.shape)\n",
        "print(x[:3], \"\\n-----\")\n",
        "\n",
        "input_vocab_size = len(input_char_idx)\n",
        "output_vocab_size = len(output_char_idx)\n",
        "print(input_vocab_size)\n",
        "print(output_vocab_size)\n",
        "x = to_categorical(x, input_vocab_size)\n",
        "y = to_categorical(y, output_vocab_size)\n",
        "print(x.shape)\n",
        "print(x[:3], \"\\n-----\")\n",
        "\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[57, 1, 33, 38, 48, 39, 63], [28, 44, 8, 33, 48], [22, 48, 33, 43]] \n",
            "-----\n",
            "(10887, 20)\n",
            "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0 57  1 33 38 48 39 63]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 28 44  8 33 48]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 22 48 33 43]] \n",
            "-----\n",
            "64\n",
            "24\n",
            "(10887, 20, 64)\n",
            "[[[1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 1.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]] \n",
            "-----\n",
            "(10887, 20, 64) (10887, 20, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNqqnkVSwXC-"
      },
      "source": [
        "# Attention Mechanism\n",
        "## Task 2: Code your own (key-value) attention mechnism (1 point)\n",
        "* PLEASE READ: you DO NOT have to follow all the details in (Daniluk, et al. 2017). You just need to create a key-value attention mechanism where the \"key\" part of the mechanism is used for attention score calculation, and the \"value\" part of the mechanism is used to encode information to create a context vector.  \n",
        "* Define global variables\n",
        "* fill code for one_step_attention function\n",
        "* Hint: use keras.layers.Lambda \n",
        "* HINT: you will probably need more hidden dimmensions than what you've seen in the demo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSdFcuGuwXDB"
      },
      "source": [
        "from tensorflow.keras.activations import softmax\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow import split\n",
        "def softMaxAxis1(x):\n",
        "    return softmax(x,axis=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNraiNpMB5XY"
      },
      "source": [
        "#These are global variables (shared layers)\n",
        "repeator = RepeatVector(max_input)\n",
        "concatenator = Concatenate(axis=-1)\n",
        "splitter = Lambda(lambda tensor: split(tensor, num_or_size_splits=2, axis=-1) )\n",
        "#Attention function###\n",
        "fattn_1 = Dense(10, activation = \"tanh\")\n",
        "fattn_2 = Dense(1, activation = \"relu\")\n",
        "###\n",
        "activator = Activation(softMaxAxis1, name='attention_scores') \n",
        "dotor = Dot(axes = 1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsF2OldsB9RL"
      },
      "source": [
        "def one_step_attention(a, s_prev):\n",
        "\n",
        "    a_k, a_v = splitter(a)\n",
        "    s_prev = repeator(s_prev)\n",
        "    s_prev_k, s_prev_v = splitter(s_prev)\n",
        "    concat = concatenator([a_k, s_prev_k])\n",
        "    e = fattn_1(concat)\n",
        "    energies = fattn_2(e)\n",
        "    attention_scores = activator(energies)\n",
        "    r = concatenator([a_v, s_prev_v])\n",
        "    re = fattn_1(r)\n",
        "    context =  dotor([attention_scores, re])\n",
        "    return context"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bgSCY3NwXDU"
      },
      "source": [
        "## Task3: Create and train your encoder/decoder model here (1 point)\n",
        "* HINT: you will probably need more hidden dimmensions than what you've seen in the demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pmo6LO2N4H8"
      },
      "source": [
        "n_h = 128 #hidden dimensions for encoder \n",
        "n_s = 128 #hidden dimensions for decoder\n",
        "m = 10887\n",
        "encoder_LSTM =  Bidirectional(LSTM(n_h, return_sequences=True),input_shape=(-1, max_input, n_h*2))\n",
        "decoder_LSTM_cell = LSTM(n_s, return_state = True) #decoder_LSTM_cell\n",
        "output_layer = Dense(output_vocab_size, activation=\"softmax\") #softmax output layer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSTTONrUOJSI"
      },
      "source": [
        "s0 = np.zeros((m, n_s))\n",
        "c0 = np.zeros((m, n_s))\n",
        "outputs = list(y.swapaxes(0,1))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_JYHl6YN631"
      },
      "source": [
        "def model(Tx, Ty, n_h, n_s, input_vocab_size, output_vocab_size):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    Tx -- length of the input sequence\n",
        "    Ty -- length of the output sequence\n",
        "    n_h -- hidden state size of the Bi-LSTM\n",
        "    n_s -- hidden state size of the post-attention LSTM\n",
        "    input_vocab_size -- size of the input vocab\n",
        "    output_vocab_size -- size of the output vocab\n",
        "\n",
        "    Returns:\n",
        "    model -- Keras model instance\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input of your model\n",
        "    X = Input(shape=(Tx, input_vocab_size))\n",
        "    # Define hidden state and cell state for decoder_LSTM_Cell\n",
        "    s0 = Input(shape=(n_s,), name='s0')\n",
        "    c0 = Input(shape=(n_s,), name='c0')\n",
        "    s = s0\n",
        "    c = c0\n",
        "    \n",
        "    # Initialize empty list of outputs\n",
        "    outputs = list()\n",
        "    #Encoder Bi-LSTM\n",
        "    # h = Bidirectional(LSTM(n_h, return_sequences=True),input_shape=(-1, Tx, n_h*2))(X)\n",
        "    h = encoder_LSTM(X)\n",
        "    #Iterate for Ty steps (Decoding)\n",
        "    for t in range(Ty):\n",
        "    \n",
        "        #Perform one step of the attention mechanism to calculate the context vector at timestep t\n",
        "        context = one_step_attention(h, s)\n",
        "       \n",
        "        # Feed the context vector to the decoder LSTM cell\n",
        "        s, _, c = decoder_LSTM_cell(context,initial_state=[s,c])\n",
        "           \n",
        "        # Pass the decoder hidden output to the output layer (softmax)\n",
        "        out = output_layer(s)\n",
        "        \n",
        "        # Append an output list with the current output\n",
        "        outputs.append(out)\n",
        "    \n",
        "    #Create model instance\n",
        "    model = Model(inputs=[X,s0,c0],outputs=outputs)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at2QBuIMN_uf"
      },
      "source": [
        "model = model(max_input, max_output, n_h, n_s, input_vocab_size, output_vocab_size)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKSnoc2XOD6F",
        "outputId": "96aa0e40-2f25-4490-d413-c5a574f2d99e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 20, 64)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "s0 (InputLayer)                 [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 20, 256)      197632      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector (RepeatVector)    (None, 20, 128)      0           s0[0][0]                         \n",
            "                                                                 lstm_1[0][0]                     \n",
            "                                                                 lstm_1[1][0]                     \n",
            "                                                                 lstm_1[2][0]                     \n",
            "                                                                 lstm_1[3][0]                     \n",
            "                                                                 lstm_1[4][0]                     \n",
            "                                                                 lstm_1[5][0]                     \n",
            "                                                                 lstm_1[6][0]                     \n",
            "                                                                 lstm_1[7][0]                     \n",
            "                                                                 lstm_1[8][0]                     \n",
            "                                                                 lstm_1[9][0]                     \n",
            "                                                                 lstm_1[10][0]                    \n",
            "                                                                 lstm_1[11][0]                    \n",
            "                                                                 lstm_1[12][0]                    \n",
            "                                                                 lstm_1[13][0]                    \n",
            "                                                                 lstm_1[14][0]                    \n",
            "                                                                 lstm_1[15][0]                    \n",
            "                                                                 lstm_1[16][0]                    \n",
            "                                                                 lstm_1[17][0]                    \n",
            "                                                                 lstm_1[18][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 multiple             0           bidirectional[0][0]              \n",
            "                                                                 repeat_vector[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[1][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[2][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[3][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[4][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[5][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[6][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[7][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[8][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[9][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[10][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[11][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[12][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[13][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[14][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[15][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[16][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[17][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[18][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[19][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 20, 192)      0           lambda[0][0]                     \n",
            "                                                                 lambda[1][0]                     \n",
            "                                                                 lambda[0][1]                     \n",
            "                                                                 lambda[1][1]                     \n",
            "                                                                 lambda[2][0]                     \n",
            "                                                                 lambda[3][0]                     \n",
            "                                                                 lambda[2][1]                     \n",
            "                                                                 lambda[3][1]                     \n",
            "                                                                 lambda[4][0]                     \n",
            "                                                                 lambda[5][0]                     \n",
            "                                                                 lambda[4][1]                     \n",
            "                                                                 lambda[5][1]                     \n",
            "                                                                 lambda[6][0]                     \n",
            "                                                                 lambda[7][0]                     \n",
            "                                                                 lambda[6][1]                     \n",
            "                                                                 lambda[7][1]                     \n",
            "                                                                 lambda[8][0]                     \n",
            "                                                                 lambda[9][0]                     \n",
            "                                                                 lambda[8][1]                     \n",
            "                                                                 lambda[9][1]                     \n",
            "                                                                 lambda[10][0]                    \n",
            "                                                                 lambda[11][0]                    \n",
            "                                                                 lambda[10][1]                    \n",
            "                                                                 lambda[11][1]                    \n",
            "                                                                 lambda[12][0]                    \n",
            "                                                                 lambda[13][0]                    \n",
            "                                                                 lambda[12][1]                    \n",
            "                                                                 lambda[13][1]                    \n",
            "                                                                 lambda[14][0]                    \n",
            "                                                                 lambda[15][0]                    \n",
            "                                                                 lambda[14][1]                    \n",
            "                                                                 lambda[15][1]                    \n",
            "                                                                 lambda[16][0]                    \n",
            "                                                                 lambda[17][0]                    \n",
            "                                                                 lambda[16][1]                    \n",
            "                                                                 lambda[17][1]                    \n",
            "                                                                 lambda[18][0]                    \n",
            "                                                                 lambda[19][0]                    \n",
            "                                                                 lambda[18][1]                    \n",
            "                                                                 lambda[19][1]                    \n",
            "                                                                 lambda[20][0]                    \n",
            "                                                                 lambda[21][0]                    \n",
            "                                                                 lambda[20][1]                    \n",
            "                                                                 lambda[21][1]                    \n",
            "                                                                 lambda[22][0]                    \n",
            "                                                                 lambda[23][0]                    \n",
            "                                                                 lambda[22][1]                    \n",
            "                                                                 lambda[23][1]                    \n",
            "                                                                 lambda[24][0]                    \n",
            "                                                                 lambda[25][0]                    \n",
            "                                                                 lambda[24][1]                    \n",
            "                                                                 lambda[25][1]                    \n",
            "                                                                 lambda[26][0]                    \n",
            "                                                                 lambda[27][0]                    \n",
            "                                                                 lambda[26][1]                    \n",
            "                                                                 lambda[27][1]                    \n",
            "                                                                 lambda[28][0]                    \n",
            "                                                                 lambda[29][0]                    \n",
            "                                                                 lambda[28][1]                    \n",
            "                                                                 lambda[29][1]                    \n",
            "                                                                 lambda[30][0]                    \n",
            "                                                                 lambda[31][0]                    \n",
            "                                                                 lambda[30][1]                    \n",
            "                                                                 lambda[31][1]                    \n",
            "                                                                 lambda[32][0]                    \n",
            "                                                                 lambda[33][0]                    \n",
            "                                                                 lambda[32][1]                    \n",
            "                                                                 lambda[33][1]                    \n",
            "                                                                 lambda[34][0]                    \n",
            "                                                                 lambda[35][0]                    \n",
            "                                                                 lambda[34][1]                    \n",
            "                                                                 lambda[35][1]                    \n",
            "                                                                 lambda[36][0]                    \n",
            "                                                                 lambda[37][0]                    \n",
            "                                                                 lambda[36][1]                    \n",
            "                                                                 lambda[37][1]                    \n",
            "                                                                 lambda[38][0]                    \n",
            "                                                                 lambda[39][0]                    \n",
            "                                                                 lambda[38][1]                    \n",
            "                                                                 lambda[39][1]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20, 10)       1930        concatenate[0][0]                \n",
            "                                                                 concatenate[1][0]                \n",
            "                                                                 concatenate[2][0]                \n",
            "                                                                 concatenate[3][0]                \n",
            "                                                                 concatenate[4][0]                \n",
            "                                                                 concatenate[5][0]                \n",
            "                                                                 concatenate[6][0]                \n",
            "                                                                 concatenate[7][0]                \n",
            "                                                                 concatenate[8][0]                \n",
            "                                                                 concatenate[9][0]                \n",
            "                                                                 concatenate[10][0]               \n",
            "                                                                 concatenate[11][0]               \n",
            "                                                                 concatenate[12][0]               \n",
            "                                                                 concatenate[13][0]               \n",
            "                                                                 concatenate[14][0]               \n",
            "                                                                 concatenate[15][0]               \n",
            "                                                                 concatenate[16][0]               \n",
            "                                                                 concatenate[17][0]               \n",
            "                                                                 concatenate[18][0]               \n",
            "                                                                 concatenate[19][0]               \n",
            "                                                                 concatenate[20][0]               \n",
            "                                                                 concatenate[21][0]               \n",
            "                                                                 concatenate[22][0]               \n",
            "                                                                 concatenate[23][0]               \n",
            "                                                                 concatenate[24][0]               \n",
            "                                                                 concatenate[25][0]               \n",
            "                                                                 concatenate[26][0]               \n",
            "                                                                 concatenate[27][0]               \n",
            "                                                                 concatenate[28][0]               \n",
            "                                                                 concatenate[29][0]               \n",
            "                                                                 concatenate[30][0]               \n",
            "                                                                 concatenate[31][0]               \n",
            "                                                                 concatenate[32][0]               \n",
            "                                                                 concatenate[33][0]               \n",
            "                                                                 concatenate[34][0]               \n",
            "                                                                 concatenate[35][0]               \n",
            "                                                                 concatenate[36][0]               \n",
            "                                                                 concatenate[37][0]               \n",
            "                                                                 concatenate[38][0]               \n",
            "                                                                 concatenate[39][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20, 1)        11          dense[0][0]                      \n",
            "                                                                 dense[2][0]                      \n",
            "                                                                 dense[4][0]                      \n",
            "                                                                 dense[6][0]                      \n",
            "                                                                 dense[8][0]                      \n",
            "                                                                 dense[10][0]                     \n",
            "                                                                 dense[12][0]                     \n",
            "                                                                 dense[14][0]                     \n",
            "                                                                 dense[16][0]                     \n",
            "                                                                 dense[18][0]                     \n",
            "                                                                 dense[20][0]                     \n",
            "                                                                 dense[22][0]                     \n",
            "                                                                 dense[24][0]                     \n",
            "                                                                 dense[26][0]                     \n",
            "                                                                 dense[28][0]                     \n",
            "                                                                 dense[30][0]                     \n",
            "                                                                 dense[32][0]                     \n",
            "                                                                 dense[34][0]                     \n",
            "                                                                 dense[36][0]                     \n",
            "                                                                 dense[38][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_scores (Activation)   (None, 20, 1)        0           dense_1[0][0]                    \n",
            "                                                                 dense_1[1][0]                    \n",
            "                                                                 dense_1[2][0]                    \n",
            "                                                                 dense_1[3][0]                    \n",
            "                                                                 dense_1[4][0]                    \n",
            "                                                                 dense_1[5][0]                    \n",
            "                                                                 dense_1[6][0]                    \n",
            "                                                                 dense_1[7][0]                    \n",
            "                                                                 dense_1[8][0]                    \n",
            "                                                                 dense_1[9][0]                    \n",
            "                                                                 dense_1[10][0]                   \n",
            "                                                                 dense_1[11][0]                   \n",
            "                                                                 dense_1[12][0]                   \n",
            "                                                                 dense_1[13][0]                   \n",
            "                                                                 dense_1[14][0]                   \n",
            "                                                                 dense_1[15][0]                   \n",
            "                                                                 dense_1[16][0]                   \n",
            "                                                                 dense_1[17][0]                   \n",
            "                                                                 dense_1[18][0]                   \n",
            "                                                                 dense_1[19][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 1, 10)        0           attention_scores[0][0]           \n",
            "                                                                 dense[1][0]                      \n",
            "                                                                 attention_scores[1][0]           \n",
            "                                                                 dense[3][0]                      \n",
            "                                                                 attention_scores[2][0]           \n",
            "                                                                 dense[5][0]                      \n",
            "                                                                 attention_scores[3][0]           \n",
            "                                                                 dense[7][0]                      \n",
            "                                                                 attention_scores[4][0]           \n",
            "                                                                 dense[9][0]                      \n",
            "                                                                 attention_scores[5][0]           \n",
            "                                                                 dense[11][0]                     \n",
            "                                                                 attention_scores[6][0]           \n",
            "                                                                 dense[13][0]                     \n",
            "                                                                 attention_scores[7][0]           \n",
            "                                                                 dense[15][0]                     \n",
            "                                                                 attention_scores[8][0]           \n",
            "                                                                 dense[17][0]                     \n",
            "                                                                 attention_scores[9][0]           \n",
            "                                                                 dense[19][0]                     \n",
            "                                                                 attention_scores[10][0]          \n",
            "                                                                 dense[21][0]                     \n",
            "                                                                 attention_scores[11][0]          \n",
            "                                                                 dense[23][0]                     \n",
            "                                                                 attention_scores[12][0]          \n",
            "                                                                 dense[25][0]                     \n",
            "                                                                 attention_scores[13][0]          \n",
            "                                                                 dense[27][0]                     \n",
            "                                                                 attention_scores[14][0]          \n",
            "                                                                 dense[29][0]                     \n",
            "                                                                 attention_scores[15][0]          \n",
            "                                                                 dense[31][0]                     \n",
            "                                                                 attention_scores[16][0]          \n",
            "                                                                 dense[33][0]                     \n",
            "                                                                 attention_scores[17][0]          \n",
            "                                                                 dense[35][0]                     \n",
            "                                                                 attention_scores[18][0]          \n",
            "                                                                 dense[37][0]                     \n",
            "                                                                 attention_scores[19][0]          \n",
            "                                                                 dense[39][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "c0 (InputLayer)                 [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 128), (None, 71168       dot[0][0]                        \n",
            "                                                                 s0[0][0]                         \n",
            "                                                                 c0[0][0]                         \n",
            "                                                                 dot[1][0]                        \n",
            "                                                                 lstm_1[0][0]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "                                                                 dot[2][0]                        \n",
            "                                                                 lstm_1[1][0]                     \n",
            "                                                                 lstm_1[1][2]                     \n",
            "                                                                 dot[3][0]                        \n",
            "                                                                 lstm_1[2][0]                     \n",
            "                                                                 lstm_1[2][2]                     \n",
            "                                                                 dot[4][0]                        \n",
            "                                                                 lstm_1[3][0]                     \n",
            "                                                                 lstm_1[3][2]                     \n",
            "                                                                 dot[5][0]                        \n",
            "                                                                 lstm_1[4][0]                     \n",
            "                                                                 lstm_1[4][2]                     \n",
            "                                                                 dot[6][0]                        \n",
            "                                                                 lstm_1[5][0]                     \n",
            "                                                                 lstm_1[5][2]                     \n",
            "                                                                 dot[7][0]                        \n",
            "                                                                 lstm_1[6][0]                     \n",
            "                                                                 lstm_1[6][2]                     \n",
            "                                                                 dot[8][0]                        \n",
            "                                                                 lstm_1[7][0]                     \n",
            "                                                                 lstm_1[7][2]                     \n",
            "                                                                 dot[9][0]                        \n",
            "                                                                 lstm_1[8][0]                     \n",
            "                                                                 lstm_1[8][2]                     \n",
            "                                                                 dot[10][0]                       \n",
            "                                                                 lstm_1[9][0]                     \n",
            "                                                                 lstm_1[9][2]                     \n",
            "                                                                 dot[11][0]                       \n",
            "                                                                 lstm_1[10][0]                    \n",
            "                                                                 lstm_1[10][2]                    \n",
            "                                                                 dot[12][0]                       \n",
            "                                                                 lstm_1[11][0]                    \n",
            "                                                                 lstm_1[11][2]                    \n",
            "                                                                 dot[13][0]                       \n",
            "                                                                 lstm_1[12][0]                    \n",
            "                                                                 lstm_1[12][2]                    \n",
            "                                                                 dot[14][0]                       \n",
            "                                                                 lstm_1[13][0]                    \n",
            "                                                                 lstm_1[13][2]                    \n",
            "                                                                 dot[15][0]                       \n",
            "                                                                 lstm_1[14][0]                    \n",
            "                                                                 lstm_1[14][2]                    \n",
            "                                                                 dot[16][0]                       \n",
            "                                                                 lstm_1[15][0]                    \n",
            "                                                                 lstm_1[15][2]                    \n",
            "                                                                 dot[17][0]                       \n",
            "                                                                 lstm_1[16][0]                    \n",
            "                                                                 lstm_1[16][2]                    \n",
            "                                                                 dot[18][0]                       \n",
            "                                                                 lstm_1[17][0]                    \n",
            "                                                                 lstm_1[17][2]                    \n",
            "                                                                 dot[19][0]                       \n",
            "                                                                 lstm_1[18][0]                    \n",
            "                                                                 lstm_1[18][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 24)           3096        lstm_1[0][0]                     \n",
            "                                                                 lstm_1[1][0]                     \n",
            "                                                                 lstm_1[2][0]                     \n",
            "                                                                 lstm_1[3][0]                     \n",
            "                                                                 lstm_1[4][0]                     \n",
            "                                                                 lstm_1[5][0]                     \n",
            "                                                                 lstm_1[6][0]                     \n",
            "                                                                 lstm_1[7][0]                     \n",
            "                                                                 lstm_1[8][0]                     \n",
            "                                                                 lstm_1[9][0]                     \n",
            "                                                                 lstm_1[10][0]                    \n",
            "                                                                 lstm_1[11][0]                    \n",
            "                                                                 lstm_1[12][0]                    \n",
            "                                                                 lstm_1[13][0]                    \n",
            "                                                                 lstm_1[14][0]                    \n",
            "                                                                 lstm_1[15][0]                    \n",
            "                                                                 lstm_1[16][0]                    \n",
            "                                                                 lstm_1[17][0]                    \n",
            "                                                                 lstm_1[18][0]                    \n",
            "                                                                 lstm_1[19][0]                    \n",
            "==================================================================================================\n",
            "Total params: 273,837\n",
            "Trainable params: 273,837\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpTFxnXQOID_"
      },
      "source": [
        "opt = Adam(lr= 0.01, clipvalue=0.5)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VR6J7K6OKgH",
        "outputId": "cfc23636-b0de-4b1e-df21-6c0e439cc4fe"
      },
      "source": [
        "model.fit([x, s0, c0], outputs, epochs=40, batch_size=120)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "91/91 [==============================] - 71s 88ms/step - loss: 31.5381 - dense_2_loss: 0.9933 - dense_2_1_loss: 0.6174 - dense_2_2_loss: 0.5258 - dense_2_3_loss: 0.4921 - dense_2_4_loss: 0.4790 - dense_2_5_loss: 0.4781 - dense_2_6_loss: 0.5108 - dense_2_7_loss: 0.5738 - dense_2_8_loss: 0.6910 - dense_2_9_loss: 0.8767 - dense_2_10_loss: 1.1932 - dense_2_11_loss: 1.5850 - dense_2_12_loss: 2.0578 - dense_2_13_loss: 2.5863 - dense_2_14_loss: 2.9249 - dense_2_15_loss: 3.0683 - dense_2_16_loss: 3.0411 - dense_2_17_loss: 3.1978 - dense_2_18_loss: 2.8484 - dense_2_19_loss: 2.7971 - dense_2_accuracy: 0.9443 - dense_2_1_accuracy: 0.9439 - dense_2_2_accuracy: 0.9439 - dense_2_3_accuracy: 0.9434 - dense_2_4_accuracy: 0.9425 - dense_2_5_accuracy: 0.9407 - dense_2_6_accuracy: 0.9358 - dense_2_7_accuracy: 0.9278 - dense_2_8_accuracy: 0.9115 - dense_2_9_accuracy: 0.8823 - dense_2_10_accuracy: 0.8104 - dense_2_11_accuracy: 0.6883 - dense_2_12_accuracy: 0.5389 - dense_2_13_accuracy: 0.3385 - dense_2_14_accuracy: 0.1777 - dense_2_15_accuracy: 0.1011 - dense_2_16_accuracy: 0.1107 - dense_2_17_accuracy: 0.0484 - dense_2_18_accuracy: 0.1780 - dense_2_19_accuracy: 0.0805\n",
            "Epoch 2/40\n",
            "91/91 [==============================] - 8s 88ms/step - loss: 21.3158 - dense_2_loss: 0.0170 - dense_2_1_loss: 0.0027 - dense_2_2_loss: 0.0034 - dense_2_3_loss: 0.0125 - dense_2_4_loss: 0.0143 - dense_2_5_loss: 0.0238 - dense_2_6_loss: 0.0487 - dense_2_7_loss: 0.1027 - dense_2_8_loss: 0.1784 - dense_2_9_loss: 0.3302 - dense_2_10_loss: 0.5904 - dense_2_11_loss: 0.9899 - dense_2_12_loss: 1.5168 - dense_2_13_loss: 2.1208 - dense_2_14_loss: 2.5432 - dense_2_15_loss: 2.7123 - dense_2_16_loss: 2.6361 - dense_2_17_loss: 2.8672 - dense_2_18_loss: 2.4343 - dense_2_19_loss: 2.1710 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9989 - dense_2_4_accuracy: 0.9984 - dense_2_5_accuracy: 0.9971 - dense_2_6_accuracy: 0.9929 - dense_2_7_accuracy: 0.9840 - dense_2_8_accuracy: 0.9679 - dense_2_9_accuracy: 0.9380 - dense_2_10_accuracy: 0.8728 - dense_2_11_accuracy: 0.7681 - dense_2_12_accuracy: 0.6153 - dense_2_13_accuracy: 0.4000 - dense_2_14_accuracy: 0.2396 - dense_2_15_accuracy: 0.1681 - dense_2_16_accuracy: 0.2157 - dense_2_17_accuracy: 0.0830 - dense_2_18_accuracy: 0.2907 - dense_2_19_accuracy: 0.2235\n",
            "Epoch 3/40\n",
            "91/91 [==============================] - 8s 84ms/step - loss: 19.8225 - dense_2_loss: 0.0086 - dense_2_1_loss: 6.9335e-04 - dense_2_2_loss: 0.0013 - dense_2_3_loss: 0.0114 - dense_2_4_loss: 0.0184 - dense_2_5_loss: 0.0216 - dense_2_6_loss: 0.0398 - dense_2_7_loss: 0.0813 - dense_2_8_loss: 0.1512 - dense_2_9_loss: 0.2924 - dense_2_10_loss: 0.5263 - dense_2_11_loss: 0.8650 - dense_2_12_loss: 1.3472 - dense_2_13_loss: 1.9079 - dense_2_14_loss: 2.3531 - dense_2_15_loss: 2.5714 - dense_2_16_loss: 2.5601 - dense_2_17_loss: 2.7282 - dense_2_18_loss: 2.3186 - dense_2_19_loss: 2.0181 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9988 - dense_2_4_accuracy: 0.9974 - dense_2_5_accuracy: 0.9967 - dense_2_6_accuracy: 0.9929 - dense_2_7_accuracy: 0.9844 - dense_2_8_accuracy: 0.9659 - dense_2_9_accuracy: 0.9317 - dense_2_10_accuracy: 0.8651 - dense_2_11_accuracy: 0.7678 - dense_2_12_accuracy: 0.6237 - dense_2_13_accuracy: 0.4397 - dense_2_14_accuracy: 0.2808 - dense_2_15_accuracy: 0.1939 - dense_2_16_accuracy: 0.2191 - dense_2_17_accuracy: 0.1482 - dense_2_18_accuracy: 0.3156 - dense_2_19_accuracy: 0.2673\n",
            "Epoch 4/40\n",
            "91/91 [==============================] - 8s 83ms/step - loss: 19.4021 - dense_2_loss: 0.0054 - dense_2_1_loss: 0.0011 - dense_2_2_loss: 0.0015 - dense_2_3_loss: 0.0043 - dense_2_4_loss: 0.0086 - dense_2_5_loss: 0.0157 - dense_2_6_loss: 0.0374 - dense_2_7_loss: 0.0718 - dense_2_8_loss: 0.1456 - dense_2_9_loss: 0.2805 - dense_2_10_loss: 0.5173 - dense_2_11_loss: 0.8468 - dense_2_12_loss: 1.3460 - dense_2_13_loss: 1.9107 - dense_2_14_loss: 2.3628 - dense_2_15_loss: 2.5699 - dense_2_16_loss: 2.5059 - dense_2_17_loss: 2.5989 - dense_2_18_loss: 2.2489 - dense_2_19_loss: 1.9228 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9993 - dense_2_4_accuracy: 0.9986 - dense_2_5_accuracy: 0.9976 - dense_2_6_accuracy: 0.9928 - dense_2_7_accuracy: 0.9846 - dense_2_8_accuracy: 0.9658 - dense_2_9_accuracy: 0.9348 - dense_2_10_accuracy: 0.8674 - dense_2_11_accuracy: 0.7718 - dense_2_12_accuracy: 0.6253 - dense_2_13_accuracy: 0.4366 - dense_2_14_accuracy: 0.2757 - dense_2_15_accuracy: 0.1915 - dense_2_16_accuracy: 0.2152 - dense_2_17_accuracy: 0.2043 - dense_2_18_accuracy: 0.3359 - dense_2_19_accuracy: 0.3027\n",
            "Epoch 5/40\n",
            "91/91 [==============================] - 8s 85ms/step - loss: 18.0995 - dense_2_loss: 0.0060 - dense_2_1_loss: 8.1190e-04 - dense_2_2_loss: 0.0019 - dense_2_3_loss: 0.0050 - dense_2_4_loss: 0.0087 - dense_2_5_loss: 0.0158 - dense_2_6_loss: 0.0375 - dense_2_7_loss: 0.0692 - dense_2_8_loss: 0.1350 - dense_2_9_loss: 0.2530 - dense_2_10_loss: 0.4671 - dense_2_11_loss: 0.8103 - dense_2_12_loss: 1.2704 - dense_2_13_loss: 1.8167 - dense_2_14_loss: 2.2736 - dense_2_15_loss: 2.4883 - dense_2_16_loss: 2.4016 - dense_2_17_loss: 2.4258 - dense_2_18_loss: 2.0289 - dense_2_19_loss: 1.5840 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9992 - dense_2_4_accuracy: 0.9987 - dense_2_5_accuracy: 0.9971 - dense_2_6_accuracy: 0.9924 - dense_2_7_accuracy: 0.9849 - dense_2_8_accuracy: 0.9667 - dense_2_9_accuracy: 0.9388 - dense_2_10_accuracy: 0.8763 - dense_2_11_accuracy: 0.7779 - dense_2_12_accuracy: 0.6415 - dense_2_13_accuracy: 0.4537 - dense_2_14_accuracy: 0.2956 - dense_2_15_accuracy: 0.1848 - dense_2_16_accuracy: 0.2510 - dense_2_17_accuracy: 0.2690 - dense_2_18_accuracy: 0.4102 - dense_2_19_accuracy: 0.4593\n",
            "Epoch 6/40\n",
            "91/91 [==============================] - 8s 85ms/step - loss: 17.0442 - dense_2_loss: 0.0025 - dense_2_1_loss: 0.0033 - dense_2_2_loss: 0.0038 - dense_2_3_loss: 0.0054 - dense_2_4_loss: 0.0093 - dense_2_5_loss: 0.0159 - dense_2_6_loss: 0.0440 - dense_2_7_loss: 0.0729 - dense_2_8_loss: 0.1413 - dense_2_9_loss: 0.2606 - dense_2_10_loss: 0.4704 - dense_2_11_loss: 0.7991 - dense_2_12_loss: 1.2694 - dense_2_13_loss: 1.7670 - dense_2_14_loss: 2.2284 - dense_2_15_loss: 2.4282 - dense_2_16_loss: 2.2508 - dense_2_17_loss: 2.2156 - dense_2_18_loss: 1.7441 - dense_2_19_loss: 1.3122 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9997 - dense_2_2_accuracy: 0.9996 - dense_2_3_accuracy: 0.9990 - dense_2_4_accuracy: 0.9982 - dense_2_5_accuracy: 0.9971 - dense_2_6_accuracy: 0.9911 - dense_2_7_accuracy: 0.9832 - dense_2_8_accuracy: 0.9654 - dense_2_9_accuracy: 0.9353 - dense_2_10_accuracy: 0.8744 - dense_2_11_accuracy: 0.7769 - dense_2_12_accuracy: 0.6355 - dense_2_13_accuracy: 0.4589 - dense_2_14_accuracy: 0.3009 - dense_2_15_accuracy: 0.2237 - dense_2_16_accuracy: 0.3076 - dense_2_17_accuracy: 0.3568 - dense_2_18_accuracy: 0.4703 - dense_2_19_accuracy: 0.5540\n",
            "Epoch 7/40\n",
            "91/91 [==============================] - 8s 86ms/step - loss: 16.6737 - dense_2_loss: 0.0018 - dense_2_1_loss: 0.0034 - dense_2_2_loss: 0.0035 - dense_2_3_loss: 0.0058 - dense_2_4_loss: 0.0109 - dense_2_5_loss: 0.0169 - dense_2_6_loss: 0.0395 - dense_2_7_loss: 0.0767 - dense_2_8_loss: 0.1446 - dense_2_9_loss: 0.2571 - dense_2_10_loss: 0.4814 - dense_2_11_loss: 0.8104 - dense_2_12_loss: 1.2472 - dense_2_13_loss: 1.7529 - dense_2_14_loss: 2.2139 - dense_2_15_loss: 2.3726 - dense_2_16_loss: 2.1577 - dense_2_17_loss: 2.1006 - dense_2_18_loss: 1.7759 - dense_2_19_loss: 1.2010 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9997 - dense_2_2_accuracy: 0.9996 - dense_2_3_accuracy: 0.9991 - dense_2_4_accuracy: 0.9981 - dense_2_5_accuracy: 0.9966 - dense_2_6_accuracy: 0.9923 - dense_2_7_accuracy: 0.9835 - dense_2_8_accuracy: 0.9661 - dense_2_9_accuracy: 0.9383 - dense_2_10_accuracy: 0.8706 - dense_2_11_accuracy: 0.7739 - dense_2_12_accuracy: 0.6338 - dense_2_13_accuracy: 0.4649 - dense_2_14_accuracy: 0.3170 - dense_2_15_accuracy: 0.2403 - dense_2_16_accuracy: 0.3391 - dense_2_17_accuracy: 0.3677 - dense_2_18_accuracy: 0.4397 - dense_2_19_accuracy: 0.6164\n",
            "Epoch 8/40\n",
            "91/91 [==============================] - 8s 85ms/step - loss: 14.7182 - dense_2_loss: 0.0014 - dense_2_1_loss: 0.0061 - dense_2_2_loss: 0.0069 - dense_2_3_loss: 0.0102 - dense_2_4_loss: 0.0132 - dense_2_5_loss: 0.0153 - dense_2_6_loss: 0.0380 - dense_2_7_loss: 0.0680 - dense_2_8_loss: 0.1361 - dense_2_9_loss: 0.2490 - dense_2_10_loss: 0.4439 - dense_2_11_loss: 0.7491 - dense_2_12_loss: 1.1746 - dense_2_13_loss: 1.6161 - dense_2_14_loss: 2.0733 - dense_2_15_loss: 2.2416 - dense_2_16_loss: 1.9204 - dense_2_17_loss: 1.7487 - dense_2_18_loss: 1.4115 - dense_2_19_loss: 0.7948 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9996 - dense_2_2_accuracy: 0.9996 - dense_2_3_accuracy: 0.9989 - dense_2_4_accuracy: 0.9981 - dense_2_5_accuracy: 0.9970 - dense_2_6_accuracy: 0.9926 - dense_2_7_accuracy: 0.9847 - dense_2_8_accuracy: 0.9647 - dense_2_9_accuracy: 0.9355 - dense_2_10_accuracy: 0.8748 - dense_2_11_accuracy: 0.7799 - dense_2_12_accuracy: 0.6485 - dense_2_13_accuracy: 0.5036 - dense_2_14_accuracy: 0.3557 - dense_2_15_accuracy: 0.2613 - dense_2_16_accuracy: 0.3912 - dense_2_17_accuracy: 0.4680 - dense_2_18_accuracy: 0.5500 - dense_2_19_accuracy: 0.7684\n",
            "Epoch 9/40\n",
            "91/91 [==============================] - 8s 85ms/step - loss: 13.0051 - dense_2_loss: 9.8317e-04 - dense_2_1_loss: 0.0017 - dense_2_2_loss: 0.0038 - dense_2_3_loss: 0.0055 - dense_2_4_loss: 0.0079 - dense_2_5_loss: 0.0168 - dense_2_6_loss: 0.0357 - dense_2_7_loss: 0.0621 - dense_2_8_loss: 0.1169 - dense_2_9_loss: 0.2358 - dense_2_10_loss: 0.4229 - dense_2_11_loss: 0.7221 - dense_2_12_loss: 1.1245 - dense_2_13_loss: 1.5327 - dense_2_14_loss: 1.9116 - dense_2_15_loss: 2.0399 - dense_2_16_loss: 1.6665 - dense_2_17_loss: 1.4439 - dense_2_18_loss: 1.1210 - dense_2_19_loss: 0.5328 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9993 - dense_2_4_accuracy: 0.9987 - dense_2_5_accuracy: 0.9968 - dense_2_6_accuracy: 0.9930 - dense_2_7_accuracy: 0.9852 - dense_2_8_accuracy: 0.9683 - dense_2_9_accuracy: 0.9368 - dense_2_10_accuracy: 0.8766 - dense_2_11_accuracy: 0.7895 - dense_2_12_accuracy: 0.6576 - dense_2_13_accuracy: 0.5297 - dense_2_14_accuracy: 0.3871 - dense_2_15_accuracy: 0.3279 - dense_2_16_accuracy: 0.4766 - dense_2_17_accuracy: 0.5681 - dense_2_18_accuracy: 0.6416 - dense_2_19_accuracy: 0.8507\n",
            "Epoch 10/40\n",
            "91/91 [==============================] - 8s 86ms/step - loss: 11.1689 - dense_2_loss: 0.0014 - dense_2_1_loss: 0.0012 - dense_2_2_loss: 0.0024 - dense_2_3_loss: 0.0073 - dense_2_4_loss: 0.0105 - dense_2_5_loss: 0.0145 - dense_2_6_loss: 0.0296 - dense_2_7_loss: 0.0537 - dense_2_8_loss: 0.1119 - dense_2_9_loss: 0.1987 - dense_2_10_loss: 0.3734 - dense_2_11_loss: 0.6172 - dense_2_12_loss: 0.9947 - dense_2_13_loss: 1.3715 - dense_2_14_loss: 1.7030 - dense_2_15_loss: 1.7781 - dense_2_16_loss: 1.4751 - dense_2_17_loss: 1.1978 - dense_2_18_loss: 0.8738 - dense_2_19_loss: 0.3532 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9990 - dense_2_4_accuracy: 0.9983 - dense_2_5_accuracy: 0.9972 - dense_2_6_accuracy: 0.9937 - dense_2_7_accuracy: 0.9880 - dense_2_8_accuracy: 0.9695 - dense_2_9_accuracy: 0.9467 - dense_2_10_accuracy: 0.8903 - dense_2_11_accuracy: 0.8168 - dense_2_12_accuracy: 0.7041 - dense_2_13_accuracy: 0.5800 - dense_2_14_accuracy: 0.4705 - dense_2_15_accuracy: 0.4239 - dense_2_16_accuracy: 0.5339 - dense_2_17_accuracy: 0.6321 - dense_2_18_accuracy: 0.7307 - dense_2_19_accuracy: 0.9069\n",
            "Epoch 11/40\n",
            "91/91 [==============================] - 8s 89ms/step - loss: 10.5640 - dense_2_loss: 0.0012 - dense_2_1_loss: 0.0029 - dense_2_2_loss: 0.0046 - dense_2_3_loss: 0.0073 - dense_2_4_loss: 0.0118 - dense_2_5_loss: 0.0202 - dense_2_6_loss: 0.0358 - dense_2_7_loss: 0.0593 - dense_2_8_loss: 0.1228 - dense_2_9_loss: 0.2279 - dense_2_10_loss: 0.3742 - dense_2_11_loss: 0.6206 - dense_2_12_loss: 0.9752 - dense_2_13_loss: 1.3146 - dense_2_14_loss: 1.5931 - dense_2_15_loss: 1.6151 - dense_2_16_loss: 1.3305 - dense_2_17_loss: 1.1009 - dense_2_18_loss: 0.7830 - dense_2_19_loss: 0.3629 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9992 - dense_2_4_accuracy: 0.9982 - dense_2_5_accuracy: 0.9964 - dense_2_6_accuracy: 0.9932 - dense_2_7_accuracy: 0.9858 - dense_2_8_accuracy: 0.9690 - dense_2_9_accuracy: 0.9351 - dense_2_10_accuracy: 0.8918 - dense_2_11_accuracy: 0.8127 - dense_2_12_accuracy: 0.7037 - dense_2_13_accuracy: 0.5921 - dense_2_14_accuracy: 0.4925 - dense_2_15_accuracy: 0.4939 - dense_2_16_accuracy: 0.5782 - dense_2_17_accuracy: 0.6593 - dense_2_18_accuracy: 0.7624 - dense_2_19_accuracy: 0.9031\n",
            "Epoch 12/40\n",
            "91/91 [==============================] - 8s 92ms/step - loss: 9.3189 - dense_2_loss: 0.0014 - dense_2_1_loss: 0.0022 - dense_2_2_loss: 0.0034 - dense_2_3_loss: 0.0087 - dense_2_4_loss: 0.0152 - dense_2_5_loss: 0.0221 - dense_2_6_loss: 0.0399 - dense_2_7_loss: 0.0632 - dense_2_8_loss: 0.1083 - dense_2_9_loss: 0.2027 - dense_2_10_loss: 0.3539 - dense_2_11_loss: 0.5809 - dense_2_12_loss: 0.9039 - dense_2_13_loss: 1.1943 - dense_2_14_loss: 1.4056 - dense_2_15_loss: 1.4147 - dense_2_16_loss: 1.1507 - dense_2_17_loss: 0.9566 - dense_2_18_loss: 0.5861 - dense_2_19_loss: 0.3052 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9988 - dense_2_4_accuracy: 0.9975 - dense_2_5_accuracy: 0.9962 - dense_2_6_accuracy: 0.9913 - dense_2_7_accuracy: 0.9849 - dense_2_8_accuracy: 0.9703 - dense_2_9_accuracy: 0.9425 - dense_2_10_accuracy: 0.8984 - dense_2_11_accuracy: 0.8232 - dense_2_12_accuracy: 0.7209 - dense_2_13_accuracy: 0.6336 - dense_2_14_accuracy: 0.5448 - dense_2_15_accuracy: 0.5589 - dense_2_16_accuracy: 0.6388 - dense_2_17_accuracy: 0.7065 - dense_2_18_accuracy: 0.8335 - dense_2_19_accuracy: 0.9219\n",
            "Epoch 13/40\n",
            "91/91 [==============================] - 8s 91ms/step - loss: 7.8249 - dense_2_loss: 0.0016 - dense_2_1_loss: 0.0027 - dense_2_2_loss: 0.0037 - dense_2_3_loss: 0.0070 - dense_2_4_loss: 0.0190 - dense_2_5_loss: 0.0214 - dense_2_6_loss: 0.0391 - dense_2_7_loss: 0.0657 - dense_2_8_loss: 0.1102 - dense_2_9_loss: 0.1934 - dense_2_10_loss: 0.3358 - dense_2_11_loss: 0.5176 - dense_2_12_loss: 0.7942 - dense_2_13_loss: 1.0537 - dense_2_14_loss: 1.1925 - dense_2_15_loss: 1.1702 - dense_2_16_loss: 0.9227 - dense_2_17_loss: 0.7357 - dense_2_18_loss: 0.4350 - dense_2_19_loss: 0.2037 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9990 - dense_2_4_accuracy: 0.9974 - dense_2_5_accuracy: 0.9965 - dense_2_6_accuracy: 0.9915 - dense_2_7_accuracy: 0.9825 - dense_2_8_accuracy: 0.9698 - dense_2_9_accuracy: 0.9477 - dense_2_10_accuracy: 0.9013 - dense_2_11_accuracy: 0.8442 - dense_2_12_accuracy: 0.7515 - dense_2_13_accuracy: 0.6792 - dense_2_14_accuracy: 0.6215 - dense_2_15_accuracy: 0.6480 - dense_2_16_accuracy: 0.7221 - dense_2_17_accuracy: 0.7808 - dense_2_18_accuracy: 0.8858 - dense_2_19_accuracy: 0.9513\n",
            "Epoch 14/40\n",
            "91/91 [==============================] - 8s 89ms/step - loss: 6.9575 - dense_2_loss: 0.0015 - dense_2_1_loss: 0.0025 - dense_2_2_loss: 0.0036 - dense_2_3_loss: 0.0105 - dense_2_4_loss: 0.0114 - dense_2_5_loss: 0.0146 - dense_2_6_loss: 0.0270 - dense_2_7_loss: 0.0540 - dense_2_8_loss: 0.1013 - dense_2_9_loss: 0.1882 - dense_2_10_loss: 0.3244 - dense_2_11_loss: 0.4958 - dense_2_12_loss: 0.7266 - dense_2_13_loss: 0.9285 - dense_2_14_loss: 1.0442 - dense_2_15_loss: 1.0295 - dense_2_16_loss: 0.8193 - dense_2_17_loss: 0.6312 - dense_2_18_loss: 0.3615 - dense_2_19_loss: 0.1821 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9988 - dense_2_4_accuracy: 0.9983 - dense_2_5_accuracy: 0.9970 - dense_2_6_accuracy: 0.9939 - dense_2_7_accuracy: 0.9862 - dense_2_8_accuracy: 0.9705 - dense_2_9_accuracy: 0.9449 - dense_2_10_accuracy: 0.9019 - dense_2_11_accuracy: 0.8496 - dense_2_12_accuracy: 0.7701 - dense_2_13_accuracy: 0.7168 - dense_2_14_accuracy: 0.6785 - dense_2_15_accuracy: 0.6975 - dense_2_16_accuracy: 0.7581 - dense_2_17_accuracy: 0.8242 - dense_2_18_accuracy: 0.9063 - dense_2_19_accuracy: 0.9569\n",
            "Epoch 15/40\n",
            "91/91 [==============================] - 8s 88ms/step - loss: 6.6467 - dense_2_loss: 0.0011 - dense_2_1_loss: 0.0028 - dense_2_2_loss: 0.0033 - dense_2_3_loss: 0.0115 - dense_2_4_loss: 0.0157 - dense_2_5_loss: 0.0197 - dense_2_6_loss: 0.0289 - dense_2_7_loss: 0.0509 - dense_2_8_loss: 0.0996 - dense_2_9_loss: 0.1764 - dense_2_10_loss: 0.3076 - dense_2_11_loss: 0.4833 - dense_2_12_loss: 0.7105 - dense_2_13_loss: 0.8786 - dense_2_14_loss: 0.9764 - dense_2_15_loss: 0.9591 - dense_2_16_loss: 0.7628 - dense_2_17_loss: 0.5915 - dense_2_18_loss: 0.3644 - dense_2_19_loss: 0.2028 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9989 - dense_2_4_accuracy: 0.9980 - dense_2_5_accuracy: 0.9968 - dense_2_6_accuracy: 0.9930 - dense_2_7_accuracy: 0.9861 - dense_2_8_accuracy: 0.9723 - dense_2_9_accuracy: 0.9503 - dense_2_10_accuracy: 0.9105 - dense_2_11_accuracy: 0.8464 - dense_2_12_accuracy: 0.7740 - dense_2_13_accuracy: 0.7301 - dense_2_14_accuracy: 0.7041 - dense_2_15_accuracy: 0.7130 - dense_2_16_accuracy: 0.7806 - dense_2_17_accuracy: 0.8309 - dense_2_18_accuracy: 0.9055 - dense_2_19_accuracy: 0.9485\n",
            "Epoch 16/40\n",
            "91/91 [==============================] - 9s 96ms/step - loss: 5.6172 - dense_2_loss: 0.0010 - dense_2_1_loss: 0.0020 - dense_2_2_loss: 0.0037 - dense_2_3_loss: 0.0112 - dense_2_4_loss: 0.0133 - dense_2_5_loss: 0.0186 - dense_2_6_loss: 0.0340 - dense_2_7_loss: 0.0489 - dense_2_8_loss: 0.0886 - dense_2_9_loss: 0.1609 - dense_2_10_loss: 0.2847 - dense_2_11_loss: 0.4281 - dense_2_12_loss: 0.6304 - dense_2_13_loss: 0.7363 - dense_2_14_loss: 0.8157 - dense_2_15_loss: 0.7875 - dense_2_16_loss: 0.6396 - dense_2_17_loss: 0.4881 - dense_2_18_loss: 0.2746 - dense_2_19_loss: 0.1498 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9985 - dense_2_4_accuracy: 0.9978 - dense_2_5_accuracy: 0.9966 - dense_2_6_accuracy: 0.9919 - dense_2_7_accuracy: 0.9856 - dense_2_8_accuracy: 0.9745 - dense_2_9_accuracy: 0.9518 - dense_2_10_accuracy: 0.9136 - dense_2_11_accuracy: 0.8697 - dense_2_12_accuracy: 0.8047 - dense_2_13_accuracy: 0.7716 - dense_2_14_accuracy: 0.7613 - dense_2_15_accuracy: 0.7648 - dense_2_16_accuracy: 0.8171 - dense_2_17_accuracy: 0.8669 - dense_2_18_accuracy: 0.9311 - dense_2_19_accuracy: 0.9638\n",
            "Epoch 17/40\n",
            "91/91 [==============================] - 8s 91ms/step - loss: 6.0966 - dense_2_loss: 8.4933e-04 - dense_2_1_loss: 0.0017 - dense_2_2_loss: 0.0023 - dense_2_3_loss: 0.0117 - dense_2_4_loss: 0.0134 - dense_2_5_loss: 0.0193 - dense_2_6_loss: 0.0358 - dense_2_7_loss: 0.0577 - dense_2_8_loss: 0.0969 - dense_2_9_loss: 0.1702 - dense_2_10_loss: 0.2898 - dense_2_11_loss: 0.4437 - dense_2_12_loss: 0.6288 - dense_2_13_loss: 0.7814 - dense_2_14_loss: 0.8707 - dense_2_15_loss: 0.8373 - dense_2_16_loss: 0.6569 - dense_2_17_loss: 0.5514 - dense_2_18_loss: 0.3787 - dense_2_19_loss: 0.2480 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9986 - dense_2_4_accuracy: 0.9979 - dense_2_5_accuracy: 0.9967 - dense_2_6_accuracy: 0.9917 - dense_2_7_accuracy: 0.9859 - dense_2_8_accuracy: 0.9711 - dense_2_9_accuracy: 0.9523 - dense_2_10_accuracy: 0.9131 - dense_2_11_accuracy: 0.8618 - dense_2_12_accuracy: 0.8036 - dense_2_13_accuracy: 0.7622 - dense_2_14_accuracy: 0.7277 - dense_2_15_accuracy: 0.7441 - dense_2_16_accuracy: 0.8099 - dense_2_17_accuracy: 0.8526 - dense_2_18_accuracy: 0.8994 - dense_2_19_accuracy: 0.9331\n",
            "Epoch 18/40\n",
            "91/91 [==============================] - 8s 86ms/step - loss: 4.7844 - dense_2_loss: 9.6452e-04 - dense_2_1_loss: 0.0028 - dense_2_2_loss: 0.0038 - dense_2_3_loss: 0.0077 - dense_2_4_loss: 0.0130 - dense_2_5_loss: 0.0183 - dense_2_6_loss: 0.0277 - dense_2_7_loss: 0.0440 - dense_2_8_loss: 0.0768 - dense_2_9_loss: 0.1414 - dense_2_10_loss: 0.2520 - dense_2_11_loss: 0.3851 - dense_2_12_loss: 0.5427 - dense_2_13_loss: 0.6517 - dense_2_14_loss: 0.7124 - dense_2_15_loss: 0.6651 - dense_2_16_loss: 0.5185 - dense_2_17_loss: 0.3825 - dense_2_18_loss: 0.2128 - dense_2_19_loss: 0.1251 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9991 - dense_2_4_accuracy: 0.9980 - dense_2_5_accuracy: 0.9965 - dense_2_6_accuracy: 0.9931 - dense_2_7_accuracy: 0.9882 - dense_2_8_accuracy: 0.9759 - dense_2_9_accuracy: 0.9581 - dense_2_10_accuracy: 0.9229 - dense_2_11_accuracy: 0.8813 - dense_2_12_accuracy: 0.8259 - dense_2_13_accuracy: 0.8000 - dense_2_14_accuracy: 0.7912 - dense_2_15_accuracy: 0.7931 - dense_2_16_accuracy: 0.8532 - dense_2_17_accuracy: 0.9013 - dense_2_18_accuracy: 0.9449 - dense_2_19_accuracy: 0.9695\n",
            "Epoch 19/40\n",
            "91/91 [==============================] - 8s 91ms/step - loss: 4.0249 - dense_2_loss: 7.9226e-04 - dense_2_1_loss: 0.0012 - dense_2_2_loss: 0.0023 - dense_2_3_loss: 0.0041 - dense_2_4_loss: 0.0085 - dense_2_5_loss: 0.0132 - dense_2_6_loss: 0.0260 - dense_2_7_loss: 0.0440 - dense_2_8_loss: 0.0787 - dense_2_9_loss: 0.1430 - dense_2_10_loss: 0.2263 - dense_2_11_loss: 0.3276 - dense_2_12_loss: 0.4630 - dense_2_13_loss: 0.5517 - dense_2_14_loss: 0.5885 - dense_2_15_loss: 0.5513 - dense_2_16_loss: 0.4059 - dense_2_17_loss: 0.3192 - dense_2_18_loss: 0.1680 - dense_2_19_loss: 0.1016 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9994 - dense_2_4_accuracy: 0.9988 - dense_2_5_accuracy: 0.9975 - dense_2_6_accuracy: 0.9937 - dense_2_7_accuracy: 0.9878 - dense_2_8_accuracy: 0.9752 - dense_2_9_accuracy: 0.9575 - dense_2_10_accuracy: 0.9291 - dense_2_11_accuracy: 0.9016 - dense_2_12_accuracy: 0.8602 - dense_2_13_accuracy: 0.8354 - dense_2_14_accuracy: 0.8289 - dense_2_15_accuracy: 0.8341 - dense_2_16_accuracy: 0.8850 - dense_2_17_accuracy: 0.9201 - dense_2_18_accuracy: 0.9588 - dense_2_19_accuracy: 0.9761\n",
            "Epoch 20/40\n",
            "91/91 [==============================] - 8s 92ms/step - loss: 5.1396 - dense_2_loss: 0.0010 - dense_2_1_loss: 0.0018 - dense_2_2_loss: 0.0033 - dense_2_3_loss: 0.0078 - dense_2_4_loss: 0.0111 - dense_2_5_loss: 0.0168 - dense_2_6_loss: 0.0311 - dense_2_7_loss: 0.0477 - dense_2_8_loss: 0.0832 - dense_2_9_loss: 0.1497 - dense_2_10_loss: 0.2369 - dense_2_11_loss: 0.3400 - dense_2_12_loss: 0.5100 - dense_2_13_loss: 0.6248 - dense_2_14_loss: 0.6883 - dense_2_15_loss: 0.6845 - dense_2_16_loss: 0.5623 - dense_2_17_loss: 0.5079 - dense_2_18_loss: 0.3778 - dense_2_19_loss: 0.2534 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9990 - dense_2_4_accuracy: 0.9984 - dense_2_5_accuracy: 0.9973 - dense_2_6_accuracy: 0.9922 - dense_2_7_accuracy: 0.9870 - dense_2_8_accuracy: 0.9735 - dense_2_9_accuracy: 0.9549 - dense_2_10_accuracy: 0.9271 - dense_2_11_accuracy: 0.8937 - dense_2_12_accuracy: 0.8327 - dense_2_13_accuracy: 0.8081 - dense_2_14_accuracy: 0.7879 - dense_2_15_accuracy: 0.7840 - dense_2_16_accuracy: 0.8295 - dense_2_17_accuracy: 0.8614 - dense_2_18_accuracy: 0.8941 - dense_2_19_accuracy: 0.9277\n",
            "Epoch 21/40\n",
            "91/91 [==============================] - 8s 89ms/step - loss: 3.2071 - dense_2_loss: 6.8662e-04 - dense_2_1_loss: 0.0020 - dense_2_2_loss: 0.0018 - dense_2_3_loss: 0.0059 - dense_2_4_loss: 0.0138 - dense_2_5_loss: 0.0189 - dense_2_6_loss: 0.0273 - dense_2_7_loss: 0.0392 - dense_2_8_loss: 0.0709 - dense_2_9_loss: 0.1193 - dense_2_10_loss: 0.1906 - dense_2_11_loss: 0.2795 - dense_2_12_loss: 0.3858 - dense_2_13_loss: 0.4354 - dense_2_14_loss: 0.4572 - dense_2_15_loss: 0.4143 - dense_2_16_loss: 0.3168 - dense_2_17_loss: 0.2348 - dense_2_18_loss: 0.1192 - dense_2_19_loss: 0.0734 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9992 - dense_2_4_accuracy: 0.9982 - dense_2_5_accuracy: 0.9966 - dense_2_6_accuracy: 0.9940 - dense_2_7_accuracy: 0.9898 - dense_2_8_accuracy: 0.9786 - dense_2_9_accuracy: 0.9664 - dense_2_10_accuracy: 0.9430 - dense_2_11_accuracy: 0.9145 - dense_2_12_accuracy: 0.8810 - dense_2_13_accuracy: 0.8734 - dense_2_14_accuracy: 0.8684 - dense_2_15_accuracy: 0.8789 - dense_2_16_accuracy: 0.9138 - dense_2_17_accuracy: 0.9403 - dense_2_18_accuracy: 0.9726 - dense_2_19_accuracy: 0.9813\n",
            "Epoch 22/40\n",
            "91/91 [==============================] - 8s 90ms/step - loss: 2.9272 - dense_2_loss: 5.8742e-04 - dense_2_1_loss: 0.0043 - dense_2_2_loss: 0.0059 - dense_2_3_loss: 0.0069 - dense_2_4_loss: 0.0099 - dense_2_5_loss: 0.0134 - dense_2_6_loss: 0.0258 - dense_2_7_loss: 0.0389 - dense_2_8_loss: 0.0673 - dense_2_9_loss: 0.1144 - dense_2_10_loss: 0.1764 - dense_2_11_loss: 0.2569 - dense_2_12_loss: 0.3309 - dense_2_13_loss: 0.4097 - dense_2_14_loss: 0.4087 - dense_2_15_loss: 0.3738 - dense_2_16_loss: 0.2828 - dense_2_17_loss: 0.2082 - dense_2_18_loss: 0.1128 - dense_2_19_loss: 0.0796 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9995 - dense_2_2_accuracy: 0.9994 - dense_2_3_accuracy: 0.9990 - dense_2_4_accuracy: 0.9982 - dense_2_5_accuracy: 0.9970 - dense_2_6_accuracy: 0.9925 - dense_2_7_accuracy: 0.9894 - dense_2_8_accuracy: 0.9792 - dense_2_9_accuracy: 0.9669 - dense_2_10_accuracy: 0.9473 - dense_2_11_accuracy: 0.9204 - dense_2_12_accuracy: 0.9008 - dense_2_13_accuracy: 0.8801 - dense_2_14_accuracy: 0.8851 - dense_2_15_accuracy: 0.8909 - dense_2_16_accuracy: 0.9212 - dense_2_17_accuracy: 0.9484 - dense_2_18_accuracy: 0.9721 - dense_2_19_accuracy: 0.9811\n",
            "Epoch 23/40\n",
            "91/91 [==============================] - 8s 91ms/step - loss: 2.9983 - dense_2_loss: 5.8692e-04 - dense_2_1_loss: 0.0018 - dense_2_2_loss: 0.0040 - dense_2_3_loss: 0.0070 - dense_2_4_loss: 0.0119 - dense_2_5_loss: 0.0178 - dense_2_6_loss: 0.0278 - dense_2_7_loss: 0.0490 - dense_2_8_loss: 0.0759 - dense_2_9_loss: 0.1217 - dense_2_10_loss: 0.1871 - dense_2_11_loss: 0.2548 - dense_2_12_loss: 0.3421 - dense_2_13_loss: 0.3890 - dense_2_14_loss: 0.4033 - dense_2_15_loss: 0.3781 - dense_2_16_loss: 0.2947 - dense_2_17_loss: 0.2373 - dense_2_18_loss: 0.1184 - dense_2_19_loss: 0.0760 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9996 - dense_2_3_accuracy: 0.9991 - dense_2_4_accuracy: 0.9982 - dense_2_5_accuracy: 0.9962 - dense_2_6_accuracy: 0.9933 - dense_2_7_accuracy: 0.9864 - dense_2_8_accuracy: 0.9764 - dense_2_9_accuracy: 0.9628 - dense_2_10_accuracy: 0.9424 - dense_2_11_accuracy: 0.9238 - dense_2_12_accuracy: 0.8946 - dense_2_13_accuracy: 0.8859 - dense_2_14_accuracy: 0.8767 - dense_2_15_accuracy: 0.8910 - dense_2_16_accuracy: 0.9162 - dense_2_17_accuracy: 0.9366 - dense_2_18_accuracy: 0.9663 - dense_2_19_accuracy: 0.9799\n",
            "Epoch 24/40\n",
            "91/91 [==============================] - 8s 84ms/step - loss: 3.0291 - dense_2_loss: 6.7440e-04 - dense_2_1_loss: 0.0013 - dense_2_2_loss: 0.0012 - dense_2_3_loss: 0.0041 - dense_2_4_loss: 0.0087 - dense_2_5_loss: 0.0147 - dense_2_6_loss: 0.0226 - dense_2_7_loss: 0.0411 - dense_2_8_loss: 0.0695 - dense_2_9_loss: 0.1070 - dense_2_10_loss: 0.1788 - dense_2_11_loss: 0.2338 - dense_2_12_loss: 0.3319 - dense_2_13_loss: 0.3875 - dense_2_14_loss: 0.4104 - dense_2_15_loss: 0.3857 - dense_2_16_loss: 0.2982 - dense_2_17_loss: 0.2654 - dense_2_18_loss: 0.1677 - dense_2_19_loss: 0.0989 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9995 - dense_2_4_accuracy: 0.9986 - dense_2_5_accuracy: 0.9972 - dense_2_6_accuracy: 0.9935 - dense_2_7_accuracy: 0.9895 - dense_2_8_accuracy: 0.9805 - dense_2_9_accuracy: 0.9671 - dense_2_10_accuracy: 0.9477 - dense_2_11_accuracy: 0.9301 - dense_2_12_accuracy: 0.9012 - dense_2_13_accuracy: 0.8850 - dense_2_14_accuracy: 0.8769 - dense_2_15_accuracy: 0.8850 - dense_2_16_accuracy: 0.9157 - dense_2_17_accuracy: 0.9328 - dense_2_18_accuracy: 0.9567 - dense_2_19_accuracy: 0.9744\n",
            "Epoch 25/40\n",
            "91/91 [==============================] - 8s 90ms/step - loss: 2.4444 - dense_2_loss: 4.7130e-04 - dense_2_1_loss: 0.0026 - dense_2_2_loss: 0.0044 - dense_2_3_loss: 0.0078 - dense_2_4_loss: 0.0126 - dense_2_5_loss: 0.0143 - dense_2_6_loss: 0.0265 - dense_2_7_loss: 0.0410 - dense_2_8_loss: 0.0655 - dense_2_9_loss: 0.1003 - dense_2_10_loss: 0.1598 - dense_2_11_loss: 0.2137 - dense_2_12_loss: 0.2755 - dense_2_13_loss: 0.3181 - dense_2_14_loss: 0.3361 - dense_2_15_loss: 0.2975 - dense_2_16_loss: 0.2236 - dense_2_17_loss: 0.1880 - dense_2_18_loss: 0.0974 - dense_2_19_loss: 0.0592 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9997 - dense_2_2_accuracy: 0.9996 - dense_2_3_accuracy: 0.9988 - dense_2_4_accuracy: 0.9977 - dense_2_5_accuracy: 0.9967 - dense_2_6_accuracy: 0.9927 - dense_2_7_accuracy: 0.9879 - dense_2_8_accuracy: 0.9788 - dense_2_9_accuracy: 0.9695 - dense_2_10_accuracy: 0.9501 - dense_2_11_accuracy: 0.9370 - dense_2_12_accuracy: 0.9136 - dense_2_13_accuracy: 0.9059 - dense_2_14_accuracy: 0.9017 - dense_2_15_accuracy: 0.9122 - dense_2_16_accuracy: 0.9393 - dense_2_17_accuracy: 0.9521 - dense_2_18_accuracy: 0.9769 - dense_2_19_accuracy: 0.9854\n",
            "Epoch 26/40\n",
            "91/91 [==============================] - 8s 85ms/step - loss: 3.6533 - dense_2_loss: 5.5740e-04 - dense_2_1_loss: 0.0015 - dense_2_2_loss: 0.0019 - dense_2_3_loss: 0.0039 - dense_2_4_loss: 0.0099 - dense_2_5_loss: 0.0140 - dense_2_6_loss: 0.0278 - dense_2_7_loss: 0.0442 - dense_2_8_loss: 0.0683 - dense_2_9_loss: 0.1176 - dense_2_10_loss: 0.1814 - dense_2_11_loss: 0.2544 - dense_2_12_loss: 0.3571 - dense_2_13_loss: 0.4374 - dense_2_14_loss: 0.4841 - dense_2_15_loss: 0.4644 - dense_2_16_loss: 0.3675 - dense_2_17_loss: 0.3518 - dense_2_18_loss: 0.2885 - dense_2_19_loss: 0.1770 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9995 - dense_2_4_accuracy: 0.9985 - dense_2_5_accuracy: 0.9973 - dense_2_6_accuracy: 0.9932 - dense_2_7_accuracy: 0.9865 - dense_2_8_accuracy: 0.9782 - dense_2_9_accuracy: 0.9641 - dense_2_10_accuracy: 0.9419 - dense_2_11_accuracy: 0.9207 - dense_2_12_accuracy: 0.8857 - dense_2_13_accuracy: 0.8647 - dense_2_14_accuracy: 0.8469 - dense_2_15_accuracy: 0.8584 - dense_2_16_accuracy: 0.8882 - dense_2_17_accuracy: 0.9053 - dense_2_18_accuracy: 0.9220 - dense_2_19_accuracy: 0.9510\n",
            "Epoch 27/40\n",
            "91/91 [==============================] - 8s 88ms/step - loss: 2.1009 - dense_2_loss: 3.7244e-04 - dense_2_1_loss: 4.4745e-04 - dense_2_2_loss: 8.7663e-04 - dense_2_3_loss: 0.0045 - dense_2_4_loss: 0.0122 - dense_2_5_loss: 0.0147 - dense_2_6_loss: 0.0231 - dense_2_7_loss: 0.0343 - dense_2_8_loss: 0.0627 - dense_2_9_loss: 0.0886 - dense_2_10_loss: 0.1348 - dense_2_11_loss: 0.1841 - dense_2_12_loss: 0.2398 - dense_2_13_loss: 0.2800 - dense_2_14_loss: 0.2802 - dense_2_15_loss: 0.2519 - dense_2_16_loss: 0.1976 - dense_2_17_loss: 0.1446 - dense_2_18_loss: 0.0891 - dense_2_19_loss: 0.0570 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9993 - dense_2_4_accuracy: 0.9983 - dense_2_5_accuracy: 0.9974 - dense_2_6_accuracy: 0.9938 - dense_2_7_accuracy: 0.9898 - dense_2_8_accuracy: 0.9792 - dense_2_9_accuracy: 0.9733 - dense_2_10_accuracy: 0.9583 - dense_2_11_accuracy: 0.9431 - dense_2_12_accuracy: 0.9291 - dense_2_13_accuracy: 0.9199 - dense_2_14_accuracy: 0.9211 - dense_2_15_accuracy: 0.9263 - dense_2_16_accuracy: 0.9477 - dense_2_17_accuracy: 0.9636 - dense_2_18_accuracy: 0.9781 - dense_2_19_accuracy: 0.9856\n",
            "Epoch 28/40\n",
            "91/91 [==============================] - 8s 92ms/step - loss: 2.0117 - dense_2_loss: 3.9266e-04 - dense_2_1_loss: 3.1736e-04 - dense_2_2_loss: 0.0018 - dense_2_3_loss: 0.0068 - dense_2_4_loss: 0.0085 - dense_2_5_loss: 0.0124 - dense_2_6_loss: 0.0286 - dense_2_7_loss: 0.0401 - dense_2_8_loss: 0.0634 - dense_2_9_loss: 0.0983 - dense_2_10_loss: 0.1351 - dense_2_11_loss: 0.1697 - dense_2_12_loss: 0.2295 - dense_2_13_loss: 0.2640 - dense_2_14_loss: 0.2641 - dense_2_15_loss: 0.2362 - dense_2_16_loss: 0.1894 - dense_2_17_loss: 0.1425 - dense_2_18_loss: 0.0733 - dense_2_19_loss: 0.0473 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9990 - dense_2_4_accuracy: 0.9985 - dense_2_5_accuracy: 0.9976 - dense_2_6_accuracy: 0.9921 - dense_2_7_accuracy: 0.9879 - dense_2_8_accuracy: 0.9793 - dense_2_9_accuracy: 0.9708 - dense_2_10_accuracy: 0.9589 - dense_2_11_accuracy: 0.9489 - dense_2_12_accuracy: 0.9342 - dense_2_13_accuracy: 0.9233 - dense_2_14_accuracy: 0.9233 - dense_2_15_accuracy: 0.9340 - dense_2_16_accuracy: 0.9471 - dense_2_17_accuracy: 0.9613 - dense_2_18_accuracy: 0.9818 - dense_2_19_accuracy: 0.9894\n",
            "Epoch 29/40\n",
            "91/91 [==============================] - 8s 91ms/step - loss: 1.9373 - dense_2_loss: 5.0755e-04 - dense_2_1_loss: 7.1999e-04 - dense_2_2_loss: 0.0012 - dense_2_3_loss: 0.0059 - dense_2_4_loss: 0.0114 - dense_2_5_loss: 0.0173 - dense_2_6_loss: 0.0287 - dense_2_7_loss: 0.0399 - dense_2_8_loss: 0.0652 - dense_2_9_loss: 0.0900 - dense_2_10_loss: 0.1269 - dense_2_11_loss: 0.1774 - dense_2_12_loss: 0.2168 - dense_2_13_loss: 0.2436 - dense_2_14_loss: 0.2642 - dense_2_15_loss: 0.2308 - dense_2_16_loss: 0.1700 - dense_2_17_loss: 0.1317 - dense_2_18_loss: 0.0662 - dense_2_19_loss: 0.0489 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9990 - dense_2_4_accuracy: 0.9980 - dense_2_5_accuracy: 0.9963 - dense_2_6_accuracy: 0.9923 - dense_2_7_accuracy: 0.9887 - dense_2_8_accuracy: 0.9820 - dense_2_9_accuracy: 0.9717 - dense_2_10_accuracy: 0.9598 - dense_2_11_accuracy: 0.9480 - dense_2_12_accuracy: 0.9367 - dense_2_13_accuracy: 0.9302 - dense_2_14_accuracy: 0.9250 - dense_2_15_accuracy: 0.9324 - dense_2_16_accuracy: 0.9532 - dense_2_17_accuracy: 0.9670 - dense_2_18_accuracy: 0.9834 - dense_2_19_accuracy: 0.9866\n",
            "Epoch 30/40\n",
            "91/91 [==============================] - 8s 91ms/step - loss: 1.6240 - dense_2_loss: 2.1238e-04 - dense_2_1_loss: 0.0014 - dense_2_2_loss: 0.0014 - dense_2_3_loss: 0.0064 - dense_2_4_loss: 0.0141 - dense_2_5_loss: 0.0151 - dense_2_6_loss: 0.0247 - dense_2_7_loss: 0.0356 - dense_2_8_loss: 0.0548 - dense_2_9_loss: 0.0790 - dense_2_10_loss: 0.1101 - dense_2_11_loss: 0.1555 - dense_2_12_loss: 0.1779 - dense_2_13_loss: 0.2102 - dense_2_14_loss: 0.1997 - dense_2_15_loss: 0.1909 - dense_2_16_loss: 0.1310 - dense_2_17_loss: 0.1070 - dense_2_18_loss: 0.0605 - dense_2_19_loss: 0.0486 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9991 - dense_2_4_accuracy: 0.9975 - dense_2_5_accuracy: 0.9964 - dense_2_6_accuracy: 0.9933 - dense_2_7_accuracy: 0.9900 - dense_2_8_accuracy: 0.9830 - dense_2_9_accuracy: 0.9754 - dense_2_10_accuracy: 0.9659 - dense_2_11_accuracy: 0.9562 - dense_2_12_accuracy: 0.9504 - dense_2_13_accuracy: 0.9394 - dense_2_14_accuracy: 0.9458 - dense_2_15_accuracy: 0.9450 - dense_2_16_accuracy: 0.9631 - dense_2_17_accuracy: 0.9738 - dense_2_18_accuracy: 0.9863 - dense_2_19_accuracy: 0.9905\n",
            "Epoch 31/40\n",
            "91/91 [==============================] - 8s 92ms/step - loss: 1.5843 - dense_2_loss: 2.6521e-04 - dense_2_1_loss: 0.0040 - dense_2_2_loss: 0.0038 - dense_2_3_loss: 0.0057 - dense_2_4_loss: 0.0127 - dense_2_5_loss: 0.0142 - dense_2_6_loss: 0.0246 - dense_2_7_loss: 0.0318 - dense_2_8_loss: 0.0520 - dense_2_9_loss: 0.0797 - dense_2_10_loss: 0.1053 - dense_2_11_loss: 0.1378 - dense_2_12_loss: 0.1780 - dense_2_13_loss: 0.2126 - dense_2_14_loss: 0.1915 - dense_2_15_loss: 0.1820 - dense_2_16_loss: 0.1423 - dense_2_17_loss: 0.1063 - dense_2_18_loss: 0.0580 - dense_2_19_loss: 0.0418 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9996 - dense_2_2_accuracy: 0.9995 - dense_2_3_accuracy: 0.9989 - dense_2_4_accuracy: 0.9979 - dense_2_5_accuracy: 0.9966 - dense_2_6_accuracy: 0.9935 - dense_2_7_accuracy: 0.9904 - dense_2_8_accuracy: 0.9850 - dense_2_9_accuracy: 0.9776 - dense_2_10_accuracy: 0.9688 - dense_2_11_accuracy: 0.9582 - dense_2_12_accuracy: 0.9466 - dense_2_13_accuracy: 0.9408 - dense_2_14_accuracy: 0.9445 - dense_2_15_accuracy: 0.9451 - dense_2_16_accuracy: 0.9604 - dense_2_17_accuracy: 0.9715 - dense_2_18_accuracy: 0.9848 - dense_2_19_accuracy: 0.9898\n",
            "Epoch 32/40\n",
            "91/91 [==============================] - 9s 97ms/step - loss: 1.9496 - dense_2_loss: 2.5321e-04 - dense_2_1_loss: 1.5376e-04 - dense_2_2_loss: 7.4641e-04 - dense_2_3_loss: 0.0038 - dense_2_4_loss: 0.0085 - dense_2_5_loss: 0.0129 - dense_2_6_loss: 0.0219 - dense_2_7_loss: 0.0317 - dense_2_8_loss: 0.0586 - dense_2_9_loss: 0.0849 - dense_2_10_loss: 0.1179 - dense_2_11_loss: 0.1654 - dense_2_12_loss: 0.2145 - dense_2_13_loss: 0.2393 - dense_2_14_loss: 0.2513 - dense_2_15_loss: 0.2451 - dense_2_16_loss: 0.1788 - dense_2_17_loss: 0.1432 - dense_2_18_loss: 0.1022 - dense_2_19_loss: 0.0685 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9994 - dense_2_4_accuracy: 0.9984 - dense_2_5_accuracy: 0.9970 - dense_2_6_accuracy: 0.9943 - dense_2_7_accuracy: 0.9918 - dense_2_8_accuracy: 0.9812 - dense_2_9_accuracy: 0.9754 - dense_2_10_accuracy: 0.9651 - dense_2_11_accuracy: 0.9522 - dense_2_12_accuracy: 0.9385 - dense_2_13_accuracy: 0.9289 - dense_2_14_accuracy: 0.9215 - dense_2_15_accuracy: 0.9246 - dense_2_16_accuracy: 0.9490 - dense_2_17_accuracy: 0.9575 - dense_2_18_accuracy: 0.9732 - dense_2_19_accuracy: 0.9832\n",
            "Epoch 33/40\n",
            "91/91 [==============================] - 8s 86ms/step - loss: 2.2125 - dense_2_loss: 4.0136e-04 - dense_2_1_loss: 3.3627e-04 - dense_2_2_loss: 7.2542e-04 - dense_2_3_loss: 0.0063 - dense_2_4_loss: 0.0125 - dense_2_5_loss: 0.0185 - dense_2_6_loss: 0.0294 - dense_2_7_loss: 0.0345 - dense_2_8_loss: 0.0610 - dense_2_9_loss: 0.0920 - dense_2_10_loss: 0.1372 - dense_2_11_loss: 0.2011 - dense_2_12_loss: 0.2449 - dense_2_13_loss: 0.2871 - dense_2_14_loss: 0.2846 - dense_2_15_loss: 0.2611 - dense_2_16_loss: 0.2152 - dense_2_17_loss: 0.1539 - dense_2_18_loss: 0.1005 - dense_2_19_loss: 0.0713 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9989 - dense_2_4_accuracy: 0.9980 - dense_2_5_accuracy: 0.9965 - dense_2_6_accuracy: 0.9928 - dense_2_7_accuracy: 0.9900 - dense_2_8_accuracy: 0.9805 - dense_2_9_accuracy: 0.9710 - dense_2_10_accuracy: 0.9563 - dense_2_11_accuracy: 0.9369 - dense_2_12_accuracy: 0.9292 - dense_2_13_accuracy: 0.9177 - dense_2_14_accuracy: 0.9174 - dense_2_15_accuracy: 0.9222 - dense_2_16_accuracy: 0.9342 - dense_2_17_accuracy: 0.9562 - dense_2_18_accuracy: 0.9734 - dense_2_19_accuracy: 0.9821\n",
            "Epoch 34/40\n",
            "91/91 [==============================] - 8s 89ms/step - loss: 1.5286 - dense_2_loss: 3.6081e-04 - dense_2_1_loss: 4.2300e-04 - dense_2_2_loss: 7.6756e-04 - dense_2_3_loss: 0.0037 - dense_2_4_loss: 0.0092 - dense_2_5_loss: 0.0130 - dense_2_6_loss: 0.0240 - dense_2_7_loss: 0.0340 - dense_2_8_loss: 0.0523 - dense_2_9_loss: 0.0758 - dense_2_10_loss: 0.1011 - dense_2_11_loss: 0.1459 - dense_2_12_loss: 0.1734 - dense_2_13_loss: 0.1906 - dense_2_14_loss: 0.1825 - dense_2_15_loss: 0.1555 - dense_2_16_loss: 0.1434 - dense_2_17_loss: 0.1025 - dense_2_18_loss: 0.0708 - dense_2_19_loss: 0.0494 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9993 - dense_2_4_accuracy: 0.9985 - dense_2_5_accuracy: 0.9975 - dense_2_6_accuracy: 0.9940 - dense_2_7_accuracy: 0.9904 - dense_2_8_accuracy: 0.9853 - dense_2_9_accuracy: 0.9772 - dense_2_10_accuracy: 0.9701 - dense_2_11_accuracy: 0.9580 - dense_2_12_accuracy: 0.9487 - dense_2_13_accuracy: 0.9493 - dense_2_14_accuracy: 0.9486 - dense_2_15_accuracy: 0.9541 - dense_2_16_accuracy: 0.9603 - dense_2_17_accuracy: 0.9703 - dense_2_18_accuracy: 0.9814 - dense_2_19_accuracy: 0.9861\n",
            "Epoch 35/40\n",
            "91/91 [==============================] - 8s 91ms/step - loss: 1.4860 - dense_2_loss: 3.1928e-04 - dense_2_1_loss: 0.0010 - dense_2_2_loss: 0.0018 - dense_2_3_loss: 0.0056 - dense_2_4_loss: 0.0105 - dense_2_5_loss: 0.0113 - dense_2_6_loss: 0.0208 - dense_2_7_loss: 0.0355 - dense_2_8_loss: 0.0561 - dense_2_9_loss: 0.0816 - dense_2_10_loss: 0.1073 - dense_2_11_loss: 0.1391 - dense_2_12_loss: 0.1736 - dense_2_13_loss: 0.1956 - dense_2_14_loss: 0.1760 - dense_2_15_loss: 0.1593 - dense_2_16_loss: 0.1238 - dense_2_17_loss: 0.0937 - dense_2_18_loss: 0.0525 - dense_2_19_loss: 0.0404 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9989 - dense_2_4_accuracy: 0.9980 - dense_2_5_accuracy: 0.9971 - dense_2_6_accuracy: 0.9934 - dense_2_7_accuracy: 0.9893 - dense_2_8_accuracy: 0.9856 - dense_2_9_accuracy: 0.9760 - dense_2_10_accuracy: 0.9682 - dense_2_11_accuracy: 0.9613 - dense_2_12_accuracy: 0.9549 - dense_2_13_accuracy: 0.9438 - dense_2_14_accuracy: 0.9464 - dense_2_15_accuracy: 0.9551 - dense_2_16_accuracy: 0.9662 - dense_2_17_accuracy: 0.9748 - dense_2_18_accuracy: 0.9863 - dense_2_19_accuracy: 0.9890\n",
            "Epoch 36/40\n",
            "91/91 [==============================] - 9s 95ms/step - loss: 1.3080 - dense_2_loss: 2.5704e-04 - dense_2_1_loss: 0.0019 - dense_2_2_loss: 0.0023 - dense_2_3_loss: 0.0062 - dense_2_4_loss: 0.0120 - dense_2_5_loss: 0.0157 - dense_2_6_loss: 0.0306 - dense_2_7_loss: 0.0346 - dense_2_8_loss: 0.0460 - dense_2_9_loss: 0.0575 - dense_2_10_loss: 0.0899 - dense_2_11_loss: 0.1101 - dense_2_12_loss: 0.1477 - dense_2_13_loss: 0.1661 - dense_2_14_loss: 0.1528 - dense_2_15_loss: 0.1465 - dense_2_16_loss: 0.1180 - dense_2_17_loss: 0.0824 - dense_2_18_loss: 0.0497 - dense_2_19_loss: 0.0378 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9995 - dense_2_3_accuracy: 0.9987 - dense_2_4_accuracy: 0.9976 - dense_2_5_accuracy: 0.9965 - dense_2_6_accuracy: 0.9923 - dense_2_7_accuracy: 0.9895 - dense_2_8_accuracy: 0.9873 - dense_2_9_accuracy: 0.9818 - dense_2_10_accuracy: 0.9743 - dense_2_11_accuracy: 0.9671 - dense_2_12_accuracy: 0.9590 - dense_2_13_accuracy: 0.9523 - dense_2_14_accuracy: 0.9548 - dense_2_15_accuracy: 0.9590 - dense_2_16_accuracy: 0.9685 - dense_2_17_accuracy: 0.9781 - dense_2_18_accuracy: 0.9883 - dense_2_19_accuracy: 0.9911\n",
            "Epoch 37/40\n",
            "91/91 [==============================] - 8s 93ms/step - loss: 1.2223 - dense_2_loss: 2.2184e-04 - dense_2_1_loss: 7.2328e-04 - dense_2_2_loss: 0.0012 - dense_2_3_loss: 0.0058 - dense_2_4_loss: 0.0103 - dense_2_5_loss: 0.0137 - dense_2_6_loss: 0.0268 - dense_2_7_loss: 0.0340 - dense_2_8_loss: 0.0481 - dense_2_9_loss: 0.0644 - dense_2_10_loss: 0.0867 - dense_2_11_loss: 0.1115 - dense_2_12_loss: 0.1479 - dense_2_13_loss: 0.1528 - dense_2_14_loss: 0.1497 - dense_2_15_loss: 0.1295 - dense_2_16_loss: 0.1028 - dense_2_17_loss: 0.0728 - dense_2_18_loss: 0.0389 - dense_2_19_loss: 0.0246 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9989 - dense_2_4_accuracy: 0.9981 - dense_2_5_accuracy: 0.9967 - dense_2_6_accuracy: 0.9924 - dense_2_7_accuracy: 0.9908 - dense_2_8_accuracy: 0.9860 - dense_2_9_accuracy: 0.9790 - dense_2_10_accuracy: 0.9750 - dense_2_11_accuracy: 0.9662 - dense_2_12_accuracy: 0.9552 - dense_2_13_accuracy: 0.9567 - dense_2_14_accuracy: 0.9573 - dense_2_15_accuracy: 0.9634 - dense_2_16_accuracy: 0.9706 - dense_2_17_accuracy: 0.9793 - dense_2_18_accuracy: 0.9900 - dense_2_19_accuracy: 0.9935\n",
            "Epoch 38/40\n",
            "91/91 [==============================] - 7s 82ms/step - loss: 1.2310 - dense_2_loss: 2.7325e-04 - dense_2_1_loss: 0.0013 - dense_2_2_loss: 0.0014 - dense_2_3_loss: 0.0054 - dense_2_4_loss: 0.0092 - dense_2_5_loss: 0.0108 - dense_2_6_loss: 0.0191 - dense_2_7_loss: 0.0306 - dense_2_8_loss: 0.0442 - dense_2_9_loss: 0.0621 - dense_2_10_loss: 0.0913 - dense_2_11_loss: 0.1175 - dense_2_12_loss: 0.1393 - dense_2_13_loss: 0.1490 - dense_2_14_loss: 0.1481 - dense_2_15_loss: 0.1400 - dense_2_16_loss: 0.0995 - dense_2_17_loss: 0.0783 - dense_2_18_loss: 0.0475 - dense_2_19_loss: 0.0362 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9990 - dense_2_4_accuracy: 0.9982 - dense_2_5_accuracy: 0.9977 - dense_2_6_accuracy: 0.9948 - dense_2_7_accuracy: 0.9917 - dense_2_8_accuracy: 0.9869 - dense_2_9_accuracy: 0.9806 - dense_2_10_accuracy: 0.9754 - dense_2_11_accuracy: 0.9651 - dense_2_12_accuracy: 0.9561 - dense_2_13_accuracy: 0.9563 - dense_2_14_accuracy: 0.9574 - dense_2_15_accuracy: 0.9576 - dense_2_16_accuracy: 0.9714 - dense_2_17_accuracy: 0.9786 - dense_2_18_accuracy: 0.9881 - dense_2_19_accuracy: 0.9907\n",
            "Epoch 39/40\n",
            "91/91 [==============================] - 8s 92ms/step - loss: 1.3433 - dense_2_loss: 1.6037e-04 - dense_2_1_loss: 4.2498e-04 - dense_2_2_loss: 6.1667e-04 - dense_2_3_loss: 0.0034 - dense_2_4_loss: 0.0053 - dense_2_5_loss: 0.0091 - dense_2_6_loss: 0.0251 - dense_2_7_loss: 0.0319 - dense_2_8_loss: 0.0471 - dense_2_9_loss: 0.0667 - dense_2_10_loss: 0.0937 - dense_2_11_loss: 0.1246 - dense_2_12_loss: 0.1596 - dense_2_13_loss: 0.1724 - dense_2_14_loss: 0.1621 - dense_2_15_loss: 0.1455 - dense_2_16_loss: 0.1079 - dense_2_17_loss: 0.0930 - dense_2_18_loss: 0.0565 - dense_2_19_loss: 0.0381 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9991 - dense_2_4_accuracy: 0.9989 - dense_2_5_accuracy: 0.9977 - dense_2_6_accuracy: 0.9936 - dense_2_7_accuracy: 0.9895 - dense_2_8_accuracy: 0.9867 - dense_2_9_accuracy: 0.9783 - dense_2_10_accuracy: 0.9710 - dense_2_11_accuracy: 0.9634 - dense_2_12_accuracy: 0.9539 - dense_2_13_accuracy: 0.9525 - dense_2_14_accuracy: 0.9541 - dense_2_15_accuracy: 0.9569 - dense_2_16_accuracy: 0.9694 - dense_2_17_accuracy: 0.9748 - dense_2_18_accuracy: 0.9870 - dense_2_19_accuracy: 0.9895\n",
            "Epoch 40/40\n",
            "91/91 [==============================] - 8s 93ms/step - loss: 1.2769 - dense_2_loss: 2.3921e-04 - dense_2_1_loss: 3.3037e-04 - dense_2_2_loss: 5.2985e-04 - dense_2_3_loss: 0.0046 - dense_2_4_loss: 0.0097 - dense_2_5_loss: 0.0150 - dense_2_6_loss: 0.0236 - dense_2_7_loss: 0.0323 - dense_2_8_loss: 0.0487 - dense_2_9_loss: 0.0668 - dense_2_10_loss: 0.0898 - dense_2_11_loss: 0.1216 - dense_2_12_loss: 0.1473 - dense_2_13_loss: 0.1648 - dense_2_14_loss: 0.1547 - dense_2_15_loss: 0.1399 - dense_2_16_loss: 0.1075 - dense_2_17_loss: 0.0846 - dense_2_18_loss: 0.0373 - dense_2_19_loss: 0.0276 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9991 - dense_2_4_accuracy: 0.9982 - dense_2_5_accuracy: 0.9959 - dense_2_6_accuracy: 0.9940 - dense_2_7_accuracy: 0.9905 - dense_2_8_accuracy: 0.9849 - dense_2_9_accuracy: 0.9794 - dense_2_10_accuracy: 0.9727 - dense_2_11_accuracy: 0.9637 - dense_2_12_accuracy: 0.9556 - dense_2_13_accuracy: 0.9513 - dense_2_14_accuracy: 0.9550 - dense_2_15_accuracy: 0.9595 - dense_2_16_accuracy: 0.9686 - dense_2_17_accuracy: 0.9777 - dense_2_18_accuracy: 0.9899 - dense_2_19_accuracy: 0.9932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efc20456710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C2RET9GwXDh"
      },
      "source": [
        "# Thai-Script to Roman-Script Translation\n",
        "* Task 4: Test your model on 5 examples of your choice including your name! (1 point)\n",
        "* Task 5: Show your visualization of attention scores on one of your example (1 point)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dvr8zVctSUr7",
        "outputId": "e1be9bd3-746a-44e5-a47f-eaa69567ad7c"
      },
      "source": [
        "def prep_input(input_list):\n",
        "    prep = []\n",
        "    for line in input_list:\n",
        "        temp = []\n",
        "        for char in line:\n",
        "            temp.append(input_char_idx[char])\n",
        "        prep.append(temp)\n",
        "    prep = pad_sequences(prep, maxlen=max_input)\n",
        "    prep = to_categorical(prep, input_vocab_size)\n",
        "    return prep\n",
        "\n",
        "\n",
        "ex = [\"ธีระ\", \"ธีรา\", \"ธีรธรรม\", \"ธรรมธร\", \"ธรรมกร\"]\n",
        "isin = [ name in name_th for name in ex]\n",
        "\n",
        "s0 = np.zeros((len(ex), n_s))\n",
        "c0 = np.zeros((len(ex), n_s))\n",
        "prep = prep_input(ex)\n",
        "\n",
        "prediction_a = model.predict([prep, s0, c0])\n",
        "prediction_b = np.swapaxes(prediction_a, 0, 1)\n",
        "prediction = np.argmax(prediction_b, axis=-1)\n",
        "for j in range(len(prediction)):\n",
        "    output = (\"\".join([output_idx_char[int(i)] for i in prediction[j]])).strip(\"<PAD>\")\n",
        "    print(isin[j], ex[j], output)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True ธีระ thira\n",
            "False ธีรา thira\n",
            "False ธีรธรรม thiratham\n",
            "False ธรรมธร thamthon\n",
            "False ธรรมกร thhmmkon\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9-mxbsKwXDp"
      },
      "source": [
        "### Plot the attention map\n",
        "* If you need to install thai font: sudo apt install xfonts-thai\n",
        "* this is what your visualization might look like:\n",
        "<img src=\"https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/images/attn_viz_sample.png\"  style=\"width: 350px;\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRL8hHaLwXDq"
      },
      "source": [
        "#task 5\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['font.family']='TH Sarabun New'  #you can change to other font that works for you\n",
        "#fill your code here"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOq8vFSkR2BU"
      },
      "source": [
        "model_att = Model(inputs=model.inputs, outputs=[model.outputs, [model.get_layer('attention_scores').get_output_at(e) for e in range(max_output)]])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymnlnlHPRgpX"
      },
      "source": [
        "ex_name = \"ธรรมกร\"\n",
        "ex_name_pad = [\"<PAD>\" for i in range(max_input-len(ex_name))]+list(ex_name)\n",
        "prep_name = prep_input([ex_name])\n",
        "s0 = np.zeros((len(prep_name), n_s))\n",
        "c0 = np.zeros((len(prep_name), n_s))\n",
        "\n",
        "pred_name = model_att.predict([prep_name, s0, c0])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_jWtbv9SW3o",
        "outputId": "46b98c2a-856a-4c57-c97c-a7c088752a65"
      },
      "source": [
        "pred_name_out = np.swapaxes(pred_name[0], 0, 1)\n",
        "pred_name_out = np.argmax(pred_name_out, axis=-1)\n",
        "\n",
        "output = [output_idx_char[int(i)] for i in pred_name_out[0]]\n",
        "print(\"\".join(ex_name_pad))\n",
        "print(\"\".join(output))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>ธรรมกร\n",
            "<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>thhmmkon\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XreV4yRFdUoJ"
      },
      "source": [
        "attention_score = np.array(pred_name[1])\n",
        "attention_score = attention_score.reshape(20, 20)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "RjAN_6MshQ2T",
        "outputId": "67ca0931-5c54-447e-b51f-36dded18c4ca"
      },
      "source": [
        "sns.heatmap(attention_score, xticklabels=ex_name_pad, yticklabels=output ,linewidths=0.01)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7efb25740650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}