{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hw2_nn_word_tokenizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVPuInbZGhZu"
      },
      "source": [
        "## Word Tokenizer exercise##\n",
        "\n",
        "In this exercise, you are going to build a set of deep learning models on a (sort of) real world task using Tensorflow and Keras. Tensorflow is a deep learning framwork developed by Google, and Keras is a frontend library built on top of Tensorflow (or Theano, CNTK) to provide an easier way to use standard layers and networks.\n",
        "\n",
        "To complete this exercise, you will need to build deep learning models for word tokenization in Thai (แบ่งเว้นวรรคภาษาไทย) using NECTEC's BEST corpus. You will build one model for each of the following type:\n",
        "- Fully Connected (Feedforward) Neural Network\n",
        "- One-Dimentional Convolution Neural Network (1D-CNN)\n",
        "- Recurrent Neural Network with Gated Recurrent Unit (GRU)\n",
        "\n",
        "and one more model of your choice to achieve the highest score possible.\n",
        "\n",
        "We provide the code for data cleaning and some starter code for keras in this notebook but feel free to modify those parts to suit your needs. You can also complete this exercise using only Tensorflow (without using Keras). Feel free to use additional libraries (e.g. scikit-learn) as long as you have a model for each type mentioned above.\n",
        "\n",
        "**Don't forget to change hardware accelerator to GPU in Google Colab.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaTlUuSSP-ib"
      },
      "source": [
        "#Select tensorflow 2.0\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5xZnz2pGhZx"
      },
      "source": [
        "# Run setup code\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "import tensorflow as tf\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "c0eeumL-M8oZ",
        "outputId": "82b5a5e2-0a23-487d-d2d5-56792875b4b0"
      },
      "source": [
        "#Check GPU is available\n",
        "!nvidia-smi\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jan 28 13:32:40 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUiIBX2EHe3G"
      },
      "source": [
        "#Download dataset\n",
        "gdd.download_file_from_google_drive(file_id='1iodAqVNWEkiJgH8cWkccsLi_tqoFcMrV',\n",
        "                                    dest_path='./corpora.tar.gz')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-GN9NAyII9p",
        "outputId": "ff995deb-2d2b-4541-9224-edca4c212793"
      },
      "source": [
        "!tar xvzf corpora.tar.gz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpora/\n",
            "corpora/mnist_data/\n",
            "corpora/mnist_data/t10k-images-idx3-ubyte.gz\n",
            "corpora/mnist_data/train-images-idx3-ubyte.gz\n",
            "corpora/mnist_data/.ipynb_checkpoints/\n",
            "corpora/mnist_data/vis_utils.py\n",
            "corpora/mnist_data/__init__.py\n",
            "corpora/mnist_data/load_mnist.py\n",
            "corpora/mnist_data/train-labels-idx1-ubyte.gz\n",
            "corpora/mnist_data/t10k-labels-idx1-ubyte.gz\n",
            "corpora/BEST/\n",
            "corpora/BEST/test/\n",
            "corpora/BEST/test/df_best_article_test.csv\n",
            "corpora/BEST/test/df_best_encyclopedia_test.csv\n",
            "corpora/BEST/test/df_best_novel_test.csv\n",
            "corpora/BEST/test/df_best_news_test.csv\n",
            "corpora/BEST/train/\n",
            "corpora/BEST/train/df_best_encyclopedia_train.csv\n",
            "corpora/BEST/train/df_best_article_train.csv\n",
            "corpora/BEST/train/df_best_news_train.csv\n",
            "corpora/BEST/train/df_best_novel_train.csv\n",
            "corpora/BEST/val/\n",
            "corpora/BEST/val/df_best_encyclopedia_val.csv\n",
            "corpora/BEST/val/df_best_news_val.csv\n",
            "corpora/BEST/val/df_best_article_val.csv\n",
            "corpora/BEST/val/df_best_novel_val.csv\n",
            "corpora/.ipynb_checkpoints/\n",
            "corpora/.ipynb_checkpoints/Word_Tokenizer.new-checkpoint.ipynb\n",
            "corpora/.ipynb_checkpoints/BackProp-checkpoint.ipynb\n",
            "corpora/.ipynb_checkpoints/Word_Tokenizer_backup-checkpoint.ipynb\n",
            "corpora/.ipynb_checkpoints/char2vec-checkpoint.ipynb\n",
            "corpora/.ipynb_checkpoints/Word_Tokenizer-checkpoint.ipynb\n",
            "corpora/cattern/\n",
            "corpora/cattern/gradient_check.py\n",
            "corpora/cattern/.ipynb_checkpoints/\n",
            "corpora/cattern/__init__.py\n",
            "corpora/cattern/data_utils.py\n",
            "corpora/wiki/\n",
            "corpora/wiki/thwiki_chk.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C76gLVKeGhZ0"
      },
      "source": [
        "# Prepare data\n",
        "# You don't need to run the following code as we already did it for you to give everyone the same dataset\n",
        "# import cattern.data_utils\n",
        "# cattern.data_utils.generate_best_dataset(os.getcwd()+'/data', create_val=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhxWFvL2GhZ3"
      },
      "source": [
        "For simplicity, we are going to build a word tokenization model which is a binary classification model trying to predict whether a character is the begining of the word or not (if it is, then there is a space in front of it) and without using any knowledge about type of character (vowel, number, English character etc.).\n",
        "\n",
        "For example,\n",
        "\n",
        "'แมวดำน่ารักมาก' -> 'แมว ดำ น่า รัก มาก'\n",
        "\n",
        "will have these true labels:\n",
        "\n",
        "[(แ,1), (ม,0), (ว,0) (ด,1), ( ำ,0), (น,1), (-่,0), (า,0), (ร,1), (-ั,0), (ก,0), (ม,1), (า,0), (ก,0)]\n",
        "\n",
        "In this task, we will use only main character you are trying to predict  and the characters that surround it (the context) as features. However, you can imagine that a more complex model will try to include more knowledge about each character into the model. You can do that too if you feel like it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PIEb0TMGhZ4",
        "outputId": "852ec8a9-6322-4fe9-b737-a806e024db81"
      },
      "source": [
        "# Create a character map\n",
        "CHARS = [\n",
        "  '\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+',\n",
        "  ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8',\n",
        "  '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E',\n",
        "  'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R',\n",
        "  'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_',\n",
        "  'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
        "  'n', 'o', 'other', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y',\n",
        "  'z', '}', '~', 'ก', 'ข', 'ฃ', 'ค', 'ฅ', 'ฆ', 'ง', 'จ', 'ฉ', 'ช',\n",
        "  'ซ', 'ฌ', 'ญ', 'ฎ', 'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท',\n",
        "  'ธ', 'น', 'บ', 'ป', 'ผ', 'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ฤ',\n",
        "  'ล', 'ว', 'ศ', 'ษ', 'ส', 'ห', 'ฬ', 'อ', 'ฮ', 'ฯ', 'ะ', 'ั', 'า',\n",
        "  'ำ', 'ิ', 'ี', 'ึ', 'ื', 'ุ', 'ู', 'ฺ', 'เ', 'แ', 'โ', 'ใ', 'ไ',\n",
        "  'ๅ', 'ๆ', '็', '่', '้', '๊', '๋', '์', 'ํ', '๐', '๑', '๒', '๓',\n",
        "  '๔', '๕', '๖', '๗', '๘', '๙', '‘', '’', '\\ufeff'\n",
        "]\n",
        "CHARS_MAP = {v: k for k, v in enumerate(CHARS)}\n",
        "CHARS_MAP"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '#': 4,\n",
              " '$': 5,\n",
              " '%': 6,\n",
              " '&': 7,\n",
              " \"'\": 8,\n",
              " '(': 9,\n",
              " ')': 10,\n",
              " '*': 11,\n",
              " '+': 12,\n",
              " ',': 13,\n",
              " '-': 14,\n",
              " '.': 15,\n",
              " '/': 16,\n",
              " '0': 17,\n",
              " '1': 18,\n",
              " '2': 19,\n",
              " '3': 20,\n",
              " '4': 21,\n",
              " '5': 22,\n",
              " '6': 23,\n",
              " '7': 24,\n",
              " '8': 25,\n",
              " '9': 26,\n",
              " ':': 27,\n",
              " ';': 28,\n",
              " '<': 29,\n",
              " '=': 30,\n",
              " '>': 31,\n",
              " '?': 32,\n",
              " '@': 33,\n",
              " 'A': 34,\n",
              " 'B': 35,\n",
              " 'C': 36,\n",
              " 'D': 37,\n",
              " 'E': 38,\n",
              " 'F': 39,\n",
              " 'G': 40,\n",
              " 'H': 41,\n",
              " 'I': 42,\n",
              " 'J': 43,\n",
              " 'K': 44,\n",
              " 'L': 45,\n",
              " 'M': 46,\n",
              " 'N': 47,\n",
              " 'O': 48,\n",
              " 'P': 49,\n",
              " 'Q': 50,\n",
              " 'R': 51,\n",
              " 'S': 52,\n",
              " 'T': 53,\n",
              " 'U': 54,\n",
              " 'V': 55,\n",
              " 'W': 56,\n",
              " 'X': 57,\n",
              " 'Y': 58,\n",
              " 'Z': 59,\n",
              " '[': 60,\n",
              " '\\\\': 61,\n",
              " ']': 62,\n",
              " '^': 63,\n",
              " '_': 64,\n",
              " 'a': 65,\n",
              " 'b': 66,\n",
              " 'c': 67,\n",
              " 'd': 68,\n",
              " 'e': 69,\n",
              " 'f': 70,\n",
              " 'g': 71,\n",
              " 'h': 72,\n",
              " 'i': 73,\n",
              " 'j': 74,\n",
              " 'k': 75,\n",
              " 'l': 76,\n",
              " 'm': 77,\n",
              " 'n': 78,\n",
              " 'o': 79,\n",
              " 'other': 80,\n",
              " 'p': 81,\n",
              " 'q': 82,\n",
              " 'r': 83,\n",
              " 's': 84,\n",
              " 't': 85,\n",
              " 'u': 86,\n",
              " 'v': 87,\n",
              " 'w': 88,\n",
              " 'x': 89,\n",
              " 'y': 90,\n",
              " 'z': 91,\n",
              " '}': 92,\n",
              " '~': 93,\n",
              " 'ก': 94,\n",
              " 'ข': 95,\n",
              " 'ฃ': 96,\n",
              " 'ค': 97,\n",
              " 'ฅ': 98,\n",
              " 'ฆ': 99,\n",
              " 'ง': 100,\n",
              " 'จ': 101,\n",
              " 'ฉ': 102,\n",
              " 'ช': 103,\n",
              " 'ซ': 104,\n",
              " 'ฌ': 105,\n",
              " 'ญ': 106,\n",
              " 'ฎ': 107,\n",
              " 'ฏ': 108,\n",
              " 'ฐ': 109,\n",
              " 'ฑ': 110,\n",
              " 'ฒ': 111,\n",
              " 'ณ': 112,\n",
              " 'ด': 113,\n",
              " 'ต': 114,\n",
              " 'ถ': 115,\n",
              " 'ท': 116,\n",
              " 'ธ': 117,\n",
              " 'น': 118,\n",
              " 'บ': 119,\n",
              " 'ป': 120,\n",
              " 'ผ': 121,\n",
              " 'ฝ': 122,\n",
              " 'พ': 123,\n",
              " 'ฟ': 124,\n",
              " 'ภ': 125,\n",
              " 'ม': 126,\n",
              " 'ย': 127,\n",
              " 'ร': 128,\n",
              " 'ฤ': 129,\n",
              " 'ล': 130,\n",
              " 'ว': 131,\n",
              " 'ศ': 132,\n",
              " 'ษ': 133,\n",
              " 'ส': 134,\n",
              " 'ห': 135,\n",
              " 'ฬ': 136,\n",
              " 'อ': 137,\n",
              " 'ฮ': 138,\n",
              " 'ฯ': 139,\n",
              " 'ะ': 140,\n",
              " 'ั': 141,\n",
              " 'า': 142,\n",
              " 'ำ': 143,\n",
              " 'ิ': 144,\n",
              " 'ี': 145,\n",
              " 'ึ': 146,\n",
              " 'ื': 147,\n",
              " 'ุ': 148,\n",
              " 'ู': 149,\n",
              " 'ฺ': 150,\n",
              " 'เ': 151,\n",
              " 'แ': 152,\n",
              " 'โ': 153,\n",
              " 'ใ': 154,\n",
              " 'ไ': 155,\n",
              " 'ๅ': 156,\n",
              " 'ๆ': 157,\n",
              " '็': 158,\n",
              " '่': 159,\n",
              " '้': 160,\n",
              " '๊': 161,\n",
              " '๋': 162,\n",
              " '์': 163,\n",
              " 'ํ': 164,\n",
              " '๐': 165,\n",
              " '๑': 166,\n",
              " '๒': 167,\n",
              " '๓': 168,\n",
              " '๔': 169,\n",
              " '๕': 170,\n",
              " '๖': 171,\n",
              " '๗': 172,\n",
              " '๘': 173,\n",
              " '๙': 174,\n",
              " '‘': 175,\n",
              " '’': 176,\n",
              " '\\ufeff': 177}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLzWh8e3GhZ7"
      },
      "source": [
        "def create_n_gram_df(df, n_pad):\n",
        "  \"\"\"\n",
        "  Given an input dataframe, create a feature dataframe of shifted characters\n",
        "  Input:\n",
        "  df: timeseries of size (N)\n",
        "  n_pad: the number of context. For a given character at position [idx],\n",
        "    character at position [idx-n_pad/2 : idx+n_pad/2] will be used \n",
        "    as features for that character.\n",
        "  \n",
        "  Output:\n",
        "  dataframe of size (N * n_pad) which each row contains the character, \n",
        "    n_pad_2 characters to the left, and n_pad_2 characters to the right\n",
        "    of that character.\n",
        "  \"\"\"\n",
        "  n_pad_2 = int((n_pad - 1)/2)\n",
        "  for i in range(n_pad_2):\n",
        "      df['char-{}'.format(i+1)] = df['char'].shift(i + 1)\n",
        "      df['char{}'.format(i+1)] = df['char'].shift(-i - 1)\n",
        "  return df[n_pad_2: -n_pad_2]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTdWc1kAGhZ9"
      },
      "source": [
        "def prepare_feature(best_processed_path, option='train'):\n",
        "  \"\"\"\n",
        "  Transform the path to a directory containing processed files \n",
        "  into a feature matrix and output array\n",
        "  Input:\n",
        "  best_processed_path: str, path to a processed version of the BEST dataset\n",
        "  option: str, 'train' or 'test'\n",
        "  \"\"\"\n",
        "  # we use padding equals 21 here to consider 10 characters to the left\n",
        "  # and 10 characters to the right as features for the character in the middle\n",
        "  n_pad = 21\n",
        "  n_pad_2 = int((n_pad - 1)/2)\n",
        "  pad = [{'char': ' ', 'target': True}]\n",
        "  df_pad = pd.DataFrame(pad * n_pad_2)\n",
        "\n",
        "  df = []\n",
        "  # article types in BEST corpus\n",
        "  article_types = ['article', 'encyclopedia', 'news', 'novel']\n",
        "  for article_type in article_types:\n",
        "      df.append(pd.read_csv(os.path.join(best_processed_path, option, 'df_best_{}_{}.csv'.format(article_type, option))))\n",
        "  \n",
        "  df = pd.concat(df)\n",
        "  # pad with empty string feature\n",
        "  df = pd.concat((df_pad, df, df_pad))\n",
        "\n",
        "  # map characters to numbers, use 'other' if not in the predefined character set.\n",
        "  df['char'] = df['char'].map(lambda x: CHARS_MAP.get(x, 80))\n",
        "\n",
        "  # Use nearby characters as features\n",
        "  df_with_context = create_n_gram_df(df, n_pad=n_pad)\n",
        "\n",
        "  char_row = ['char' + str(i + 1) for i in range(n_pad_2)] + \\\n",
        "             ['char-' + str(i + 1) for i in range(n_pad_2)] + ['char']\n",
        "\n",
        "  # convert pandas dataframe to numpy array to feed to the model\n",
        "  x_char = df_with_context[char_row].to_numpy()\n",
        "  y = df_with_context['target'].astype(int).to_numpy()\n",
        "\n",
        "  return x_char, y"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD-rj_A-GhaA"
      },
      "source": [
        "Before running the following commands, we must inform you that our data is quite large and loading the whole dataset at once will **use a lot of memory (~6 GB after processing and up to ~12GB while processing)**. We expect you to be running this on Google Cloud or Google Colab so that you will not run into this problem. But, if, for any reason, you have to run this on your PC or machine with not enough memory, you might need to write a data generator to process a few entries at a time then feed it to the model while training.\n",
        "\n",
        "For keras, you can use [fit_generator](https://keras.io/getting-started/faq/#how-can-i-use-keras-with-datasets-that-dont-fit-in-memory) to cope with that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO6tammyGhaA"
      },
      "source": [
        "# Path to the preprocessed data\n",
        "best_processed_path = 'corpora/BEST'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGTv1h-_GhaD",
        "outputId": "75be820d-b91d-42ae-bdb7-cd128f469032"
      },
      "source": [
        "# Load preprocessed BEST corpus\n",
        "x_train_char, y_train = prepare_feature(best_processed_path, option='train')\n",
        "x_val_char, y_val = prepare_feature(best_processed_path, option='val')\n",
        "x_test_char, y_test = prepare_feature(best_processed_path, option='test')\n",
        "\n",
        "# As a sanity check, we print out the size of the training, val, and test data.\n",
        "print('Training data shape: ', x_train_char.shape)\n",
        "print('Training data labels shape: ', y_train.shape)\n",
        "print('Validation data shape: ', x_val_char.shape)\n",
        "print('Validation data labels shape: ', y_val.shape)\n",
        "print('Test data shape: ', x_test_char.shape)\n",
        "print('Test data labels shape: ', y_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape:  (16461637, 21)\n",
            "Training data labels shape:  (16461637,)\n",
            "Validation data shape:  (2035694, 21)\n",
            "Validation data labels shape:  (2035694,)\n",
            "Test data shape:  (2271932, 21)\n",
            "Test data labels shape:  (2271932,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXh5E82tGhaF",
        "outputId": "4abe56cb-e18a-4004-a1cc-29de8ea06fc1"
      },
      "source": [
        "# Print some entry from the data to make sure it is the same as what you think.\n",
        "print('First 3 features: ', x_train_char[:3])\n",
        "print('First 30 class labels', y_train[:30])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 3 features:  [[112. 140. 114. 148. 130. 142.  94. 142. 128. 128.   1.   1.   1.   1.\n",
            "    1.   1.   1.   1.   1.   1.  97.]\n",
            " [140. 114. 148. 130. 142.  94. 142. 128. 128. 141.  97.   1.   1.   1.\n",
            "    1.   1.   1.   1.   1.   1. 112.]\n",
            " [114. 148. 130. 142.  94. 142. 128. 128. 141. 109. 112.  97.   1.   1.\n",
            "    1.   1.   1.   1.   1.   1. 140.]]\n",
            "First 30 class labels [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7sUX7gCGhaI",
        "outputId": "d3d9000a-049b-492e-ea1e-56cfb5c7084d"
      },
      "source": [
        "#print char of feature 1\n",
        "char = np.array(CHARS)\n",
        "\n",
        "#A function for displaying our features in text\n",
        "def print_features(tfeature,label,index):\n",
        "    feature = np.array(tfeature[index],dtype=int).reshape(21,1)\n",
        "    #Convert to string\n",
        "    char_list = char[feature]\n",
        "    left = ''.join(reversed(char_list[10:20].reshape(10))).replace(\" \", \"\")\n",
        "    center = ''.join(char_list[20])\n",
        "    right =  ''.join(char_list[0:10].reshape(10)).replace(\" \", \"\")\n",
        "    word = ''.join([left,' ',center,' ',right])\n",
        "    print(center + ': ' + word + \"\\tpred = \"+str(label[index]))\n",
        "\n",
        "for ind in range(0,30):\n",
        "    print_features(x_train_char,y_train,ind)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ค:  ค ณะตุลาการร\tpred = 1\n",
            "ณ: ค ณ ะตุลาการรั\tpred = 0\n",
            "ะ: คณ ะ ตุลาการรัฐ\tpred = 0\n",
            "ต: คณะ ต ุลาการรัฐธ\tpred = 0\n",
            "ุ: คณะต ุ ลาการรัฐธร\tpred = 0\n",
            "ล: คณะตุ ล าการรัฐธรร\tpred = 0\n",
            "า: คณะตุล า การรัฐธรรม\tpred = 0\n",
            "ก: คณะตุลา ก ารรัฐธรรมน\tpred = 0\n",
            "า: คณะตุลาก า รรัฐธรรมนู\tpred = 0\n",
            "ร: คณะตุลากา ร รัฐธรรมนูญ\tpred = 0\n",
            "ร: คณะตุลาการ ร ัฐธรรมนูญก\tpred = 0\n",
            "ั: ณะตุลาการร ั ฐธรรมนูญกั\tpred = 0\n",
            "ฐ: ะตุลาการรั ฐ ธรรมนูญกับ\tpred = 0\n",
            "ธ: ตุลาการรัฐ ธ รรมนูญกับค\tpred = 0\n",
            "ร: ุลาการรัฐธ ร รมนูญกับคว\tpred = 0\n",
            "ร: ลาการรัฐธร ร มนูญกับควา\tpred = 0\n",
            "ม: าการรัฐธรร ม นูญกับความ\tpred = 0\n",
            "น: การรัฐธรรม น ูญกับความเ\tpred = 0\n",
            "ู: ารรัฐธรรมน ู ญกับความเป\tpred = 0\n",
            "ญ: รรัฐธรรมนู ญ กับความเป็\tpred = 0\n",
            "ก: รัฐธรรมนูญ ก ับความเป็น\tpred = 1\n",
            "ั: ัฐธรรมนูญก ั บความเป็นอ\tpred = 0\n",
            "บ: ฐธรรมนูญกั บ ความเป็นอง\tpred = 0\n",
            "ค: ธรรมนูญกับ ค วามเป็นองค\tpred = 1\n",
            "ว: รรมนูญกับค ว ามเป็นองค์\tpred = 0\n",
            "า: รมนูญกับคว า มเป็นองค์ก\tpred = 0\n",
            "ม: มนูญกับควา ม เป็นองค์กร\tpred = 0\n",
            "เ: นูญกับความ เ ป็นองค์กรต\tpred = 1\n",
            "ป: ูญกับความเ ป ็นองค์กรตุ\tpred = 0\n",
            "็: ญกับความเป ็ นองค์กรตุล\tpred = 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh5dG3w3GhaN"
      },
      "source": [
        "Now, you are going to define the model to be used as your classifier. If you are using Keras, please follow the guideline we provide below. We encourage you to use the Keras Funtional API instead of the Sequential model as it is easier to create complex models (and to read your code). You can find more about Keras Functional API on Keras [documentation](https://keras.io/getting-started/functional-api-guide/).\n",
        "\n",
        "You need to create a function that return a model you want and write code that invoke _**model.fit**_ to train your model. For example, your function ***get_nn()*** might looks like this:\n",
        "\n",
        "```python\n",
        "def get_nn():\n",
        "  input1 = Input(...)\n",
        "  ...\n",
        "  # Create your wonderful model.\n",
        "  ...\n",
        "  out = ...\n",
        "  model = Model(inputs=input1, outputs=out)\n",
        "  model.compile(...)\n",
        "return model\n",
        "```\n",
        "\n",
        "Also, beware that complex model requires more time to train and your dataset is already quite large. We tested it with a simple 1-hidden-layered feedforward nueral network and it used ~10 mins to train 1 epoch. It got more than 95% accuracy on validation set after the first epoch, so you should aim for a model with accuracy around 96-98%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGX36Qc4GhaO"
      },
      "source": [
        "# Three-Layer Feedforward Neural Networks\n",
        "\n",
        "Below, we provide you the code for creating a 3-layer fully connected neural network in keras. This will also serve as the baseline for your other models. Run the code below while making sure you understand what you are doing. Then, report the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TohElGvuGhaO"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def get_feedforward_nn():\n",
        "  input1 = Input(shape=(21,))\n",
        "  x = Dense(100, activation='relu')(input1)\n",
        "  x = Dense(100, activation='relu')(x)\n",
        "  x = Dense(100, activation='relu')(x)\n",
        "  out = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "  model = Model(inputs=input1, outputs=out)\n",
        "  model.compile(optimizer=Adam(),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])\n",
        "  return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDwqboppGhaR",
        "outputId": "c184eddc-479a-4ca5-d5e2-b1b7d116da48"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "\n",
        "# This is called to clear the original model session in order to use TensorBoard\n",
        "from tensorflow.keras import backend as K\n",
        "K.clear_session()\n",
        "\n",
        "# Path to save model parameters\n",
        "weight_path_feedforward_nn='./model_weight_feedforward_nn.h5'\n",
        "\n",
        "# Training callbacks list. TensorBoard() write logs for tensorboard GUI. \n",
        "# ModelCheckpoint() writes the resulting model.\n",
        "# Note that writing to disk takes time (longer than model training time). \n",
        "# For other sections, you might not writing any files to disk \n",
        "# or write only the graph for TensorBoard.\n",
        "\n",
        "callbacks_list_feedforward_nn = [\n",
        "        TensorBoard(log_dir='./Graph/ff', histogram_freq=1, write_graph=True, write_grads=False),\n",
        "        ModelCheckpoint(\n",
        "            weight_path_feedforward_nn,\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True,\n",
        "            monitor='val_loss',\n",
        "            mode='min',\n",
        "            verbose=1\n",
        "        )\n",
        "  ]\n",
        "\n",
        "print('start training')\n",
        "verbose = 1\n",
        "model_feedforward_nn = get_feedforward_nn()\n",
        "train_params = [(3, 512)]\n",
        "for (epochs, batch_size) in train_params:\n",
        "  print(\"train with {} epochs and {} batch size\".format(epochs, batch_size))\n",
        "  model_feedforward_nn.fit(x_train_char, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose,\n",
        "                           callbacks=callbacks_list_feedforward_nn,\n",
        "                           validation_data=(x_val_char, y_val))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start training\n",
            "train with 3 epochs and 512 batch size\n",
            "Epoch 1/3\n",
            "32152/32152 [==============================] - 99s 3ms/step - loss: 0.4222 - acc: 0.8247 - val_loss: 0.2937 - val_acc: 0.8736\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.29374, saving model to ./model_weight_feedforward_nn.h5\n",
            "Epoch 2/3\n",
            "32152/32152 [==============================] - 95s 3ms/step - loss: 0.2826 - acc: 0.8792 - val_loss: 0.2581 - val_acc: 0.8916\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.29374 to 0.25812, saving model to ./model_weight_feedforward_nn.h5\n",
            "Epoch 3/3\n",
            "32152/32152 [==============================] - 96s 3ms/step - loss: 0.2546 - acc: 0.8931 - val_loss: 0.2528 - val_acc: 0.8959\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.25812 to 0.25276, saving model to ./model_weight_feedforward_nn.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SCsblxEGhaT"
      },
      "source": [
        "################################################################################\n",
        "# In case you want to close the session, you can re-load the model by          #\n",
        "################################################################################\n",
        "# weight_path_feedforward_nn='/data/model_weight_feedforward_nn.h5'\n",
        "# model_feedforward_nn = get_feedforward_nn()\n",
        "# model_feedforward_nn.load_weights(weight_path_feedforward_nn)\n",
        "# model_feedforward_nn._make_predict_function()\n",
        "# model_feedforward_nn.summary()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07ErGkHMGhaV"
      },
      "source": [
        "from sklearn.metrics import f1_score,precision_score,recall_score\n",
        "\n",
        "################################################################################\n",
        "# Write a function to evaluate your model. Your function must make prediction  #\n",
        "# using the input model and return f-score, precision, and recall of the model.#\n",
        "# You can make predictions by calling model.predict().                         #\n",
        "################################################################################\n",
        "def evaluate(x_test, y_test, model):\n",
        "  \"\"\"\n",
        "  Evaluate model on the splitted 10 percent testing set.\n",
        "  \"\"\"\n",
        "  y_pred = model.predict(x_test)\n",
        "\n",
        "  #map probability to class\n",
        "  prob_to_class = lambda p: 1 if p[0]>=0.5 else 0\n",
        "  y_pred = np.apply_along_axis(prob_to_class,1,y_pred)\n",
        "  \n",
        "  f1score = f1_score(y_test,y_pred)\n",
        "  precision = precision_score(y_test,y_pred)\n",
        "  recall = recall_score(y_test,y_pred)\n",
        "\n",
        "  return f1score, precision, recall"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZoBB5YJGhaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "012718e5-8546-4f71-ee0d-2ddcc6da3a1f"
      },
      "source": [
        "evaluate(x_test_char, y_test, model_feedforward_nn)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8166626429550139, 0.8266893034652752, 0.8068762884155155)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBuqJw3kGhaa"
      },
      "source": [
        "# Debugging\n",
        "\n",
        "In order to understand what is going on in your model and where the error is, you should try looking at the inputs your model made wrong predictions.\n",
        "\n",
        "In this task, write a function to print the characters on test data that got wrong prediction along with its context of size 10 (from [x-10] to [x+10]). Examine a fews of those and write your assumption on where the model got wrong prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsV7cHslGhab"
      },
      "source": [
        "# TODO#1\n",
        "# Write code to show a few of the errors the models made.\n",
        "\n",
        "def debug(model, x_test, y_test, percent) :\n",
        "    y_pred = model.predict(x_test)\n",
        "    prob_to_class = lambda p: 1 if p[0]>=0.5 else 0\n",
        "    y_pred = np.apply_along_axis(prob_to_class,1,y_pred)\n",
        "\n",
        "    for ind in range(int(len(y_pred)*percent)) :\n",
        "        if y_test[ind] != y_pred[ind] :\n",
        "            print_features(x_test, y_pred, ind)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQmMO0nhLBl3",
        "outputId": "72fd7bd0-e93f-4485-8d85-96ef42b0bc3c"
      },
      "source": [
        "debug(model_feedforward_nn, x_test_char, y_test, 0.001)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ิ: ปฏ ิ รูปการศึกษ\tpred = 1\n",
            "ก: ปฏิรูป ก ารศึกษา:\tpred = 0\n",
            "ท: งทางกระบวน ท ัศน์และบริ\tpred = 0\n",
            "บ: วนทัศน์และ บ ริบทสังคมไ\tpred = 0\n",
            "ส: น์และบริบท ส ังคมไทยThe\tpred = 0\n",
            "ไ: บริบทสังคม ไ ทยTheRefo\tpred = 0\n",
            "ท: ริบทสังคมไ ท ยTheRefor\tpred = 1\n",
            "ร: rspectiveก ร ะบวนทัศน์แ\tpred = 1\n",
            "ะ: spectiveกร ะ บวนทัศน์แล\tpred = 1\n",
            "ท: tiveกระบวน ท ัศน์และวิธ\tpred = 0\n",
            "ว: วนทัศน์และ ว ิธีคิดแบบแ\tpred = 0\n",
            "แ: วิธีคิดแบบ แ ยกส่วนลดส\tpred = 0\n",
            "ก: ธีคิดแบบแย ก ส่วนลดส่ว\tpred = 1\n",
            "ส: ีคิดแบบแยก ส ่วนลดส่วน\tpred = 0\n",
            "ส: แยกส่วนลด ส ่วนได้ทำใ\tpred = 0\n",
            "เ: ้\"การศึกษา เ รียนรู้\"ใน\tpred = 0\n",
            "ร: ศึกษาเรียน ร ู้\"ในหลาย\tpred = 1\n",
            "ใ: าเรียนรู้\" ใ นหลายทศวร\tpred = 0\n",
            "ท: ู้\"ในหลาย ท ศวรรษที่ผ่\tpred = 0\n",
            "ก: ของนักวิชา ก ารด้านศึกษ\tpred = 1\n",
            "ก: กระทรวงศึ ก ษาธิการทบ\tpred = 1\n",
            "า: ระทรวงศึกษ า ธิการทบวง\tpred = 1\n",
            "ม: ธิการทบวง ม หาวิทยาลัย\tpred = 1\n",
            "เ: มาอย่างต่อ เ นื่องยาวนา\tpred = 1\n",
            "ภ: ่เรื่องสุข ภ าพเป็นเรื่\tpred = 1\n",
            "โ: องแพทย์และ โ รงพยาบาล)\tpred = 0\n",
            "ภ: ัดการศึกษา ภ ายใต้กระบว\tpred = 0\n",
            "ท: ยใต้กระบวน ท ัศน์และวิธ\tpred = 0\n",
            "ว: วนทัศน์และ ว ิธีคิดแบบด\tpred = 0\n",
            "ิ: น์และวิธีค ิ ดแบบดังกล่\tpred = 1\n",
            "ก: งรัฐได้ถู ก วิพากษ์วิจ\tpred = 1\n",
            "ว: รัฐได้ถูก ว ิพากษ์วิจา\tpred = 0\n",
            "ษ: ด้ถูกวิพาก ษ ์วิจารณ์แล\tpred = 1\n",
            "จ: กวิพากษ์วิ จ ารณ์และตกเ\tpred = 1\n",
            "ต: วิจารณ์และ ต กเป็นจำเลย\tpred = 0\n",
            "ม: ณ์ทางสังคม ม ากมายอันส\tpred = 0\n",
            "ส: มากมายอัน ส ะท้อนถึงคว\tpred = 0\n",
            "ล: ้อนถึงความ ล ้มเหลวของก\tpred = 0\n",
            "พ: ศึกษาเพื่อ พ ัฒนามนุษย์\tpred = 0\n",
            "น: ษาเพื่อพัฒ น ามนุษย์(ป\tpred = 1\n",
            "ม: เพื่อพัฒนา ม นุษย์(ปัญ\tpred = 0\n",
            "ศ: ษย์(ปัญหา ศ ีลธรรมเสื่\tpred = 0\n",
            "ถ: ธรรมเสื่อม ถ อยยาเสพติ\tpred = 1\n",
            "เ: ื่อมถอยยา เ สพติดการข\tpred = 0\n",
            "ต: มถอยยาเสพ ต ิดการขาดจ\tpred = 0\n",
            "า: สพติดการข า ดจิตสำนึกท\tpred = 1\n",
            "ส: การขาดจิต ส ำนึกทางสัง\tpred = 0\n",
            "ำ: การขาดจิตส ำ นึกทางสังค\tpred = 1\n",
            "ร: ซึ่งสังคม ร ่วมกันสรุป\tpred = 0\n",
            "ุ: มร่วมกันสร ุ ปว่าเกิดจ\tpred = 1\n",
            "ล: กิดจากความ ล ้มเหลวของร\tpred = 0\n",
            "ก: หลวของระบบ ก ารศึกษาในก\tpred = 0\n",
            "ใ: บบการศึกษา ใ นกระบวนทัศ\tpred = 0\n",
            "ท: ษาในกระบวน ท ัศน์แบบแยก\tpred = 0\n",
            "บ: บวนทัศน์แบ บ แยกส่วนนำ\tpred = 1\n",
            "แ: วนทัศน์แบบ แ ยกส่วนนำม\tpred = 0\n",
            "ก: ทัศน์แบบแย ก ส่วนนำมาส\tpred = 1\n",
            "ส: ัศน์แบบแยก ส ่วนนำมาสู\tpred = 0\n",
            "ม: แยกส่วนนำ ม าสู่การปฏิ\tpred = 0\n",
            "า: ยกส่วนนำม า สู่การปฏิร\tpred = 1\n",
            "ส: กส่วนนำมา ส ู่การปฏิรู\tpred = 0\n",
            "ป: นำมาสู่การ ป ฏิรูปการศึ\tpred = 0\n",
            "ิ: มาสู่การปฏ ิ รูปการศึกษ\tpred = 1\n",
            "ท: ูปการศึกษา ท ี่กำลังดำเ\tpred = 0\n",
            "ล: ศึกษาที่กำ ล ังดำเนินกา\tpred = 1\n",
            "ก: ำลังดำเนิน ก ารอยู่ในปั\tpred = 1\n",
            "จ: รอยู่ในปัจ จ ุบันด้วยเ\tpred = 1\n",
            "ส: าหมายเพื่อ ส ร้างการเรี\tpred = 0\n",
            "ร: างการเรียน ร ู้แบบองค์ร\tpred = 1\n",
            "บ: เรียนรู้แบ บ องค์รวมที\tpred = 1\n",
            "อ: รียนรู้แบบ อ งค์รวมที่\tpred = 0\n",
            "ค: ยนรู้แบบอง ค ์รวมที่จะ\tpred = 1\n",
            "ใ: วมที่จะทำ ใ ห้\"ผู้เรีย\tpred = 0\n",
            "ง: ู้เรียนเก่ ง -ดี-มีความ\tpred = 1\n",
            "ด: เรียนเก่ง- ด ี-มีความสุ\tpred = 0\n",
            "-: ียนเก่ง-ดี - มีความสุข\"\tpred = 0\n",
            "ค: เก่ง-ดี-มี ค วามสุข\"คำถ\tpred = 0\n",
            "ส: -ดี-มีความ ส ุข\"คำถามที\tpred = 0\n",
            "ถ: ความสุข\"คำ ถ ามที่ผู้เข\tpred = 0\n",
            "น: ที่ผู้เขีย น สนใจในการป\tpred = 1\n",
            "ส: ี่ผู้เขียน ส นใจในการปฏ\tpred = 0\n",
            "ิ: นใจในการปฏ ิ รูปการศึกษ\tpred = 1\n",
            "ท: ูปการศึกษา ท ี่ดำเนินกา\tpred = 0\n",
            "เ: ศึกษาที่ดำ เ นินการในปั\tpred = 1\n",
            "ก: าที่ดำเนิน ก ารในปัจจุบ\tpred = 1\n",
            "ิ: คือ๑.การปฏ ิ รูปการศึกษ\tpred = 1\n",
            "ใ: ูปการศึกษา ใ นปัจจุบันด\tpred = 0\n",
            "ก: ุบันดำเนิน ก ารภายใต้กร\tpred = 1\n",
            "ท: ยใต้กระบวน ท ัศน์แบบบูร\tpred = 0\n",
            "ก: น์แบบบูรณา ก าร(องค์รว\tpred = 1\n",
            "ร: าการ(องค์ ร วม)ตามที่ต\tpred = 0\n",
            "ค: ้งจุดประสง ค ์ไว้จริงหร\tpred = 1\n",
            "ร: ระสงค์ไว้จ ร ิงหรือไม่\tpred = 1\n",
            "ไ: อไม่อย่าง ไ ร๒.ในบริบท\tpred = 0\n",
            "บ: ย่างไร๒.ใน บ ริบทของสัง\tpred = 0\n",
            "ไ: บทของสังคม ไ ทยปัจจุบัน\tpred = 0\n",
            "ป: ุบันหากจะ ป ฏิรูปการศึ\tpred = 0\n",
            "ิ: ันหากจะปฏ ิ รูปการศึกษ\tpred = 1\n",
            "เ: ูปการศึกษา เ พื่อไปสู่ก\tpred = 0\n",
            "ไ: ศึกษาเพื่อ ไ ปสู่การเรี\tpred = 0\n",
            "ก: เพื่อไปสู่ ก ารเรียนรู้\tpred = 0\n",
            "ร: ู่การเรียน ร ู้อย่างบู\tpred = 1\n",
            "ก: อย่างบูรณา ก ารจริงจะต้\tpred = 1\n",
            "จ: างบูรณาการ จ ริงจะต้องป\tpred = 0\n",
            "ล: ต้องปรับเป ล ี่ยนปัจจัย\tpred = 1\n",
            "จ: เปลี่ยนปัจ จ ัยหรือเงื่\tpred = 1\n",
            "เ: ปัจจัยหรือ เ งื่อนไขอะไ\tpred = 0\n",
            "ไ: หรือเงื่อน ไ ขอะไรอีกหร\tpred = 1\n",
            "อ: ือเงื่อนไข อ ะไรอีกหรือ\tpred = 0\n",
            "อ: ื่อนไขอะไร อ ีกหรือไม่\tpred = 0\n",
            "ห: นไขอะไรอีก ห รือไม่อย่\tpred = 0\n",
            "ไ: อไม่อย่าง ไ ร๑.กระบวน\tpred = 0\n",
            "ท: ร๑.กระบวน ท ัศน์การศึก\tpred = 0\n",
            "ไ: น์การศึกษา ไ ทยหลังสงคร\tpred = 0\n",
            "ห: ารศึกษาไทย ห ลังสงครามโ\tpred = 0\n",
            "ส: กษาไทยหลัง ส งครามโลกคร\tpred = 0\n",
            "ค: าไทยหลังสง ค รามโลกครั้\tpred = 1\n",
            "โ: หลังสงคราม โ ลกครั้งที่\tpred = 0\n",
            "ท: ามโลกครั้ง ท ี่๒สิ้นส\tpred = 0\n",
            "ส: ที่๒สิ้น ส ุดลงประเท\tpred = 1\n",
            "ล: ๒สิ้นสุด ล งประเทศสห\tpred = 0\n",
            "ม: ในการพัฒนา ม นุษย์และสั\tpred = 0\n",
            "ค: ุษย์และสัง ค มทุกด้านเ\tpred = 1\n",
            "บ: นเป็นต้นแ บ บของการพัฒ\tpred = 1\n",
            "เ: ฒนาทางด้าน เ ศรษฐกิจสั\tpred = 0\n",
            "ศ: สังคมการ ศ ึกษาฯลฯว\tpred = 0\n",
            "ห: ฯวัฒนธรรม ห รือวิถีชีว\tpred = 0\n",
            "ว: ฒนธรรมหรือ ว ิถีชีวิตแบ\tpred = 0\n",
            "ว: หรือวิถีชี ว ิตแบบอเมริ\tpred = 1\n",
            "แ: อวิถีชีวิต แ บบอเมริกัน\tpred = 0\n",
            "บ: ิถีชีวิตแบ บ อเมริกันได\tpred = 1\n",
            "อ: ถีชีวิตแบบ อ เมริกันได้\tpred = 0\n",
            "ส: พึงปรารถนา ส ำหรับประเท\tpred = 0\n",
            "ป: รถนาสำหรับ ป ระเทศอดีตอ\tpred = 0\n",
            "ศ: ำหรับประเท ศ อดีตอาณานิ\tpred = 1\n",
            "อ: หรับประเทศ อ ดีตอาณานิค\tpred = 0\n",
            "อ: ประเทศอดีต อ าณานิคมและ\tpred = 0\n",
            "น: ทศอดีตอาณา น ิคมและประเ\tpred = 1\n",
            "ม: ดีตอาณานิค ม และประเทศเ\tpred = 1\n",
            "ป: าณานิคมและ ป ระเทศเกิดใ\tpred = 0\n",
            "เ: มและประเทศ เ กิดใหม่หลั\tpred = 0\n",
            "ใ: ประเทศเกิด ใ หม่หลังสงค\tpred = 0\n",
            "ห: ทศเกิดใหม่ ห ลังสงครามโ\tpred = 0\n",
            "ส: ิดใหม่หลัง ส งครามโลกแ\tpred = 0\n",
            "ค: ใหม่หลังสง ค รามโลกแนว\tpred = 1\n",
            "โ: หลังสงคราม โ ลกแนวคิดก\tpred = 0\n",
            "พ: แนวคิดการ พ ัฒนาของโลก\tpred = 0\n",
            "ง: การพัฒนาขอ ง โลกตะวันตก\tpred = 1\n",
            "โ: ารพัฒนาของ โ ลกตะวันตกท\tpred = 0\n",
            "ว: นาของโลกตะ ว ันตกที่มีส\tpred = 1\n",
            "ต: องโลกตะวัน ต กที่มีสหรั\tpred = 0\n",
            "ส: วันตกที่มี ส หรัฐเป็นผู\tpred = 0\n",
            "ห: ันตกที่มีส ห รัฐเป็นผู้\tpred = 1\n",
            "ภ: ำนั้นอยู่ ภ ายใต้กระบว\tpred = 0\n",
            "ท: ยใต้กระบวน ท ัศน์หรือฐา\tpred = 0\n",
            "ห: ระบวนทัศน์ ห รือฐานคิดข\tpred = 0\n",
            "อ: วนทัศน์หรื อ ฐานคิดของว\tpred = 1\n",
            "ฐ: นทัศน์หรือ ฐ านคิดของวิ\tpred = 0\n",
            "แ: ่มองโลกแบบ แ ยกส่วนลดส\tpred = 0\n",
            "ก: องโลกแบบแย ก ส่วนลดส่ว\tpred = 1\n",
            "ส: แยกส่วนลด ส ่วน(reduc\tpred = 0\n",
            "ย: ามสำคัญและ ย อมรับ\"ความ\tpred = 0\n",
            "ช: กับสิ่งที่ ช ั่งตวงวั\tpred = 0\n",
            "ว: หลักการและ ว ิธีการทางว\tpred = 0\n",
            "ก: การและวิธี ก ารทางวิทยา\tpred = 1\n",
            "อ: ้นความรู้ อ ื่นๆที่ช\tpred = 0\n",
            "ช: อื่นๆที่ ช ั่งตวงวั\tpred = 0\n",
            "ด: ได้อย่างชั ด เจนแม่นยำ\tpred = 1\n",
            "เ: ด้อย่างชัด เ จนแม่นยำห\tpred = 1\n",
            "น: อย่างชัดเจ น แม่นยำหรื\tpred = 1\n",
            "ย: ชัดเจนแม่น ย ำหรือพิสู\tpred = 1\n",
            "พ: ม่นยำหรือ พ ิสูจน์ให้ป\tpred = 0\n",
            "จ: ูจน์ให้ประ จ ักษ์(Empi\tpred = 1\n",
            "เ: ical)หรือ เ ห็นแบบชัดเ\tpred = 0\n",
            "เ: งที่ไม่น่า เ ชื่อถือหา\tpred = 0\n",
            "น: อถือหากจะ น ับให้เป็นค\tpred = 0\n",
            "ง: จะต้องแสว ง หาวิธีการช\tpred = 1\n",
            "ว: ต้องแสวงหา ว ิธีการชั่ง\tpred = 0\n",
            "จ: วณค่าออกมา จ ึงจะเชื่อถ\tpred = 0\n",
            "ด: ้นความรู้ ด ั้งเดิมที\tpred = 0\n",
            "เ: วามรู้ดั้ง เ ดิมที่เป็\tpred = 1\n",
            "ป: ี่เป็นภูมิ ป ัญญาของท้อ\tpred = 1\n",
            "ญ: ป็นภูมิปัญ ญ าของท้องถิ\tpred = 1\n",
            "ถ: ญญาของท้อง ถ ิ่นซึ่งอธิ\tpred = 1\n",
            "อ: องถิ่นซึ่ง อ ธิบายด้วยว\tpred = 0\n",
            "บ: ิ่นซึ่งอธิ บ ายด้วยวิธี\tpred = 1\n",
            "ก: ายด้วยวิธี ก ารทางวิทยา\tpred = 1\n",
            "แ: ยาศาสตร์ใน แ บบที่กำหนด\tpred = 0\n",
            "ป: ้แม้จะใช้ ป ระโยชน์ได้\tpred = 0\n",
            "จ: ระโยชน์ได้ จ ริงในชีวิต\tpred = 0\n",
            "ป: ริงในชีวิต ป ระจำวันของ\tpred = 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHjvB1syGhad"
      },
      "source": [
        "# Write your answer here\n",
        "\n",
        "**Your answer**: TODO#2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F1ncACiLTY-"
      },
      "source": [
        "จากการสังเกตจะเห็นว่ามักจะเกิดข้อผิดพลาดในจุดที่สละอยู่ในระดับเดียวกับตัวอักษรเช่น า โ แ หรือตัวอักษรที่อยู่ในคำที่เป็นคำที่มีหลายพยางค์\r\n",
        "\r\n",
        "\r\n",
        "อย่างไรก็ตามอาจมีคำที่ label ผิดพลาดเช่น \"ชีวิตประจำวัน\" ที่น่าจะเป็นคำเดียวกันไม่ใช่ \"ชีวิต\" ประจำวัน\" การที่โมเดล predict ว่าเป็น 0 จึงควรถูกแล้ว"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9cLkAUEGhae"
      },
      "source": [
        "# Tensorboard #\n",
        "The code provided also have Tensorboard (a visualization tool that comes with Tensorflow). Note the part that calls it `TensorBoard(log_dir='./Graph/' + graph_name, histogram_freq=1, write_graph=True, write_grads=True)`. This tells Tensorflow to write extra outputs to the `log_dir` which can then be used for visualization.\n",
        "\n",
        "To start tensorboard do\n",
        "```\n",
        "tensorboard --logdir=/full_path_to_your_logs\n",
        "```\n",
        "\n",
        "In Tensorboard, you will be able to debug your computation graph which can be hard to keep track in code. This is might seem trivial in Keras, but it is very helpful for Tensorflow. You can see a visualization of the computation graph at the `GRAPH` tab. If you see multiple dense layers (more than 4), this is caused by running the code several times without deleting the log dir. Delete the log dir and re-run the code.\n",
        "\n",
        "Next, let's look at the scalars tab, we can see the loss and accuracy on the training and validation set as they change over each epoch. This can be useful to detect overfitting.\n",
        "\n",
        "Another useful tab is the histograms tab (Enable by setting 'write_grads=True'). This plot histograms of the weights, biases, and outputs of each layer. The depth of the histograms show the change over epochs. We can see how the histograms of weights change over the training peroid. This can be used to debug vanishing gradients or getting stuck in local minimas.\n",
        "\n",
        "There are other useful tabs in Tensorboard, you can read about them in the Keras [documentation](https://keras.io/callbacks/#tensorboard) for tensorboard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGsGl0wPJYjI"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir='./Graph/ff'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-feqv2DbGhae"
      },
      "source": [
        "# Tensorboard observation\n",
        "\n",
        "Write your own interpretation of the logs from this example. A simple sentence or two for each tab is sufficient.\n",
        "\n",
        "**Your answer**: TODO#3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrsYWDaijKsb"
      },
      "source": [
        "Scalar: บอกถึง accuracy กับ loss ที่เปลี่ยนตาม epoch แต่ละครั้ง\r\n",
        "\r\n",
        "Graph: แสดง neural network model \r\n",
        "\r\n",
        "Distribution: แสดงว่าค่า parameter ต่างๆในโมเดลเปลี่ยนไปยังไง\r\n",
        "\r\n",
        "Histogram: อีกรูปแบบหนึ่งของการแสดงค่า parameter ต่างๆ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvYIoaL9Ghaf"
      },
      "source": [
        "# Dropout\n",
        "\n",
        "You might notice that the 3-layered feedforward does not use dropout at all. Now, try adding dropout to the model, run, and report the result again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kCkj03VGhag"
      },
      "source": [
        "# TODO#4\n",
        "# Write a function that return feedforward model with dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def get_nn_with_dropout():\n",
        "  input = Input(shape=(21,))\n",
        "  x = Dense(100, activation='relu')(input)\n",
        "  x = Dense(100, activation='relu')(x)\n",
        "  x = Dense(100, activation='relu')(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  out = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "  model = Model(inputs=input, outputs=out)\n",
        "  model.compile(optimizer=Adam(),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])\n",
        "  return model"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7ZnCqcyw4qL",
        "outputId": "6c368c72-ef78-4a6e-d3a8-38953d68f81b"
      },
      "source": [
        "model_nn_with_dropout = get_nn_with_dropout()\r\n",
        "model_nn_with_dropout.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 21)]              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               2200      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 22,501\n",
            "Trainable params: 22,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i08GqWiGhai",
        "outputId": "c55ba4d1-c922-4b56-8245-5b20a085d8b4"
      },
      "source": [
        "# Train your model\n",
        "print('start training')\n",
        "verbose = 2\n",
        "model_nn_with_dropout = get_nn_with_dropout()\n",
        "# TODO#5\n",
        "# Complete the code to train your model with dropout\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "callbacks_list = [\n",
        "        TensorBoard(log_dir='./Graph/dropout', histogram_freq=1, write_graph=True, write_grads=False)\n",
        "]\n",
        "\n",
        "epochs = 3\n",
        "batch_size = 512\n",
        "print(\"train with {} epochs and {} batch size\".format(epochs, batch_size))\n",
        "model_nn_with_dropout.fit(x_train_char, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose,\n",
        "                        callbacks=callbacks_list,\n",
        "                        validation_data=(x_val_char, y_val))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start training\n",
            "train with 3 epochs and 512 batch size\n",
            "Epoch 1/3\n",
            "32152/32152 - 94s - loss: 0.3585 - acc: 0.8445 - val_loss: 0.2945 - val_acc: 0.8715\n",
            "Epoch 2/3\n",
            "32152/32152 - 92s - loss: 0.2917 - acc: 0.8748 - val_loss: 0.2700 - val_acc: 0.8845\n",
            "Epoch 3/3\n",
            "32152/32152 - 93s - loss: 0.2727 - acc: 0.8845 - val_loss: 0.2551 - val_acc: 0.8927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0d23e18240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhnDFcAaGhan",
        "outputId": "4e79179b-f940-4726-d1d9-31b2fef04a8e"
      },
      "source": [
        "evaluate(x_test_char, y_test, model_nn_with_dropout)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.799284186206441, 0.8615505679110622, 0.7454114636400256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOTSGof4Ghaq"
      },
      "source": [
        "# Convolution Neural Networks\n",
        "\n",
        "Now, you are going to implement you own 1d-convolution neural networks with the following structure:\n",
        "input -> embedding layer (size 32) -> 1D-convolution layer (100 filters of size 5, strides of 1) -> TimeDistributed (Dense size 5) -> fully-connected layer (size 100) -> output.\n",
        "\n",
        "These parameters are simple guidelines to save your time. You can play with them in the final section.\n",
        "\n",
        "The results should be better than the feedforward model.\n",
        "\n",
        "Embedding layers turn the input from a one-hot vector into better representations via some feature transform (a simple matrix multiply in this case). TimeDistributed is Keras' way of specifying that the layer of the network should be distributed along time (the first dimension) as shown in the picture below.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/ekapolc/nlp_course/master/HW1/images/configuration.png\">\n",
        "\n",
        "Note you need to flatten() before the final fully connected layer because of dimension mis-match.\n",
        "\n",
        "Do consult keras documentation on how to use [embedding layers](https://keras.io/layers/embeddings/) and [1D-cnn](https://keras.io/layers/convolutional/).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5hKpZ-3hE1E"
      },
      "source": [
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Conv1D, TimeDistributed, Flatten\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ruKGHjTGhaq"
      },
      "source": [
        "################################################################################\n",
        "# TODO#6:                                                                      #\n",
        "# Write a function that returns keras convolution nueral network model.        #\n",
        "# You can choose any normalization methods, activation function, as well as    #\n",
        "# any hyperparameter the way you want. Your goal is to predict a score         #\n",
        "# between [0,1] for each input whether it is the beginning of the word or not. #\n",
        "#                                                                              #\n",
        "# Hint: You should read keras documentation to see the list of available       #\n",
        "# layers and options you can use.                                              #\n",
        "################################################################################\n",
        "\n",
        "def get_conv1d_nn():\n",
        "    input = Input(shape=(21,))\n",
        "    x = Embedding(input_dim=179,output_dim=32)(input)\n",
        "    x = Conv1D(filters=100, strides=1, kernel_size=5)(x)\n",
        "    x = TimeDistributed(Dense(5))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(100, activation=\"relu\")(x)\n",
        "    out = Dense(1, activation='sigmoid')(x)\n",
        "    \n",
        "    model = Model(inputs=input, outputs=out)\n",
        "    model.compile(optimizer=Adam(),\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['acc'])\n",
        "    return model"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oepouo71xFl_",
        "outputId": "566e7c2e-7f68-4e77-e3cf-b2b10e76151b"
      },
      "source": [
        "model_conv1d_nn = get_conv1d_nn()\r\n",
        "model_conv1d_nn.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 21)]              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 21, 32)            5728      \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 17, 100)           16100     \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 17, 5)             505       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 85)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 100)               8600      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 31,034\n",
            "Trainable params: 31,034\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAohzSijGhas",
        "outputId": "80d16040-dcf7-4407-d1c2-1439c60f7fd6"
      },
      "source": [
        "################################################################################\n",
        "# TODO#7:                                                                      #\n",
        "# Write code that call model.fit, or model.fit_generator if you have data      #\n",
        "# generator, to train you models. Make sure you have validation_data as an     # \n",
        "# argument and use verbose=2 to generate one log line per epoch. Select your   #\n",
        "# batch size carefully as it will affect your model's ability to converge and  #\n",
        "# time needed for one epoch.                                                   #\n",
        "################################################################################\n",
        "print('start training conv1d')\n",
        "model_conv1d_nn = get_conv1d_nn()\n",
        "verbose = 2\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "callback_list = [TensorBoard(log_dir=\"./Graph/Conv1D\", histogram_freq=1, write_graph=True, write_grads=False)]\n",
        "train_params = [(3, 512)]\n",
        "eopchs = 3 \n",
        "batch_size = 512\n",
        "print(\"train with {} epochs and {} batch size\".format(epochs, batch_size))\n",
        "model_conv1d_nn.fit(x_train_char, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose,\n",
        "                        callbacks=callback_list,\n",
        "                        validation_data=(x_val_char, y_val))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start training conv1d\n",
            "train with 3 epochs and 512 batch size\n",
            "Epoch 1/3\n",
            "32152/32152 - 174s - loss: 0.1106 - acc: 0.9565 - val_loss: 0.0994 - val_acc: 0.9615\n",
            "Epoch 2/3\n",
            "32152/32152 - 164s - loss: 0.0928 - acc: 0.9644 - val_loss: 0.0926 - val_acc: 0.9648\n",
            "Epoch 3/3\n",
            "32152/32152 - 164s - loss: 0.0881 - acc: 0.9664 - val_loss: 0.0893 - val_acc: 0.9666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0d23cfa208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFT1ZjZuGhau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70831b6f-2ad0-489b-8e3e-c77c7cd69f7c"
      },
      "source": [
        "evaluate(x_test_char, y_test, model_conv1d_nn)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9449224874254285, 0.925735251772394, 0.9649219249816364)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctS8V2rMGhax"
      },
      "source": [
        "# GRU\n",
        "\n",
        "Implement your GRU model with the following structure: input -> embedding layer (size 32) -> GRU layer (size 32) -> fully-connected layer (size 100) -> output.\n",
        "\n",
        "\n",
        "These parameters are simple guidelines to save your time. You can play with them in the final section.\n",
        "\n",
        "The result should be better than the feedforward model and at least on par with your CNN model.\n",
        "\n",
        "Do consult keras documentation on how to use [embedding layers](https://keras.io/layers/embeddings/) and [GRUs](https://keras.io/layers/recurrent/).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8OZwDclkD9w"
      },
      "source": [
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, GRU\r\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQbPtCKUGhay"
      },
      "source": [
        "################################################################################\n",
        "# TODO#8                                                                       #\n",
        "# Write a function that returns keras GRU network moded. You can choose any    #\n",
        "# normalization methods, activation function, as well as any hyperparameter    #\n",
        "# the way you want. Your goal is to predict a score between [0,1] for each     #\n",
        "# input whether it is the beginning of the word or not.                        #\n",
        "#                                                                              #\n",
        "# Hint: You should read keras documentation to see the list of available       #\n",
        "# layers and options you can use.                                              #\n",
        "################################################################################\n",
        "\n",
        "def get_gru():\n",
        "    inputs = Input(shape=(21,))\n",
        "    x = Embedding(180,32)(inputs)\n",
        "    x = GRU(32)(x)\n",
        "    outputs = Dense(100, activation=\"relu\")(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=Adam(),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['acc'])\n",
        "    return model"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3l0z_nUGha0",
        "outputId": "798cffba-d3b5-46e4-d800-191567fba0d3"
      },
      "source": [
        "################################################################################\n",
        "# TODO#9                                                                       #\n",
        "# Write code that call model.fit, or model.fit_generator if you have data      #\n",
        "# generator, to train you models. Make sure you have validation_data as an     # \n",
        "# argument and use verbose=2 to generate one log line per epoch. Select your   #\n",
        "# batch size carefully as it will affect your model's ability to converge and  #\n",
        "# time needed for one epoch.                                                   #\n",
        "################################################################################\n",
        "print('start training conv1d')\n",
        "model_gru = get_gru()\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "callback_list = [TensorBoard(log_dir=\"./Graph/GRU\", histogram_freq=1, write_graph=True, write_grads=False)]\n",
        "train_params = [(3, 512)]\n",
        "epochs = 3\n",
        "batch_size = 512\n",
        "print(\"train with {} epochs and {} batch size\".format(epochs, batch_size))\n",
        "model_gru.fit(x_train_char, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose,\n",
        "                        callbacks=callback_list,\n",
        "                        validation_data=(x_val_char, y_val))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start training conv1d\n",
            "train with 3 epochs and 512 batch size\n",
            "Epoch 1/3\n",
            "32152/32152 - 207s - loss: 0.2836 - acc: 0.2709 - val_loss: 0.2490 - val_acc: 0.3639\n",
            "Epoch 2/3\n",
            "32152/32152 - 206s - loss: 0.2103 - acc: 0.4453 - val_loss: 0.1647 - val_acc: 0.5178\n",
            "Epoch 3/3\n",
            "32152/32152 - 203s - loss: 0.1762 - acc: 0.5029 - val_loss: 0.2179 - val_acc: 0.4875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0d23470f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiYbLM1IGha2",
        "outputId": "90816d95-3211-4a30-9d41-b31ac58c41ad"
      },
      "source": [
        "evaluate(x_test_char, y_test, model_gru)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8375472160520963, 0.8252042865684456, 0.8502649890608093)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqgyzyMIGha4"
      },
      "source": [
        "# Final Section\n",
        "# Keras playground\n",
        "\n",
        "Now, train the best model you can do for this task. You can use any model structure and function available. Remember that trainig time increases with the complexity of the model. You might find TensorBoard helpful in tuning of complicated models.\n",
        "\n",
        "Your model should be better than your CNN or GRU model in the previous sections.\n",
        "\n",
        "Some ideas to try\n",
        "1. Tune the parameters\n",
        "2. Bi-directional GRU\n",
        "3. CNN-GRU model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xx1HCP6J3cX"
      },
      "source": [
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, GRU, Dropout, Conv1D, Bidirectional, LSTM, Activation, SpatialDropout1D, MaxPooling1D\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\r\n",
        "from tensorflow.keras import Sequential"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLAItYSVzUva"
      },
      "source": [
        "verbose = 1"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIya6OYHGha4"
      },
      "source": [
        "################################################################################\n",
        "# TODO#10                                                                      #\n",
        "# Write a function that returns keras your best model. You can use anything    #\n",
        "# you want. The goal here is to create the best model you can think of.        #\n",
        "# Your model should get f-score more than 97% from calling evaluate().         #\n",
        "#                                                                              #\n",
        "# Hint: You should read keras documentation to see the list of available       #\n",
        "# layers and options you can use.                                              #\n",
        "################################################################################\n",
        "\n",
        "def get_my_best_model():\n",
        "    input = Input(shape=(21,))\n",
        "    x = Embedding(input_dim=180, output_dim=300, input_length=21)(input)\n",
        "    x = Bidirectional(GRU(100, return_sequences=True))(x)\n",
        "    x = Bidirectional(LSTM(100))(x)\n",
        "    x = Dense(100, activation=\"relu\")(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(100, activation=\"relu\")(x)\n",
        "    output = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = Model(inputs=input, outputs=output)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mOriMKuGha7",
        "outputId": "3fb03727-b102-4f6a-cb44-8ef25c12b874"
      },
      "source": [
        "################################################################################\n",
        "# TODO#11                                                                      #\n",
        "# Write code that call model.fit, or model.fit_generator if you have data      #\n",
        "# generator, to train you models. Make sure you have validation_data as an     # \n",
        "# argument and use verbose=2 to generate one log line per epoch. Select your   #\n",
        "# batch size carefully as it will affect your model's ability to converge and  #\n",
        "# time needed for one epoch.                                                   #\n",
        "#                                                                              #\n",
        "# Hint: Read about callbacks_list argument on the documentation. You might     #\n",
        "# find  ReduceLROnPlateau() and ModelCheckpoint() useful for your training     #\n",
        "# process. Feel free to use any other callback function available.             #\n",
        "################################################################################\n",
        "print('start training')\n",
        "my_best_model = get_my_best_model()\n",
        "verbose = 1\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "callback_list = [TensorBoard(log_dir=\"./Graph/mbm\", histogram_freq=1, write_graph=True, write_grads=False)]\n",
        "epochs = 3\n",
        "batch_size = 512\n",
        "print(\"train with {} epochs and {} batch size\".format(epochs, batch_size))\n",
        "my_best_model.fit(x_train_char, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose,\n",
        "                            callbacks=callback_list,\n",
        "                            validation_data=(x_val_char, y_val))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start training\n",
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 21)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 21, 300)           54000     \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 21, 200)           241200    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 200)               240800    \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 566,301\n",
            "Trainable params: 566,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "train with 3 epochs and 512 batch size\n",
            "Epoch 1/3\n",
            "32152/32152 [==============================] - 943s 29ms/step - loss: 0.0942 - accuracy: 0.9622 - val_loss: 0.0434 - val_accuracy: 0.9852\n",
            "Epoch 2/3\n",
            "32152/32152 [==============================] - 957s 30ms/step - loss: 0.0354 - accuracy: 0.9879 - val_loss: 0.0389 - val_accuracy: 0.9869\n",
            "Epoch 3/3\n",
            "32152/32152 [==============================] - 957s 30ms/step - loss: 0.0338 - accuracy: 0.9884 - val_loss: 0.0416 - val_accuracy: 0.9860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0d1c13c518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvKUBwu0xf2e",
        "outputId": "a9c946e2-0cdb-4923-8af1-a025a0f0834b"
      },
      "source": [
        "evaluate(x_test_char, y_test, my_best_model)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9779469963914411, 0.9732325002190211, 0.9827073904698718)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}