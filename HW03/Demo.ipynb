{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "Demo.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poTf4ECrC__U",
        "colab_type": "text"
      },
      "source": [
        "# CRF Tutorial using python-crfsuite\n",
        "\n",
        "In this tutorial, we will try to use CRF to work on part-of-speech (POS) tagging. There are 6 main parts in this tutorial\n",
        "1. Setup and preprocessing\n",
        "2. Designing feature funcions\n",
        "3. Training\n",
        "4. Making predictions\n",
        "5. Evaluation\n",
        "6. Try: Design a more complex model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q0r5bMWC__X",
        "colab_type": "text"
      },
      "source": [
        "# 1. Setup and preprocessing\n",
        "\n",
        "In this demo we will use [python-crfsuite](https://github.com/scrapinghub/python-crfsuite)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4goDOqhDHyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://www.dropbox.com/s/tuvrbsby4a5axe0/resources.zip\n",
        "!unzip resources.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgvizFblDwQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install python-crfsuite"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0P4NXh2C__Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pycrfsuite\n",
        "import numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_vshf2IC__e",
        "colab_type": "text"
      },
      "source": [
        "We use POS data from [ORCHID corpus](https://www.nectec.or.th/corpus/index.php?league=pm), which is a POS corpus for Thai language.\n",
        "A method used to read the corpus into a list of sentences with (word, POS) pairs have been implemented already. The example usage has shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmKJpcShC__f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from data.orchid_corpus import get_sentences\n",
        "train_data = get_sentences('train')\n",
        "test_data = get_sentences('test')\n",
        "train_data[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLm9wu-JC__k",
        "colab_type": "text"
      },
      "source": [
        "## 2. Designing features functions\n",
        "\n",
        "- __word2features()__: This method returns all feature functions for time step _i_ of an input sequence. So, this method is where all feature functions are defined. From the code, we can define just features from input sequence (word for this example), the library will manage the transition functions ($y_{t-1}$ -> $y_t$) and state functions ($y_t$ -> $X$, with all $X$ features you defined in this method) for you.\n",
        "- __sent2features()__: Loop and call word2features() over the input sequence.\n",
        "- __sent2labels()__: Get the output labels from train/test sequence\n",
        "- __sent2tokens()__: Get words from train/test sequence (used in prediction part just to show the full result)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqz0CWOjC__m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    \n",
        "    features = {\n",
        "        'word': word,\n",
        "        'word.isdigit': word.isdigit(),\n",
        "        'word.length': len(word),\n",
        "    }\n",
        "    \n",
        "    features['BOS'] = (i == 0)  # beginning of sentence\n",
        "    features['EOS'] = (i == len(sent)-1)  # end of sentence\n",
        "    \n",
        "    return features\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for (word, label) in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [word for (word, label) in sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cJAoXcfC__q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent2features(train_data[0])[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5JOoNsJC__u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "x_train = [sent2features(sent) for sent in train_data]\n",
        "y_train = [sent2labels(sent) for sent in train_data]\n",
        "x_test = [sent2features(sent) for sent in test_data]\n",
        "y_test = [sent2labels(sent) for sent in test_data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR3ujmQbC__y",
        "colab_type": "text"
      },
      "source": [
        "## 3. Training\n",
        "\n",
        "To train a CRF model in python-crfsuite, we have to create a trainer and load training data (pairs of __generated features__ and __labels__) to the trainer first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7D2E4xjC__0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer = pycrfsuite.Trainer(verbose=False)\n",
        "for xseq, yseq in zip(x_train, y_train):\n",
        "    trainer.append(xseq, yseq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Roy0l0kBC__3",
        "colab_type": "text"
      },
      "source": [
        "There are several parameters you can set for the training process. You can list all parameter using this method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUb26dOvC__4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.params()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leHjaeM4C__9",
        "colab_type": "text"
      },
      "source": [
        "In this tutorial, we will use 3 parameters:\n",
        "\n",
        "- __max_iterations__: Define how many times we will let the model learn through training data\n",
        "- __feature.possible_transitions__: Enable the library to create transition feature functions (as we discussed in section 2)\n",
        "- __feature.possible_states__: Enable state feature functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUFm-wnHC__-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.set_params({\n",
        "    'max_iterations': 100,\n",
        "    'feature.possible_transitions': True,\n",
        "    'feature.possible_states': True,\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgmuWlMdDAAC",
        "colab_type": "text"
      },
      "source": [
        "Finally, call the trainer to train with the specified model path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyBxmMA8DAAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "model_path = 'model/crf_basic.model'\n",
        "trainer.train(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaS-0GiKDAAG",
        "colab_type": "text"
      },
      "source": [
        "## 4. Making predictions\n",
        "\n",
        "When we finished training a model. We can use that model to predict any sequence of words.\n",
        "To do this, create a tagger with path to the saved model. Then, generate features with a sequence we want to predict and send them to _tag_ method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czHncCaKDAAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tagger = pycrfsuite.Tagger()\n",
        "tagger.open(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRTwCBLrDAAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_sent = test_data[20]\n",
        "print(' '.join(sent2tokens(example_sent)))\n",
        "\n",
        "print('Predicted: ', ' '.join(tagger.tag(sent2features(example_sent))))\n",
        "print('Correct: ', ' '.join(sent2labels(example_sent)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3kWkkqaDAAT",
        "colab_type": "text"
      },
      "source": [
        "## 5. Evaluation\n",
        "\n",
        "To measure how good the model can perform, we have to evaluate the model on _test data_. For sequence labeling tasks, we often use __accuracy__ to measure a model's goodness. However, we can analyze further by considering each tag with\n",
        "- __prediction__: How many times the predicted tag _x_ is correctly tagged (it is a tag _x_ in the test data)\n",
        "- __recall__: How many times the real tag _x_ is correctly tagged (the model can answer that it is a tag _x_)\n",
        "\n",
        "The method below, evaluation_report(), is implemented to measure all metrics described and display it in DataFrame. It is ok to just use this method and not going through this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78W9EWc2DAAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "def evaluation_report(y_true, y_pred):\n",
        "    # retrieve all tags in y_true\n",
        "    tag_set = set()\n",
        "    for sent in y_true:\n",
        "        for tag in sent:\n",
        "            tag_set.add(tag)\n",
        "    tag_list = sorted(list(tag_set))\n",
        "    \n",
        "    # count correct points\n",
        "    tag_info = dict()\n",
        "    for tag in tag_list:\n",
        "        tag_info[tag] = {'correct_tagged': 0, 'y_true': 0, 'y_pred': 0}\n",
        "\n",
        "    all_correct = 0\n",
        "    all_count = sum([len(sent) for sent in y_true])\n",
        "    for sent_true, sent_pred in zip(y_true, y_pred):\n",
        "        for tag_true, tag_pred in zip(sent_true, sent_pred):\n",
        "            if tag_true == tag_pred:\n",
        "                tag_info[tag_true]['correct_tagged'] += 1\n",
        "                all_correct += 1\n",
        "            tag_info[tag_true]['y_true'] += 1\n",
        "            tag_info[tag_pred]['y_pred'] += 1\n",
        "    accuracy = (all_correct / all_count) * 100\n",
        "            \n",
        "    # summarize and make evaluation result\n",
        "    eval_list = list()\n",
        "    for tag in tag_list:\n",
        "        eval_result = dict()\n",
        "        eval_result['tag'] = tag\n",
        "        eval_result['correct_count'] = tag_info[tag]['correct_tagged']\n",
        "        precision = (tag_info[tag]['correct_tagged']/tag_info[tag]['y_pred'])*100 if tag_info[tag]['y_pred'] else '-'\n",
        "        recall = (tag_info[tag]['correct_tagged']/tag_info[tag]['y_true'])*100\n",
        "        eval_result['precision'] = precision\n",
        "        eval_result['recall'] = recall\n",
        "        eval_result['f_score'] = (2*precision*recall)/(precision+recall) if (type(precision) is float and recall > 0) else '-'\n",
        "        \n",
        "        eval_list.append(eval_result)\n",
        "\n",
        "    eval_list.append({'tag': 'accuracy=%.2f' % accuracy, 'correct_count': '', 'precision': '', 'recall': '', 'f_score': ''})\n",
        "    \n",
        "    df = pd.DataFrame.from_dict(eval_list)\n",
        "    df = df[['tag', 'precision', 'recall', 'f_score', 'correct_count']]\n",
        "    display(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGe--G2BDAAa",
        "colab_type": "text"
      },
      "source": [
        "Make predictions on test set (y_pred) and evaluate against the real label (y_test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBeKHRdbDAAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = [tagger.tag(x_sent) for x_sent in x_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mDyk1lODAAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_report(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awiCvf8BDAAj",
        "colab_type": "text"
      },
      "source": [
        "## 6. Use pretrained word embedding\n",
        "\n",
        "In this exercise, we will use pretrained word embedding from previous homework as word feature in pycrfsuite. We load pretrained word embedding using pickle. The pretrained weight is a dictionary which map a word to its embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtDNXb8mDAAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "fp = open('basic_ff_embedding.pt', 'rb')\n",
        "embeddings = pickle.load(fp)\n",
        "fp.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJyS8UUuDAAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word2features(sent, i, emb):\n",
        "    def add_embedding_features(feat, prefix, query_word):\n",
        "        if query_word in emb:\n",
        "            vec = emb[query_word]\n",
        "        else:\n",
        "            vec = numpy.zeros(32)\n",
        "        \n",
        "        for i in range(vec.shape[0]):\n",
        "            feat[prefix + str(i)] = vec[i]\n",
        "    \n",
        "    features = dict()\n",
        "    word = sent[i][0]\n",
        "    add_embedding_features(features, 'word.embd', word)\n",
        "    features.update({\n",
        "        'word.word' : word,\n",
        "        'word.isdigit': word.isdigit(),\n",
        "        'word.length': len(word),\n",
        "    })\n",
        "    \n",
        "    features['BOS'] = (i == 0)  # beginning of sentence\n",
        "    features['EOS'] = (i == len(sent)-1)  # end of sentence\n",
        "    \n",
        "    return features\n",
        "\n",
        "def sent2features(sent, emb_dict):\n",
        "    return [word2features(sent, i, emb_dict) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for (word, label) in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [word for (word, label) in sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_RwP00_DAAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "x_train = [sent2features(sent, embeddings) for sent in train_data]\n",
        "y_train = [sent2labels(sent) for sent in train_data]\n",
        "x_test = [sent2features(sent, embeddings) for sent in test_data]\n",
        "y_test = [sent2labels(sent) for sent in test_data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1ExtXIWDAAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent2features(train_data[0], embeddings)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AhJ-ZW8DAAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "trainer = pycrfsuite.Trainer(verbose=True)\n",
        "trainer.set_params({\n",
        "    'max_iterations': 100,\n",
        "    'feature.possible_transitions': True,\n",
        "    'feature.possible_states': True,\n",
        "})\n",
        "\n",
        "for xseq, yseq in zip(x_train, y_train):\n",
        "    trainer.append(xseq, yseq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MruTdjXYDAA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "model_path = 'model/crf_neural.model'\n",
        "trainer.train(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDa9Z3o5DAA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "model_path = 'model/crf_neural.model'\n",
        "tagger = pycrfsuite.Tagger()\n",
        "tagger.open(model_path)\n",
        "y_pred = [tagger.tag(x_sent) for x_sent in x_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VFaFz-IDAA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_report(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4324LUDpECxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}